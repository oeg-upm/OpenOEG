{
  "message": "SYSTEM: Wiki: Ir a LinkedData\nContents\n[\nhide\n]\n1\nPeople involved\n2\nPlanning\n3\nData sources\n3.1\nStudy of data set\n4\nVocabularies / Ontologies\n4.1\nSCOVO\n4.2\nOntology Review in the Meteorology domain\n4.3\nNon Ontological Resources\n4.4\nMetOffice conceptual objects model\n4.5\nAEMET ontology network\n5\nRDF Publication\n5.1\nInstalling Virtuoso\n5.1.1\nVirtuoso in Linux\n5.1.2\nVirtuoso in Windows\n5.2\nInstalling Pubby\n5.2.1\nThe Pubby Configuration File\n5.2.2\nPubby Configuration in the virtual server\n6\nData cleansing\n7\nVisualization\n8\nTO DO List\n8.1\nNext Week - 25/02/2011\n8.2\nNext Week - 18/03/2011\n8.3\nSecond iteration\nPeople involved\n\n1. Ghis\n2. Idafen\n3. Dani Garijo\n4. Soledad\n5. María\n6. Dani Vila\n7. José Mora\n8. Luis Vilches\n9. Mikel\n10. Pablo\nPlanning\n\nN\nTask\nPerson\n1\nIdentification and analysis of the resources\nHecha. Usaremos las observaciones. (Ver qué es la tabla 4680)\n2\nVocabulary/Ontology modelling\nMaría,Ghis\n3\nRDF Generation\nDaniel (G), Mora. Todos deben de entender el proceso. Interesante explorar codificación en español (eñes, acentos), generar documentación\n4\nRDF Publication\nTodos deben de aprender cómo se monta un pubby con un virtuoso, etc. Cualquier documentación es bienvenida. Cómo meterlo en nuestro visualizador (debería saber scovo, foaf, etc). Idafen. Daniel (G)\n5\nData cleansing\nSoledad, Daniel (V)\n6\nLinking the RDF generated\nSoledad, ?\n7\nEnable effective discovery\nTodos. registrar AEMET. Definición de URIs no va a ser un problema.\nData sources\n\nftp://ftpdatos.aemet.es/\n[datos_observacion/observaciones_diezminutales/] (\nscript\n)\nTambién es interesante tener en cuenta Invent de UK MetOffice, que acaban de sacar muy recientemente. Si sacamos Linked Data de esto nos hacemos famosos:\nhttp://www.metoffice.gov.uk/public/pws/invent/weathermap/\nPágina de descarga de los datasets\n: \"They may not be used for commercial or business applications, sold,\ntransferred\nor sub-licensed to any third party without obtaining an appropriate licence from the Met Office.\"\nFAQ\n. Otros enlaces:\n1\n2\nStudy of data set\n\nThe format is .csv (comma separate values)\nThe name of the file has the following nomenclatura yyyymmddhhmm_datos.csv. Thus, it could help extracting useful information at parsing time when reusing the data set contained in the dataset.\nExample. The file 201102121900_datos.csv means the data are from the year 2011, the month of february, on the 12 at 19:00.\nFor more example of a \"decoded\" data\n08001,A CORUÑA, --Estación con su código (cfr. tabla maestro.csv)\n43.366944, -8.419167: coordenadas\n1297554600000, 1297555200000: rango de milisegundos desde el 1 de enero de 1970 al que se refieren las mediciones.\nALT=58.0, --Altitud\nVV10m=5.0, --Velocidad media del viento (m/s)\nQVV10m=0, ---no identificado\nDV10m=202, --Dirección media del viento (grados)\nQDV10m=0, --no identificado\nRVIENTO=30.0, --Recorrido del viento\nQRVIENTO=0, --No identificado\nVMAX10m=11.3, --Velocidad máxima del viento m/s\nQVMAX10m=0, --No identificado\nDMAX10m=228, --Dirección de la velocidad máxima del viento (grados)\nQDMAX10m=0, --no identificado\nTA=11.3, --Temperatura del aire (grado)\nQTA=0, --no identificado\nHR=74,--Humedad relativa(%)\nQHR=0,-- no identificado\nREC=0.0, --no identificado\nQPREC=0, --no identificado\nPRES=1005.5, --Presión (hPa)\nQPRES=0, --no identificado\nTPR=6.8, --Temperatura del punto de rocío (%)\nQTPR=0, -- no identificado\nPRES_nmar=1013.6, --Presión reducida al nivel del mar\nQPRES_nmar=0 --no identificado\nNot all the stations presented in the dataset are filled with the same attributes.\nTime spend: 3 hours\nQ+Acronym refers to the quality of the data. The possible values are:\n0: Pasa todos los filtros.\n2: El dato se considera sospechoso.\n3: El dato podría ser erróneo.\nVocabularies / Ontologies\n\nhttp://aemet.linkeddata.es/ontology/\nhttp://aemet.linkeddata.es/ontology/ClassName\n(for Concepts)\nhttp://aemet.linkeddata.es/ontology/property\n(for Properties)\nSCOVO\n\nExamples:\nhttp://sw.joanneum.at/scovo/schema.html\nPaper:\nhttp://vmserver14.nuigalway.ie/xmlui/bitstream/handle/10379/443/eswc09-inuse-scovo.pdf?sequence=1\nStatistical Data and metadata eXchange (SDMX)\nhttp://www.iso.org/iso/catalogue_detail.htm?csnumber=40555\n(CHF 324,00?)\nSDMX content-oriented guidelines :\nhttp://sdmx.org/wp-content/uploads/2009/01/00_sdmx_content-oriented_guidelines_2009.pdf\nOntology Review in the Meteorology domain\n\nhttp://www.csd.abdn.ac.uk/research/AgentCities/WeatherAgent/weather-ont.daml\n(temperature, weather)\nhttp://homepages.inf.ed.ac.uk/stephenp/OWL/ForecastOntology.owl\n(Forecast)\nhttp://metadata.net/WildNET/Geography.owl\n(stations location)\nhttp://metadata.net/WildNET/Climate.owl\n(imports Geography.owl-Rainfall)\nhttp://sweet.jpl.nasa.gov/ontology/phenomena.owl\n(Phenomena- SWEET Project, 2004)\nhttp://sweet.jpl.nasa.gov/2.0/\n(SWEET Project)\nhttp://www.vistology.com/ont/2006/JC3IEDM3.0/JC3IEDM-Attributes.owl\n(temperature, pressure, wind, visibility)\nNon Ontological Resources\n\nhttp://www.wmo.int/pages/prog/www/metadata/WMO-core-metadata-toc.html\n(WMO Core Metadata)\nhttp://www.wmo.int/pages/prog/www/metadata/WMO19115_v0_1.html\n(WMO 19115 xsd)\nhttp://www.wmo.int/pages/prog/www/metadata/WMO-core-metadata-example-2.pdf\n(Example of using WMO by Met Office)\nMetOffice conceptual objects model\n\nAEMET ontology network\n\nAEMET ontology network conceptual model (draft):\nRDF Publication\n\nTo publish the data in RDF it is necessary to install two tools:\nVirtuoso\n(Triple Store which stores the rdf data and provides a SPARQL endpoint) and\nlink Pubby\n(to query the data from the repository in a viesual way instead of having to send sparql queries to the endpoint).\nSPARQLEndpoint\nhttp://aemet.linkeddata.es/sparql\nGraphs\nGraph Name:\nhttp://aemet.linkeddata.es/data\nLos datos generados por Mora\nViewer\nhttp://geo.linkeddata.es:8282/aemet/\nInstalling Virtuoso\n\nWe have run Virtuoso in Windows and Linux. Here we summarize the steps to make them work\nVirtuoso in Linux\n\nGo to this\nlink\nand download the application. Extract it in a folder and run the install.sh script.\nGo to\nhttp://localhost:8890/sparql\nto check that everything went all right.\nIf you go to\nhttp://localhost:8890\nit will redirect you to the admin console. There you can import new graphs and see which ones you have already in your database.\nVirtuoso in Windows\n\nFollow the steps in the tutorial made by Boris:\nhttp://virtuoso.openlinksw.com/dataspace/dav/wiki/Main/VOSUsageWindows\nDownload:\nhttp://sourceforge.net/projects/virtuoso/files/virtuoso/6.1.2/virtuso-opensourcewin32-6.1.2.zip/download\nODBC Registration: Set up VIRTUOSO_HOME variable pointing out to virtuoso-opensource directory:\ncd %VIRTUOSO_HOME%\\lib\nregsvr32 virtodbc.dll\nCreating a Windows Service\ncd %VIRTUOSO_HOME%\\database\nSET PATH=%PATH%;%VIRTUOSO_HOME%\\bin;%VIRTUOSO_HOME%\\lib\nvirtuoso-t -? //to verify\nvirtuoso-t +service screate +instance \"Instance Name\" +configfile virtuoso.ini\nvirtuoso-t +service list //to verify\nvirtuoso-t -I \"Instance Name\" +service start //start the service\nVirtuoso Web Admin Tool (conductor)\nhttp://localhost:8890/conductor\nInstalling Pubby\n\n(The same installation steps are necessary for Windows and Linux).\nYou need Apache Tomcat in order to make Pubby work. It can be downloaded from\nhere\nYou only need to extract the folder anywhere you want.\nStart the Tomcat (go to /bin and execute the startup.bat (Windows) or startup.sh (linux)).\nOpen your browser and go to\nhttp://localhost:8080\nto check that the tomcat works fine.\nThen you have to download pubby from\nhere\n. Extract the files in a new folder.\nCopy Pubby's \"webApp\" folder into the Apache Tomcat's \"webapps\" folder. It must be renamed (e.g. pubby).\nEdit Pubby's configuration file. It is located in webapps/<Name of your pubby folder>/WEB-INF/config.n3 The extension of the file may vary depending on the version of Pubby.\nThe Pubby Configuration File\n\nIn this file you must point pubby to your endpoint, your \"index resource\" (the one which will be shown by default) and the ontology base URI\nExample file, where:\nThe Pubby folder is called \"LUF\"\nThe test index resource of the ontology is\nhttp://www.semanticweb.org/ontologies/2010/6/Ontology1279014806237.owl#Pizza_2\nThe datasetBase is:\nhttp://www.semanticweb.org/ontologies/2010/6/Ontology1279014806237.owl\nIdeally, the resources' URIs should be the same as the the given in the server\n# Prefix declarations to be used in RDF output.\nPut the prefixes from your ontology here\n@prefix conf: <\nhttp://richard.cyganiak.de/2007/pubby/config.rdf#\n> .\n@prefix meta: <\nhttp://example.org/metadata#\n> .\n@prefix rdf: <\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#\n> .\n@prefix rdfs: <\nhttp://www.w3.org/2000/01/rdf-schema#\n> .\n@prefix xsd: <\nhttp://www.w3.org/2001/XMLSchema#\n> .\n@prefix owl: <\nhttp://www.w3.org/2002/07/owl#\n> .\n@prefix dc: <\nhttp://purl.org/dc/elements/1.1/\n> .\n@prefix dcterms: <\nhttp://purl.org/dc/terms/\n> .\n@prefix foaf: <\nhttp://xmlns.com/foaf/0.1/\n> .\n@prefix skos: <\nhttp://www.w3.org/2004/02/skos/core#\n> .\n@prefix geo: <\nhttp://www.w3.org/2003/01/geo/wgs84_pos#\n> .\n@prefix dbpedia: <\nhttp://localhost:8080/resource/\n> .\n@prefix p: <\nhttp://localhost:8080/property/\n> .\n@prefix yago: <\nhttp://localhost:8080/class/yago/\n> .\n@prefix units: <\nhttp://dbpedia.org/units/\n> .\n@prefix geonames: <\nhttp://www.geonames.org/ontology#\n> .\n@prefix prv:      <\nhttp://purl.org/net/provenance/ns#\n> .\n@prefix prvTypes: <\nhttp://purl.org/net/provenance/types#\n> .\n@prefix tags: <\nhttp://www.holygoat.co.uk/owl/redwood/0.1/tags/\n> .\n@prefix rev: <\nhttp://purl.org/stuff/rev#\n> .\n# Server configuration section\n<> a conf:Configuration;\n   # Project name for display in page titles\n   conf:projectName \"Linked User Feedback example\";\n   # Homepage with description of the project for the link in the page header\n   conf:projectHomepage <\nhttp://localhost:8080\n>;\n   #\nThe Pubby root, where the webapp is running inside the servlet container.\nconf:webBase <\nhttp://localhost:8080/LUF/\n>;\n   # URL of an RDF file whose prefix mapping is to be used by the\n   # server; defaults to <>, which is *this* file.\n   conf:usePrefixesFrom <>;\n   # If labels and descriptions are available in multiple languages,\n   # prefer this one.\n   conf:defaultLanguage \"en\";\n   # When the homepage of the server is accessed, this resource will\n   # be shown.\nconf:indexResource\n<\nhttp://www.semanticweb.org/ontologies/2010/6/Ontology1279014806237.owl#Pizza_2\n>;\n# Dataset configuration section #1 (for DBpedia resources)\n#\n# URIs in the SPARQL endpoint:\nhttp://dbpedia.org/resource/*\n# URIs on the Web:\nhttp://localhost:8080/resource/*\nconf:dataset [\n# SPARQL endpoint URL of the dataset\nconf:sparqlEndpoint <\nhttp://localhost:8890/sparql\n>;\n# Default graph name to query (not necessary for most endpoints)\n       # conf:sparqlDefaultGraph <\nhttp://dbpedia.org\n>;\n       # Common URI prefix of all resource URIs in the SPARQL dataset\n       conf:datasetBase <\nhttp://www.semanticweb.org/ontologies/2010/6/Ontology1279014806237.owl\n>;\n       # Will be appended to the conf:webBase to form the public\n       # resource URIs; if not present, defaults to \"\"\n       # conf:webResourcePrefix \"resource/\";\n       # Fixes an issue with the server running behind an Apache proxy;\n       # can be ignored otherwise\n       conf:fixUnescapedCharacters \"(),'!$&*+;=@\";\n       conf:queryPrefix '\nDEFINE sql:describe-mode \\\"CBD\\\"'\n;\n# include metadata\n       # conf:metadataTemplate \"metadata.n3\";\n# configure your metadata here\n       # Use properties with the meta: prefix where the property name\n       # corresponds to the placeholder URIs in metadata.n3 that begin\n       # with about:metadata:metadata:\n       # Examples for such properties are:\n#        meta:pubbyUser <URI of the data publisher who uses this Pubby>;\n#        meta:pubbyOperator <URI of the service provider who operates this Pubby>;\n#        meta:endpointUser <URI of the data publisher who uses the SPARQL endpoint queried by this Pubby>;\n#        meta:endpointOperator <URI of the service provider who operates the SPARQL endpoint>;\n   ];\nYou may also want to add more than one endpoint. Just add another \"dataset block\":\n#conf:dataset [\n# SPARQL endpoint URL of the dataset\n       #conf:sparqlEndpoint <\nhttp://mccarthy.dia.upm.es:8890/sparql\n>;\n       # Default graph name to query (not necessary for most endpoints)\n       #conf:sparqlDefaultGraph <\nhttp://mccarthy.dia.upm.es/upmlod\n>;\n       # Common URI prefix of all resource URIs in the SPARQL dataset\n       #conf:datasetBase <\nhttp://mccarthy.dia.upm.es/\n>;\n       # Will be appended to the conf:webBase to form the public\n       # resource URIs; if not present, defaults to \"\"\n       #conf:webResourcePrefix \"resource/\";\n       # Fixes an issue with the server running behind an Apache proxy;\n       # can be ignored otherwise\n       #conf:fixUnescapedCharacters \"(),'!$&*+;=@\";\n# include metadata\n       # conf:metadataTemplate \"metadata.n3\";\n# configure your metadata here\n       # Use properties with the meta: prefix where the property name\n       # corresponds to the placeholder URIs in metadata.n3 that begin\n       # with about:metadata:metadata:\n       # Examples for such properties are:\n#        meta:pubbyUser <URI of the data publisher who uses this Pubby>;\n#        meta:pubbyOperator <URI of the service provider who operates this Pubby>;\n#        meta:endpointUser <URI of the data publisher who uses the SPARQL endpoint queried by this Pubby>;\n#        meta:endpointOperator <URI of the service provider who operates the SPARQL endpoint>;\n#    ];\n   .\nNota: muy importante poner \"DEFINE sql:describe-mode \"CBD\"\", ya que eso hace que el pubby / Virtuoso no muestre solo los datos del grafo del recurso, sino que busque en todos los grafos. MUY útil si tenemos los metadatos de un recurso en un grafo, en otro su localización y en otro su descripción.\nWe have highlighted the fields which have to be modified in orther to make pubby work.\nPubby Configuration in the virtual server\n\nJust like it's done with the sparql endpoint, the ProxyPass and ProxyPassReverse must be configured in the virtual server created for a specific domain. For instances, let's take aemet domain. In the configuration of its virtual server, the following lines must be entered for Pubby to work properly:\nProxyPass /resource\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/resource\nProxyPass /page\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/page\nProxyPass /static\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/static\nProxyPass /data\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/data\nProxyPass /ontology\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/ontology\nProxyPassReverse /resource\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/resource\nProxyPassReverse /page\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/page\nProxyPassReverse /static\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/static\nProxyPassReverse /data\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/data\nProxyPassReverse /ontology\nhttp://localhost:8181/pubby-0.3.3-aemet.linkeddata.es/ontology\nFor each option, /resource, /page, /static, etc, there are two lines, ProxyPass and ProxyPassReverse, both of them pointing to the location of the pubby instance created for the domain.\nData cleansing\n\nTools:\nGoogle Refine:\nhttp://code.google.com/p/google-refine/\nExtension RDF (\nhttp://lab.linkeddata.deri.ie/2010/grefine-rdf-extension/\n)\nVisualization\n\nNetBeans details for configuration:\nHow to reduce the number of permutations for development:\nIn the file map4rdf.gwt.xml add:\n<set-property name=\"user.agent\" value=\"gecko\"/>\n<set-property name=\"locale\" value=\"en\"/>\nThis makes Netbeans to compile just de permutations for firefox in english (instead of every one).\nIn the pom.xml file, add on the gwt-maven-plugin:\n<draftCompile>true</draftCompile>\nTO DO List\n\nVocabulary reusing Metoffice\nScript to check the files from the repository\nBoris has to introduce Nor2O to everyone\nExtend Nor2O to read the .csv from AEMET.\nComplete the tutorial on the Pubby configuration file: load some rdf to Virtuoso, and access it form Pubby successfully.\nTutorial on Nor2O (Nor2O for dummies)\nResearch on special character on Pubby (accents, ñ, etc).\nHow to publish new contents in the visualizer made by Alex, Miguel Angel and Boris.\nScovo for statistics\nRegister AEMET's domain\nVisualizador: Feedback y cosas a hacer tras la primera versión\nQue la interfaz se asemejara en el blurb que aparece más a lo que se muestra en sensors.ijs.si o en la propia AEMET para esos mismos datos.\nQue en la parte de facetas no apareciera ese texto tan feo, sino algo más centrado en estaciones o algo así\nLo ideal sería poder mostrar que como resultado de una consulta (dime las estaciones que han tenido más de x litros por metro cuadrado en los últimos días) se muestre esto en el mapa (esa es la que no es fácil hacer ahora mismo con la información que se proporciona si no se trata de alguna manera.\nSpark o Widgets de google para ver gráficas.\nColor de las chinchetas según la temperatura, viento, etc. Se puede hacer con una sparql query simple.\nNext Week - 25/02/2011\n\nDaniG&Mora\nDocumentar el proceso de uso de NOR2O\nGhis&Maria\nOntologia\nIdafen&Dani\nProbar el visualizador\nSole&DaniV\nAnalizar los datos con GoogleRefine\nNext Week - 18/03/2011\n\nOscar\nNos pasa el documento que le pasaron los de AEMET\nMaria&Boris&Ghis&Pablo&Mikel\nTerminar modelo básico el lunes (depende disponibilidad de Boris)\nInteractuar para la generación del modelo\nAñadir la ssn y alinear con el modelo actual.\nMora\nCambiar el script para generar el RDF siguiendo el modelo básico de María&Ghis\nPasar a rdflib para automatizar  y que no haya fallos.\nGenerar ya la información de las estaciones\nDaniV&Sole\nMirar el tema del cleansing\nAlcazar\nCrear el dominio aemet.linkeddata.es\nDani&Idafen\nSubir el RDF generado y el modelo.\nVisualizador: intentar ver gráficas de diezminutales. LightBox con los datos de la observacion actual\nRoadmap\nSecond iteration\n\nMiguel Ángel and Mora\nSet the generation and automate the load of an RDF file in the server every 10 minutes.",
  "speaker": "SYSTEM",
  "uuid": "9ba17502-8f34-4fa2-8c32-c28063de61c0"
}