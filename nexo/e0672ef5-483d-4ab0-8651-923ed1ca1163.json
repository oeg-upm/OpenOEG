{
  "message": "SYSTEM: OntologyDebugging_KCAP2009.pdf: Página 1\nTowards a Set of OWL Ontology Debugging Guidelines\nCatherine Roussey \nUniversité de Lyon CNRS  \nUniversité Lyon 1, LIRIS \nUMR5205 \nVilleurbanne, France \ncatherine.roussey@liris.cnrs.fr \nOscar Corcho \nOntology Engineering Group. \nDepartamento de Inteligencia \nArtificial. Universidad Politécnica \nde Madrid Spain \nocorcho@fi.upm.es \nLuis Manuel Vilches \nBlázquez \nOntology Engineering Group. \nDepartamento de Inteligencia \nArtificial. Universidad Politécnica \nde Madrid, Spain \nlmvilches@ fi.upm.es\n \nABSTRACT \nDebugging inconsistent OWL ontologies is normally a tedi-\nous and time-consuming task where a combination of on-\ntology engineers and domain experts is often required to \nunderstand whether the changes performed are actually \ndealing with formalisation errors or changing the intended \nmeaning of the original knowledge model. Debugging ser-\nvices included in existing ontology engineering tools aid in \nthis task. However, in complex cases they are still far from \nproviding adequate support to ontology developers, due to \ntheir lack of efficiency or precision when explaining the \nmain causes for inconsistencies. We claim that it is possible \nto provide additional guidelines to these users, based on the \nidentification of common antipatterns and an adequate de-\nbugging strategy, which can be combined with the use of \nthese tools in order to make this task more effective.  \nCategories and Subject Descriptors \nI.2.4 Knowledge Representation Formalisms and Methods – \nrepresentation languages  \nGeneral Terms \nDesign, Languages, Verification  \nKeywords \nOWL, ontology, debugging, antipattern \n1. INTRODUCTION \nOntology engineering methodologies describe the sets of \nactivities to be carried out for ontology building, together \nwith methods and techniques that can be applied to them. \nAmong these activities, those of ontology formalisation and \nimplementation appear in most methodologies, since the \nfinal objective is to obtain one or several ontologies that \ndescribe the domain according to the ontology requirement \nspecifications provided in the early stages of development.  \nFormalisation and implementation activities have different \ndegrees of difficulty, considering the knowledge representa-\ntion formalism and ontology language selected, and the \nontology requirements, among others. It is not the same to \nformalise and implement an RDF(S) ontology than an OWL \nontology. Nor is it the same to develop a small OWL ontol-\nogy where only primitive concepts are needed than a net-\nwork of ontologies where defined concepts are extensively \nused and complex inferences have to be drawn upon. \nThese degrees of difficulty can be somehow transitively \napplied to most of the tasks in which these activities can be \ndecomposed, one of which is ontology debugging. There \nare no studies about how difficult it is nor about how much \neffort it takes to debug an ontology (not even in approaches \nlike ONTOCOM [8]). Taking into account the experience \nfrom debugging in software engineering and in knowledge \nrepresentation systems, we can intuitively assume that this \nis one of the most effort-consuming tasks. Therefore any \nhelp for ontology developers for this task will be probably \ntranslated into a reduction in the effort and time required to \nobtain results, and a better quality of the results.  \nIf we focus on description logic formalisation and OWL \nimplementation, several debugging tools exist ([4,5]). \nThese tools isolate as much as possible the axioms “respon-\nsible” for inconsistencies, and find the roots of inconsis-\ntency problems, which are then propagated throughout the \nconcept hierarchy. These tools have proven their effective-\nness, but are still far from optimal in the provision of ade-\nquate explanations about the reasons for inconsistencies and \nin the proposal of alternatives to resolve the identified con-\nflicts. To illustrate this, we experienced with early versions \nof a medium-sized OWL ontology developed by a domain \nexpert in the area of hydrology [15], consisting of 150 \nclasses, 34 object properties and 66 datatype properties1. \nThe first version generated by a group of experts had a total \nof 102 unsatisfiable classes. The debugging systems used \n([4,5]) did not provide enough information about root un-\nsatisfiable classes or adequate (e.g., understandable by do-\nmain experts) justifications of the reasons for their unsatis-\nfiability. And in several occasions during the debugging \nprocess the generation of justifications for inconsistencies \ntook several hours, what made these tools hard to use. As a \nresult, we found out that in several occasions domain ex-\nperts were just changing axioms from the original ontology \nin a somehow random manner, even changing the intended \nmeaning of the real definitions instead of correcting errors \nin their formalisations. \nWe made an effort to understand common inconsistency-\nleading patterns used by domain experts when implement-\n                                                           \n1 This early version of the ontology is available at \nhttp://www.dia.fi.upm.es/~ocorcho/OWLDebugging/, \ntogether \nwith some of the most relevant intermediate versions of such \nontology as domain experts were debugging it. \n",
  "speaker": "SYSTEM",
  "uuid": "e0672ef5-483d-4ab0-8651-923ed1ca1163"
}