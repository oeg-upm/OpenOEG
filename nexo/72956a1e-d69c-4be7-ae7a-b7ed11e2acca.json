{
  "message": "SYSTEM: OEG_submission_SSN2014.pdf: Página 1\nPushing Sensor Observations for\nRDF Stream Processing - Short Paper\nAlejandro Llaves, Javier D. Fern´andez, and Oscar Corcho\nOntology Engineering Group, Universidad Polit´ecnica de Madrid, Madrid, Spain\n{allaves,jdfernandez,ocorcho}@fi.upm.es\nAbstract. This paper describes ongoing research on the development\nof a scalable RDF streaming engine. Preparing a dataset for evaluat-\ning a stream processing engine is sometimes an underestimated time-\nconsuming task. We explain here the diﬀerent steps for cleaning, mod-\nelling, and transforming a historical dataset about earthquake observa-\ntions in Spain into a dynamic RDF stream. At the end, we propose open\nquestions related to the eﬃcient processing of RDF streams from the\nSensor Web.\n1\nIntroduction\nOur current research deals with the design and implementation of an engine that\nallows eﬃcient processing of complex queries over heterogeneous data streams\nin near real-time. Data streams may come from multiple sources, being Sensor\nWeb sources the most common ones. During the last years, Sensor Web tech-\nnologies were established as the technological foundations to allow publishing,\nupdating, and accessing sensor data streams [3]. Sensors may range from en-\nvironmental ones, normally with slow rate frequencies, to sensors monitoring\nindustrial processes, producing millions of measurements per second.\nThere is a growing number of applications that depend on the usage of real-\ntime environmental data, and which need to complement the usual three levels\nof decision making (strategic, tactical, and operational) with real-time decision\nmaking. One example would be oil prospecting monitoring, where decisions on\nthe maintenance of a extraction plant may be made on short time slots based on\nthe combination of a set of spatio-temporal data streams coming from diﬀerent\nproviders, e.g. seismic activity or weather information. Getting information from\nthese streams is complex because of the heterogeneity of the data, the rate of\ndata generation, and the data volume. To tap these data sources accordingly\nand get relevant information, scalable processing infrastructures are required, as\nwell as eﬃcient approaches to enable data integration and fusion.\n2\nExtending morph-streams\nThis work is an extension of previous research on ontology-based access to data\nstream sources [4,6,5]. Morph-streams, see ﬁgure 1, is a system that allows query-\n",
  "speaker": "SYSTEM",
  "uuid": "72956a1e-d69c-4be7-ae7a-b7ed11e2acca"
}