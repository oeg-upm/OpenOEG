{
  "message": "SYSTEM: 2216-LT2013_Report_20130408.pdf: Página 44\n42\nwww.lt‐innovate.eu ‐ contact@lt‐innovate.eu\nAlthough early 90’s represented incremental and critically important progress in practical application for\ndeveloping both voice‐independent speech recognition and synthesis technologies, during this year’s speech\ntechnologies  still were facing big challenges. Speech technologies strongly depended on the user training of\nthe system; which was a very high‐consuming process. Users recording needed to be associated manually to\nphonetic or spelling combinations and still produced voices sounded very artificial and not human natural.\nIt was not until late 90`s that large scale voice recognition and unified messaging are seen, when companies\nstarted to invest in Computer Telephony Integration (CTI) with IVR systems; which became vital for call cen‐\ntres. Speech recognition vendors focused on small niches such as customer services with basic speech‐recog‐\nnition applications which understanding caller requests and respond to spoken prompts under limited\nacceptable options (e.g. voice activated dialling, call routing, etc.). Universal queuing and routing solutions\nstarted to be widely deployed in call centres as they acted as an agent collecting customer data and enabling\nintelligent routing decisions. \nCurrently sophisticated applications can accept widely varied and highly complex caller requests, enabling\nfully automated transactions or customer self‐service —‐ for example, accepting payments and entertain‐\nment ticketing, banking transactions, or collecting personal information. In fact, nearly every industry seg‐\nment (communications, financial services, government, healthcare, retail, travel and tourism, etc.) has now\nimplemented automated speech dialog at some level, from simple call routers to fully automated self‐serv‐\nice and even purchase/transaction applications. \n4.2 Speech Input or Automatic Speech Recognition\nSpeech input applications convert spoken language in text or machine‐readable format and they are also\nknown as Speech Recognition, Automatic Speech Recognition (ASR), Computer speech recognition, Speech‐\nto‐Text (STT), or even sometimes known in the market as voice recognition, natural language interface, even\nnatural language understanding. Natural Language Interface is more often used to describe environments\nthat integrate speech and semantic information ‐ making reference to some underlying model of “knowl‐\nedge” for Natural Language Understanding (NLU) ‐ rather than pure speech recognition, though these dis‐\ntinctions are increasingly blurred in the interest of marketing.\nCommercially available speech recognition technology is behind applications such as voice user interfaces\nsuch as phone services (e.g. voice dialling such as saying «Call home» to our cell phone, simple data entry\nsuch as entering a credit card number), dictation and preparation of structured documents (e.g., a radiolo‐\ngy report), speech‐to‐text processing (e.g., word processors or emails), and aircraft (usually termed Direct\nVoice Input). \nThus this technology appeals to a wide range of users going from organisations seeking for enhanced per‐\nsonal productivity in automated commercial phone systems to anyone who needs or wants a hands‐free\napproach to computing tasks or communicate.\nThe ultimate goal of automatic speech recognition technology is to deliver speaker independent speech\nrecognition services that not require (or requires a minimum) user training, and which can be used and per‐\nforms well with multiple users and under all conditions.\nThe terms «speech recognition» and «speaker recognition» are sometimes confused. Speaker recognition is\nthe task of validating a user’s claimed identity using characteristics extracted from a speaker’s voice. Thus\nwe need to differentiate between speaker recognition (recognizing who is speaking) and speech recognition\n(recognizing what is being said). \nThese two terms are also frequently confused, as is voice recognition. Voice recognition sometimes is used\n",
  "speaker": "SYSTEM",
  "uuid": "007f1aec-0e15-48ea-bbbf-7e971ce3c891"
}