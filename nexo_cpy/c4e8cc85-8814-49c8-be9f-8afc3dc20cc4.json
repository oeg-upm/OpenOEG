{
  "message": "SYSTEM: Wiki: https://delicias.dia.fi.upm.es/wiki/index.php/Espa%C3%B1aVirtual21012010 \n\nContents\n[\nhide\n]\n1\nTareas 7.2\n2\nInterfaz Anotación Híbrida\n3\nTarea 2.4\n4\nTarea 1.4\n5\nTarea 7.1\nTareas 7.2\n\nTarea 1. Mecanismo de extracción de semántica a partir de anotaciones\n.\nSe ha seguido trabajando en la actividad\nProcesamiento lingüístico páginas wikipedia en Español\nresolviendo errores y problemas que se encontraron mientras se hacia pruebas de unidad y que se detallan en cada sub-actividad:\nSub-actividades:\n- Servicio de acceso a las paginas Wikipedia:\nAvance 100%.\nSe detecto un problema de compatibilidad de set de caracteres al cargar el código html de las páginas wikipedia. Las paginas wikipedia usan UTF-8, mientras java usa UNICODE, de acuerdo a la documentación no debe haber ningun problema al leer UTF-8 en java ya que este internamente realiza la conversión. Sin embargo, al obtener los tokens a partir del html se detectaron caracteres invalidos que generaban excepciones y terminaban la ejecución.\nEl problema se soluciono utilizando otra clase que lee la página web como un\nstream\nde\nbytes\ny luego lo convierte a\nString\nusando UTF-8 como set de caracteres.\n- Procesamiento lingüístico usando GATE\nAvance 100%\nDebido al problema descrito anteriormente cuando se procesaba recursivamente algunas cadenas de caracteres se generaba una excepción de StackOverFlow. Esto era debido a que las cadenas eran muy largas y los procesos recursivos se llamaban tantas veces que llenaban la pila de java. Se decidió cambiar estos métodos e implementarlos iterativamente.\n- Creación de repositorio de información lingüística\nAvance 100%\nSe esta almacenando y recuperando información del repositorio de significados en la base de datos postgres.\nPor otra parte, se ha detectado una actividad no incluida en el cronograma de preprocesamiento inicial de la etiqueta. Este método debe analizar una etiqueta y llevarla a la versión estándar wikipedia, es decir, que todas las palabras empiecen con mayúscula, que si es una palabra compuesta el separador sea un \"_\".\nTarea 2. Procesado de fuentes de información no semántica ya existentes\n.\nTarea 3. Modelo de anotación híbrido\n.\nTarea: Patrones de reconocimiento básicos para su uso en desambiguación.\n- A pesar del avance de la semana anterior el servicio web de anotador sigue fallando.Durante esta  semana se ha estado indagando sobre los fallos y se han detectado los siguientes problemas: la configuración del fichero de inicialización ha tenido que volver a ser revisada, los parámetros de entrada/ salida del servicio puede no ser los más adecuados, la codificación de las páginas web y su procesamiento no es la correcta ya que se producen fallos a la hora de entregar las SOAP Responses. Es decir, aunque se están anotando las páginas, las respuestas pueden ser vistas pero no procesadas posteriormente por una máquina.\nSubtarea:Gazetteers\n- La tarea relacionada con las ontologías sigue en proceso. Se ha estado buscando la forma de incluirlo en el servicio web.\n- En lo relacionado con la anotación en español por parte de TreeTagger  ha habido avances.Se han incluido los paquetes necesarios y se quiere usar cono un PR. En estos momentos se está intentando acoplar con el servicio web existente. Un problema que ha surgido es la incapacidad de recoger los token obtenidos de un proceso anterior para su etiquetado. Se tratará de incluir el proceso en una aplicación completa y se probará el funcionamiento durante los próximos días.\nInterfaz Anotación Híbrida\n\nImplementación con código PHP.\n- Se esta reescribiendo toda la aplicacion con PHP con el framework yii que esta bajo el patron MVC.\n- El framework presenta funcionalidades como las solicitadas, gestión de widgets, gestión de usuarios e internacionalización.\nPruebas de conexión via web services.\n- Se han hecho las pruebas y son satisfactorias con Web services funcionando desde php a cualquier tecnología incluso se ha testeado con los web services de geobuddies.\nWidgets JQuery.\n- Se ha agregado los widgets Jquery UI para generar todos los widgets con yii framework\nRecursos.\n- yii framework para desarrollo de aplicaciones en PHP bajo MVC\n[1]\n.\n- Extensión JUI (agregar Widgets Jquery UI) para yii\n[2]\n.\n- Extensión SOAP PHP, para establecer comunicación via Web Services debe activarse en el php.ini\n[3]\n.\n- Herramienta que genera las clases necesarias en PHP apartir de un fichero wsdl para facilitar la tarea de web Services\n[4]\n.\nTarea 2.4\n\nDiseño del primer prototipo\n- Estudio y elección de las ontologías que servirán de base para la descripción de los planificadores locales. Se esta procediendo a su modificación para adaptarlas al modelo de nuestro sistema, en el que cada planificador local tendrá una especialización adaptada de una ontología común. Esta ontología base será la siguiente:\nhttp://unigrids.org/2006/05/ontology/base-grid-ontology/\nde la cual ya existen especializaciones para Globus y Unicore\nhttp://unigrids.org/2006/05/ontology/globus-ontology\nhttp://unigrids.org/2006/05/ontology/unicore-ontology\nA estas onotologías se añadirá información acerca del sistema operativo de los recursos y de la arquitectura de la maquina, que se considera pueden ser de interés para la planificación. Partiendo de esto, se creará una nueva ontología para el middleware Fura.\n- Elección de JSDL como lenguaje de codificación para el envío de trabajos a los planificadores. En esta primera fase no se hará uso de todo el potencial del lenguaje, quedándonos solo con los elementos necesarios para el primer prototipo:\n-JobDefinition\n -JobDescription\n   -JobIdentification\n     -JobName\n     -Description\n   -Application\n     -ApplicationName\n     -ApplicationVersion\n     -Description\n   -Resources\n     -FileSystem\n     -OperatingSystem\n     -CPUArchitecture\n     -IndividualCPUSpeed\n     -IndividualCPUTime\n     -IndividualCPUCount\n     -IndividualDiskSpace\n     -TotalResourceCount\n   -DataStaging\n     -FileName\n     -FileSystemName\n     -CreationFlag\n     -DeleteOnTermination\n     -Source\n     -Target\n- Se ha decidido incluir un módulo de planificación para el middleware Fura, ya que este no proporciona ninguno per se. Esta decisión responde a la necesidad de equiparar a Fura con el resto de middleware grid y es un requisito indispensable para poder metaplanificar. Este planificador elegirá el recurso (grupo cola) que ofrezca menor estimación de tiempo de inicio.\nTarea 1.4\n\nSubtarea 2.2.4. Técnica 11\n: Identificación y descripción de la nueva Técnica 11 para la consideración de valores de los atributos tipo como partes principales de búsqueda en la técnica 3.\nTarea 7.1\n\n- Generación de EndPoints para evaluación de RDF generado a través de consultas SPARQL.\n- Detección en el proceso de evaluación de errores de calidad en la generación de RDF. Estos errores se centran en las bases de datos del ICA y NGCE. Los errores detectados son producto de la codificación de las instancias [nombre instancia, tipo fenómeno].\n- Revisión de la codificación R2o para intentar solventar los problemas detectados.",
  "speaker": "SYSTEM",
  "uuid": "c4e8cc85-8814-49c8-be9f-8afc3dc20cc4"
}