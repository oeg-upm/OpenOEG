{
  "message": "SYSTEM: Eswc2010webofdatatrack_submission_2.pdf: Página 6\nside. Based on this information the optimizer chooses the best operator/site to \nexecute each part of the query plan. \n• \nTwo step optimization. This technique is based on two optimization cycles, done \nat compile and execution time. At compile time the initial query plan is \ngenerated, specifying joins, selections, projections and other operators. At the \ntime of actual execution, the query plan is optimized again using annotations \navailable at each data source site, taking into account their current status.  \n3 A SQL-based distributed query processor for SPARQL \nIn this section we describe our approach for executing SPARQL queries over \ndistributed RDF datasets, based on the theoretical results discussed in section 2.1 and \nthe usual DQP architecture described in section 2.2. We describe first our simple \nextension to SPARQL (SPARQL-D), so as to support distributed dataset querying. \nThen we describe our approach to generating basic query plans, the optimizations \nselected and the execution of the final and optimized data workflow, focusing on the \nmost relevant components from Figure 1. For an easier understanding of our approach \nwe show the walkthrough of a sample SPARQL-D query in our system. \n3.1 SPARQL extension for distributed data querying \nOne of the first issues that we have had to tackle in our approach is the identification \nof the datasets to which the SPARQL queries will be sent, which is basic for query \npartitioning. Different systems follow different approaches to specify where triples \nmay be coming from in this distributed setting. Some of them extend SPARQL and \nuse configuration files to describe the RDF datasets to access each namespace, others \nuse a pure Linked Data approach, considering that URIs should be dereferenceable, \nand others use a registry of data sources with a summary of their content so that \nqueries can be partitioned adequately taking into account this information, which may \nbe also available in the voID10 data attached to the dataset. \nWe have decided to follow an approach similar to the one proposed in DARQ: \nextend the SPARQL language to allow specifying the source of each namespace. This \nextension (SPARQL-D) consists in allowing several FROM clauses in the SPARQL \nquery, where each of these FROM clauses identifies the RDF resources to be \naccessed. While this is a restricted approach, we consider that it is not too relevant for \nthe time being for our approach, since the major contributions are on the query \ntransformation and optimization steps. In the future we plan to provide more \nflexibility, considering the use of an ad-hoc registry of sources or a general-purpose \nsearch engine (e.g., Watson11, Sindice12, etc.) to locate the sources that can provide \nresults for query parts, and considering that URIs belonging to a namespace may be \ncoming from different data sources. \n                                                           \n10 http://rdfs.org/ns/void-guide \n11 http://watson.kmi.open.ac.uk/ \n12 http://sindice.com/ \n",
  "speaker": "SYSTEM",
  "uuid": "0a0aef2b-5f99-4e83-ae37-6a2ccdf8125b"
}