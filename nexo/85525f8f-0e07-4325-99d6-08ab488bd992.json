{
  "message": "SYSTEM: Wiki: https://delicias.dia.fi.upm.es/wiki/index.php/Espa%C3%B1aVirtual11022010 \n\nContents\n[\nhide\n]\n1\nTareas 7.2\n2\nInterfaz Anotación Híbrida\n3\nTarea 2.4\n4\nTarea 1.4\n5\nTarea 7.1\nTareas 7.2\n\nTarea 1. Mecanismo de extracción de semántica a partir de anotaciones\n.\nSe ha finalizado la etapa de desarrollo de la tarea Adaptación del servicio de desambiguación en español.\nComo se informo previamente se han presentado múltiples problemas en el proceso de desarrollo. El ultimo encontrado durante esta semana fue un\nbug\n(\nhttp://netbeans.org/bugzilla/show_bug.cgi?id=66983\n) del servidor de aplicaciones\nglassfish\nque se utiliza para publicar el servicio web.\nEl servicio de desambiguación de etiquetas en español está disponible en una versión beta:\n1. Página web para realizar pruebas:\nhttp://robinson.dia.fi.upm.es:8080/LocalSemanticTags/faces/DisambiguationService.jsp\n2. WSDL del Servicio web ofrecido:\nhttp://robinson.dia.fi.upm.es:8080/LocalSemanticTags/SemanticTagsService?WSDL\nel nombre de la operación/método es\ndisambiguation\nSe modificará el cronograma de actividades para incluir actividades relacionadas con la instalación del servicio en un servidor debido a que actualmente se encuentra instalado en un ambiente de desarrollo. Entre estas actividades se tiene la instalación de la base de datos, la carga de datos de dbpedia en español y en ingles, la instalación del servidor SPARQL joseki, la instalación del glassfish y el deployment de la aplicación.\nObservaciones:\n1. En este momento se tiene cargada una versión de sept. del 2009 de la dbpedia en español por lo cual algunas definiciones extraídas de la dbpedia pueden resultar vacías.\n2. Cuando se procesa una etiqueta que antes no había sido procesada, la aplicación extrae la correspondiente información de wikipedia, luego realiza el\nparsing\npara extraer los términos y posteriormente almacena la información en la base de datos, para finalmente ejecutar el proceso de desambiguación. Como es natural el proceso toma una cantidad considerable de tiempo (+/- 12 sg) la primera vez que se analizan las paginas wikipedia asociadas a una etiqueta. Cuando esta información ya está en la base de datos el tiempo de ejecución baja notablemente. Se va a analizar la posibilidad de incluir una tarea en el cronograma para realizar un proceso de carga inicial de paginas wikipedia con el fin de disminuir los tiempos de ejecución.\nTarea 2. Procesado de fuentes de información no semántica ya existentes\n. \nRecoleccion de servicios REST.\nPara preparar un experimento real del registro e invocacion de fuentes de datos, se esta recolectando fuentes de tipo REST. El proceso que se sigue es el siguiente:\n- En\nhttp://www.programmableweb.com/\nse procede a buscar servicios relacionados con el dominio GEO.\n- Con cada uno de los servicios encontrados se realiza pruebas manuales para verificar la disponibilidad del servicio.\n- Si la fuente funciona correctamente se registra en un fichero de excel. En este fichero esta detallado los atributos de entrada y salida de cada fuente. Esta informacion se obtiene leyendo la documentacion de cada fuente.\nTarea 3. Modelo de anotación híbrido\n.\nTarea: Patrones de reconocimiento básicos para su uso en desambiguación.\n- Se ha estado trabajando en los problemas de codificación de los recursos, servidor y servicios webs ya que existen incompatibilidades. Por ejemplo, la representación en UTF-8 es accesible por el servidor pero, sin embargo, no muestra los caracteres propios del español, ya que necesitan mayor espacio. Esta semana seguirá en proceso hasta su finalización.\n- Se ha instalado el servicio web sobre la máquina regulo. Se puede encontrar en\nhttp://regulo.dia.fi.upm.es:9090/GateWebAppl/AnotadorService?Tester\nSubtarea:Gazetteers\n- Se ha contactado con los responsables de la herramienta para resolver dudas de la instalación del analizador sobre la plataforma GATE. Actualmente existe un error de validez. La aplicación no es válida en un porcentaje mínimo que es suficiente para paralizar todo el proceso.\n- Se ha buscado la forma de extraer información más allá de los NE a partir de la anotación realizada. Se ha llegado a obtener agrupar por tipos los términos anotados. Es necesario seguir en esta línea para obtener más características relevantes de cada una de las palabras. Con esta información se podrá seguir enlazando con otros recursos y, por tanto, enriquecer el resultado.\nInterfaz Anotación Híbrida\n\n- Se ha modificado el resultado de las leyendas de la interfaz del resultado para hacerla mas agradable al usuario.\n- Siguen los problemas para agregar información dinamicamente en el iframe con Jquery, Se probo la alternativa de presentar los resultados en la misma página, pero esta solución presenta el problemas de los estilos css, se combinan y desordenan la posición estructurada de los componentes.\n- Se esta pensando como mostrar una nube de tags con los resultados en un widget.\n- Se sigue trabajando con el framework yii completamente en php, para agregar los componentes de gestión de usuarios, localización y gestión de los contenidos de anotación.\n- Se implementará una opción de descargar la pagina anotada, aun esta en investigación la forma de como hacerlo.\n- Existe la necesidad de saber si algun web service realizado por miembros del grupo pueda servir para integrar en el interfaz.\n- Se ha instalado la interfaz en el servidor regulo, con el dominio:\nhttp://regulo.dia.fi.upm.es/anotador\n, la interfaz no hace validación de momento en la página de inicio, para lanzar el proceso de anotación, debe insertarse una url valida y completa, es decir debe incluirse hasta el protocolo http y seleccionar las entidades que se desean buscar y anotar en la página de resultado.\n- Se ha propuesto incluir en la página de inicio un video demostrativo del demo, y cambiar el texto en la página de inicio mostrarla en un widget y en su lugar mostrar el video de la interfaz. Se empezará a hacer este detalle. Tambien la posibilidad de agregar un autocompletado de las url ingresadas, al menos guardando las direcciones utilizadas.\nTarea 2.4\n\nImplementación del primer prototipo usando Fura\n- Se ha terminado de implementar la primera versión de la ontología que dará soporte a la descripción de los  Planificadores Locales grid que habrán de ser usados. Se han desarrollado dos ontologías correspondientes a los dos niveles del sistema de metaplanificación.\n- Nivel Metaplanificador (planificador.owl): ontología genérica que describe los componentes de cualquier tipo de planificador local.\n   - Nivel Adaptador para FURA (fura.owl): ontología que describe los componentes del planificador local usando la terminología que define FURA.\nEntre ambas ontologías se he realizado un proceso de ontology matching que describe las correspondencias entre los diferentes componentes de ambas ontologías.\nTarea 1.4",
  "speaker": "SYSTEM",
  "uuid": "85525f8f-0e07-4325-99d6-08ab488bd992"
}