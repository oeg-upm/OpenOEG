{
  "message": "SYSTEM: ISWC2010_Andres_SemGroCrosLingFol.pdf: Página 9\nSemantic Grounding of Cross-Lingual Folksonomies\n9\nwanted to evaluate if the selection of the active context leads to better disam-\nbiguation results against using the whole set of tags in the context. Thus, we\nevaluated the following approaches for the semantic grounding of tags:\n– Baseline: Selection of the sense without a disambiguation activity.\n– Sem4Tags: For each sense we use the whole Wikipedia article as source for\nfrequent terms.\n– Sem4TagsAC: Same as Sem4Tags including the selection of the Active\nContext.\n– Sem4TagsAbs: For each sense we use the ﬁrst paragraph of the Wikipedia\narticle as source for frequente terms.\n– Sem4TagsAbsAC: Same as Sem4Tags Abs including the selection of the\nActive Context.\n4.1\nEvaluation Campaign\nWe engaged 41 evaluators in the evaluation campaign. Each of them had to\nevaluate a set of semantic associations20 generated by each approach, and for\nthat evaluators were presented with the top 5 semantic entities produced by each\napproach21. We made sure that each semantic association was evaluated by at\nleast three evaluators so that we can use those decisions taken by user majority.\nFor each tagging activity evaluators had to decide whether they were able\nto identify the semantics of the tag in that tagging activity. As context we pre-\nsented to them the picture along with the other tags the user used to annotate\nthe picture. If they were able to identify the tag meaning, we asked them to\nidentify the language of the tagging activity22. In addition, users indicated if\nthe tag correspond to a named entity (e.g., we were interested in organizations,\npeople, places, and products). Evaluators had to evaluate the semantics asso-\nciations according to their language selection. We presented to them the set of\nDBpedia resources (title and abstract) returned by all the approaches in the ﬁrst\n5 positions. They were asked to state if each DBpedia resource associated with\nthe tagging activity was highly related (HR), related (R), or not related (N).\n4.2\nMetrics\nTo evaluate the proposed approaches, we translate the semantic association be-\ntween social tags and DBpedia resources into an Information Retrieval (IR) task.\nRoughly speaking, the IR problem can be formulated as follows: given a (key-\nword based) query and a set of (text) documents, ﬁnd the subset of documents\nthat are relevant to the query. In general, a user submits a query to a search\n20 tuple of the form ⟨user, tag, photo, DBpedia resource, language⟩\n21 It is important to note that evaluators did not know where semantic associations\nwere coming from\n22 Currently, our approach starts by considering both English and Spanish as the lan-\nguages in which the tag may be available, since we do not necessarily know the\nlanguage in which a tag is written\n",
  "speaker": "SYSTEM",
  "uuid": "587ad2ab-e384-41e5-a88f-b87539f1937a"
}