{
  "message": "SYSTEM: NLP.Dissociating_language_and_thought_in_large_language_models.pdf: Página 40\n5. Building models that think like humans\nCurated data en diverse objective functions (1/2)\nLos enormes corpus lingüísticos “naturalísticos” de entrenamiento de los \nLLMs son insuficientes porque:\n• Sesgado hacia propiedades de bajo nivel del input => el \ncomportamiento del modelo cambia dependiendo del prompt.\n• Información sesgada: falta de CS y de eventos inusuales.\n• Incentiva aprender patrones de textos (con varios niveles de \nabstracción), pero limita la generalización out-of-distribution.\n* Además, la cantidad de datos para que emerjan capacidades no \nlingüísticas es absurdamente grande e ineficiente.\n",
  "speaker": "SYSTEM",
  "uuid": "f0cde12e-387b-41b5-ae08-d08b6c9cdb35"
}