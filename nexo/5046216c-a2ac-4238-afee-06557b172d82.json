{
  "message": "SYSTEM: Wiki: Contents\n[\nhide\n]\n1\nCaso de Uso\n2\nPlan de Trabajo\n3\nEjecución\n3.1\nPreliminares\n3.2\nInstalación local de repositorios de datos de prueba y de resultados\n3.2.1\nDesplegar el repositorio de pruebas\n3.2.2\nDesplegar el repositorio de resultados\n3.2.3\nPruebas del repositorio de datos de prueba y de resultados\n3.3\nDefinición de datos de prueba\n3.3.1\nPROBLEMAS ENCONTRADOS:\n3.3.2\nConsultas al repositorio de pruebas:\n3.3.3\nMejoras:\n3.4\nDefinición de ficheros de resultados\n4\nDefinición de tipo de herramienta en SEALS para el clasificador\n4.1\nClasificador desde la linea de comando\n4.2\nClasificador desde Java\n4.3\nWrapper para incluirlo en un SimpleTool de SEALS\n4.4\nInstalación del wrapper en la plataforma SEALS\n4.4.1\nInstalación de la plataforma SEALS\n4.4.2\nDeploy del wrapper simpleTool en el RES Worker\n4.5\nBPEL\n4.5.1\nResultados de la ejecución del Bpel\n5\nTiempos Reales de Ejecución\nCaso de Uso\n\nObjetivo\n: Usar la plataforma Seals para evaluar los algoritmos de clasificación de tweets basados en tópicos latentes descubiertos en la colección de mensajes.\nLos datos de entrada se componen de dos ficheros, uno con datos para entrenar el clasificador y otro con datos para su validación. Ambos ficheros contienen registros de la forma: <id, mensaje, evento, clase>, donde id es el identificador numérico, mensaje es el tweet, evento es el evento relacionado con el tweet, y clase es el tipo asignado manualmente por un usuario.\nLos datos de salida se almacenarán en un único fichero que se corresponde con el fichero de validación al que se le ha adicionado una columna con la clase asignada por el clasificador.\nPara evaluar un clasificador se utilizan métricas como precisión,\nrecall\ny la medida f. Algunas veces se define un umbral que se usa para decidir si el resultado del clasificador se acepta o no. En estos casos se suele reportar los mejores resultados de evaluación, de acuerdo a una de las medidas, usando un determinado umbral.\nVariaciones\n:\nUsualmente los algoritmos de clasificación son evaluados con una técnica conocida como\ncross-validation\n. Esta técnica sirve para evaluar como los resultados del clasificador se pueden generalizar a un conjunto de datos independiente.  Los datos son divididos en k subconjuntos, k-1 subconjuntos son usados como datos de entrenamiento y 1 un subconjunto como datos de validación. El clasificador es entrenado y validado con estos conjuntos de datos. El proceso se repite k veces, de tal forma que cada subconjunto sea usado al menos una vez como datos de validación. Finalmente los resultados de las k ejecuciones son promediados. Así al usar cross-validation se tendrían dos posibilidades:\nGenerar automáticamente todas las evaluaciones con sus respectivos datos de entrenamiento y datos de validación.\nQue el clasificador se encargue de hacer el cross-validation con lo cual se  tendría una única evaluación, con un único conjunto de datos prueba.\nLos algoritmos de clasificación pueden recibir parámetros que modifican su comportamiento. En procesos de evaluación sería interesante ver que versión del clasificador definida por los parámetros de entrada tiene un mejor desempeño.\nPlan de Trabajo\n\nEl plan de trabajo se ha divido en etapas con el objetivo de ir incrementando gradualmente la complejidad de los procesos que se han de llevar a cabo.  En la primera etapa se va a trabajar con los conjuntos de datos en su versión actual, es decir ficheros csv. En esta primera etapa los clasificadores  no deberán ser modificados. En la segunda etapa se trabajará con conjuntos de datos representados en RDF, y por tanto los clasificadores deberán ser modificados para recibir y producir ficheros en este lenguaje. Además se pretende introducir parámetros que modifiquen el clasificador. Finalmente en una tercera etapa se implementará el proceso de evaluación usando cross-validation. El plan de trabajo se evaluará semanalmente y los objetivos serán revisados de acuerdo al avance semanal.\nLa primera etapa tendrá como objetivo definir la evaluación (proceso, datos de entrada y resultados a obtener) así como añadir un nuevo tipo de herramienta al\nRuntime Evaluation Service\nque de soporte al uso del clasificador. Esta etapa consta de las siguientes fases y actividades:\nDefinir test data sets:\nCrear repositorio local para datos de prueba – (Andrés, Miguel Ángel)\nDefinir estructura de los test data sets y de los metadatos asociados (Andrés, Raúl)\nCrear test data sets siguiendo la estructura definida (Andrés)\nRegistrar los conjuntos de datos de prueba - (Andrés, Miguel Ángel)\nDefinir resultados:\nCrear repositorio local de resultados – (Miguel Ángel)\nDefinir estructura de los resultados así como de los metadatos asociados – (Andrés, Raúl)\nDefinir interpretación de los resultados – (Andrés)\nDefinir nuevo tipo de herramienta para el clasificador:\nDefinir interfaz del clasificador (datos de entrada + parámetros de configuración) (Andrés, Miguel)\nEmpaquetar el clasificador:\nImplementar\ntool wrapper\n(Andrés)\nCrear\ntool package\npara el wrapper (Andrés, Miguel)\nImplementar cliente parar verificar la validez del\ntool package\nusando las utilidades del\nRuntime Evaluation Service\n(Andrés, Miguel)\nIntegrar nuevo tipo de herramienta en\nRES Worker\n:\nDefinir interfaz de servicio para el uso del clasificador en el\nRES Worker\n(Andrés, Miguel)\nImplementar extensión del\nRES Worker\npara el uso del clasificador según la interfaz de servicio anterior (Miguel)\nVerificar funcionamiento del clasificador en\nRES Worker\nlocalmente:\nDesplegar localmente el\nRES Worker\ny la extensión para el uso del clasificador (de manera que se use la instancias locales de los repositorios de datos y resultados) (Andrés, Miguel)\nDesplegar\ntool package\nen el\nRES Worker\nlocal (Andrés, Miguel)\nImplementar pruebas de integración usando\nSoapUI\npara verificar la ejecución del clasificador vía\nRES Worker\n(Andrés, Miguel)\nCrear evaluación:\nDiseñar proceso de evaluación (Andrés)\nImplementar proceso como un workflow\nBPEL\n(Andrés, Miguel)\nValidar el workflow\nBPEL\nusando\nApache ODE 1.3.5\n(Andrés, Miguel)\nCrear\nevauation description\n(Andrés, Miguel)\nIntegrar nuevo tipo de herramienta en\nRES Core\n:\nImplementar extensión del\nRES Core\npara el uso del clasificador según la interfaz de servicio anterior (Miguel)\nVerificar funcionamiento de la evaluación en\nRES Core\nlocalmente:\nDesplegar localmente el\nRES Core\ny la extensión para el uso del clasificador (Andrés, Miguel)\nDesplegar\nevaluation description\nen el\nRES Core\nlocal (Andrés, Miguel)\nImplementar pruebas de integración usando\nSoapUI\npara verificar la ejecución de la clasificador vía\nRES Core\n, mockeando el RES Worker (Andrés, Miguel)\nEjecución local de la evaluación con el clasificador a través del\nRuntime Evaluation Service\n:\nImplementar proyecto\nSoapUI\npara lanzar ejecuciones de la evaluación con el clasificador (Andrés, Miguel)\nPuesta en producción:\nDesplegar repositorio de datos en entorno de preproducción de SEALS (Equipo SEALS)\nDesplegar repositorio de resultados en entorno de preproducción de SEALS (Equipo SEALS)\nDesplegar RES y extensiones para el uso del clasificador en entorno de preproducción de SEALS (Equipo SEALS)\nVerificación del entorno de producción (Andrés, Equipo SEALS)\nDesplegar\ntool package\nen el\nRES Worker\n(Andrés, Equipo SEALS)\nDesplegar\nevaluation description\nen el\nRES Core\n(Andrés, Equipo SEALS)\nRegistrar datos de prueba en el repositorio de datos (Andrés, Equipo SEALS)\nClonar el proyecto\nSoapUI\npara lanzar ejecuciones de la evaluación con el clasificador usando el entorno de producción (Andrés, Miguel)\nLa segunda etapa consistirá en ejecutar las evaluaciones usando el\nSEALS Service Manager\nsin virtualización. Esta etapa consta de las siguientes fases y actividades:\nEmpaquetar evaluación:\nDefinir vocabulario para la evaluación (Andrés, Nandana, Miguel)\nImplementar\nevaluation description descriptor'\nItalic text\n(Andrés, Nandana, Miguel)\nCrear\nevaluation description bundle\n(Andrés, Nandana, Miguel)\nValidar evaluación empaquetada usando el\nSEALS Service Manager\nlocalmente:\nDesplegar localmente el\nSSM ES\n(Andrés, Nandana)\nDesplegar localmente el\nSSM IMS\n(Andrés, Nandana)\nConfigurar\nSSM IMS\npara que no use virtualización (Andrés, Nandana)\nConfigurar el\nSSM ES\npara que use el\nevaluation description bundle\n(Andrés, Nandana)\nImplementar pruebas de integración usando\nSoapUI\npara verificar el uso de la evaluación empaquetada vía\nSSM ES\n, mockeando\nRES Core\ny repositorio de datos (Andrés, Nandana)\nEjecución local de la evaluación con el clasificador a través del\nSEALS Service Manager\n:\nImplementar proyecto\nSoapUI\npara lanzar ejecuciones de la evaluación con el clasificador (Andrés, Nandana)\nPuesta en producción:\nDesplegar el\nSSM ES\nen entorno de preproducción de SEALS (Nandana)\nDesplegar el\nSSM IMS\nen entorno de preproducción de SEALS (Nandana)\nVerificación del entorno de producción (Andrés, Equipo SEALS)\nConfigurar\nSSM IMS\npara que no use virtualización (Andrés, Nandana)\nConfigurar el\nSSM ES\npara que use el\nevaluation description bundle\n(Andrés, Nandana)\nClonar el proyecto\nSoapUI\npara lanzar ejecuciones de la evaluación con el clasificador (Andrés, Nandana)\nLa tercera etapa consistirá en ejecutar las evaluaciones usando el\nSEALS Service Manager\nusando virtualización. Esta etapa consta de las siguientes fases y actividades:\nPreparación de la imagen para el clasificador:\nCreación de una máquina virtual en\nVMWare vSphere\n(Andrés, Alcázar)\nDesplegar\nRES Worker\nen la máquina virtual (Andrés)\nConfigurar\nRES Worker\npara que use los repositorios del entorno de producción (preproducción de SEALS) (Andrés)\nDesplegar\ntool package\nen el\nRES Worker\n(Andrés)\nVerificación de la instalación usando material anterior (Andrés)\nPuesta en producción:\nConfigurar\nSSM IMS\npara que no use la imagen de la herramienta (Andrés, Nandana)\nClonar el proyecto\nSoapUI\npara lanzar ejecuciones de la evaluación con el clasificador desplegado en la imagen (Andrés, Nandana)\nDe manera adicional se proponen la mejora del clasificador para el consumo y generación de datos en RDF en vez de CSV, así como la aplicación del proceso de cross-validation mediante el desarrollo y uso de un mecanismo para el registro automático de datos de prueba así como de generación de peticiones de ejecución que usen dichos datos de prueba. Será necesario así mismo desarrollar de un cliente que se encargue de realizar la agregación de los resultados generados explotando los resultados de las ejecuciones. La planificación y ejecución de estas mejoras está supeditada al progreso en las tres etapas mencionadas anteriormente.\nEjecución\n\nPreliminares\n\nLos casos de prueba deberían definirse teniendo en cuenta que cuando se quiera adicionar uno nuevo los cambios a los casos de prueba existentes sean mínimos o inexistentes. Sin embargo en muchos casos es prácticamente imposible porque un nuevo caso de prueba afecta a todos los casos existentes.\nSe debería incluir una figura donde se relacionen las clases de la ontología (PersitentTestData, TestDataVersion, Suite, SuiteItem, DataItem)con la terminología real para la definición de las evaluaciones evaluación (Evaluación, Versión de la evaluación, Conjunto de casos de prueba, Caso de prueba, Datos del caso de prueba).\nLo mismo debería hacerse para relacionar las clases de los datos de prueba en la ontología con las clases que describen los resultados y las interpretaciones.\nInstalación local de repositorios de datos de prueba y de resultados\n\nNota importante 1:\nVerificar la versión de los repositorios de datos de prueba y de resultados porque dependen de la versión del runtime evaluation service que se vaya a usar mas adelante en el proceso. En mi caso instale el repositorio 1.1b y era necesaria la versión 1.1 así que tuve que reinstalar el repositorio. Dependiendo de la versión se utilizan unas propiedades u otras de la ontología en los servicios web que dan accesos al repositorio de resultados (Ver\nConsultas al repositorio de pruebas\n).\nNota importante 2:\nEn el bpel al final del proceso me enteré que la propiedad hasComponentType de la ontología se utiliza para recuperar uno a uno los diferentes data items en el conjunto de datos de prueba (testSuite). Esta cuestion esta relacionada con el punto anterior porque dependiendo de la versión del repositorio se utilizan diferentes propiedades para acceder a los data items.  Verificar con Miguel esteban y Raul.\nLa instalación se realizó utilizando las guías proporcionadas en:\na PDF file\nSoftware\nJava SE Development Kit 6 update 18. En mi ordenador tengo instalada la versión 6_17 y voy a probar con ella para ver si no da problema.\n(No requerido para los repositorios) SVN client. Ya instalado en mi ordenador\n(No requerido para los repositorios) Maven 2.2.1 (Pendiente de instalar)\nMiddleware\n(No requerido para los repositorios)Fuse ESB 4.2.0-fuse-02-00. La versión requerida de fuse no se encuentra disponible en la pagina oficial. Encontré el instalador en el siguiente enlace (Pendiente de instalar):\nhttp://repo.fusesource.com/maven2/org/apache/servicemix/apache-servicemix/4.2.0-fuse-02-00/\nApache Tomcat 6.0.264\nOpenRDF SDK 2.2.4 que incluye a Sesame y Workbench.\nConfiguración de la variable de entorno ENV a D:\\SEALS\\environment, en este directorio va todo el middleware.\nEjecutar tomcat y desplegar sesame y workbench en el servidor web:\nTomcat requiere la variable de entorno BASEDIR que apunta al directorio principal de tomcat.\nmodificar fichero BASEDIR/conf/tomcat-users.xml y añadir la siguiente linea entre las etiquetas <tomcat-users> y </tomcat-users>:\n<user username=\"admin\" password=\"admin\" roles=\"manager-gui\"/>\nejecutar BASEDIR/bin/startup.bat\nir a\nhttp://localhost:8080/\ny seleccionar la opción tomcat manager. Usar como usuario y password a admin y admin\ndesplegar sesame y workbench usando los ficheros .war que se encuentra en ENV/openrdf-sesame-2.2.4/war\nDesplegar el repositorio de pruebas\n\nbajar y desplegar en tomcat:\nhttp://www.development.seals-project.eu/artifactory/global-repo/eu/sealsproject/platform/repos/tdrs-web/1.1-b/tdrs-web-1.1-b.war\n. El despliegue consiste en copiar este fichero war a la carpeta %TOMCAT%\\webapps\ncrear repositorio en OpenRDF Sesame. Ir a\nhttp://localhost:8080/openrdf-workbench/\ny seleccionar new repository. Datos del repositorio id testdata, Type: Native Java Store RDF Schema, y Triple indexes: spoc, posc, cpso\nconfigurar el repositorio de datos pruebas\nEditar fichero: %TOMCAT%\\webapps \\tdrs-web-1.1-b\\WEB-INF\\classes\\config.properties y modificar variables de acuerdo a la guía.\nCrear las siguientes carpetas:\nD:\\SEALS\\environment\\repositories\\testdata\nD:\\SEALS\\environment\\repositories\\testdata\\generators\nD:\\SEALS\\environment\\repositories\\testdata\\temp\nD:\\SEALS\\environment\\repositories\\testdata\\testdatasets\nDesplegar el repositorio de resultados\n\nbajar y desplegar en tomcat:\nhttp://www.development.seals-project.eu/artifactory/global-repo/eu/sealsproject/platform/repos/rrs-web/1.1-b/rrs-web-1.1-b.war\ncrear repositorio en OpenRDF Sesame. Ir a\nhttp://localhost:8080/openrdf-workbench/\ny seleccionar new repository. Datos del repositorio id results, Type: Native Java Store RDF Schema, y Triple indexes: spoc, posc, cpso\nconfigurar el repositorio de resultados\nEditar fichero: %TOMCAT%\\webapps \\tdrs-web-1.1-b\\WEB-INF\\classes\\config.properties y modificar variables de acuerdo a la guía\nCrear las siguientes carpetas:\nD:\\SEALS\\environment\\repositories\\results\nD:\\SEALS\\environment\\repositories\\results\\interpretations\nD:\\SEALS\\environment\\repositories\\results\\rawresults\nPruebas del repositorio de datos de prueba y de resultados\n\nPara probar el repositorio se usa el fichero de pruebas\na ZIP file\nque se encuentran en la página\nSEALSTestData#Usage\n. El proceso se divide en 2 etapas. Primero se registra la colección de datos de prueba y luego se adicionan los datos de prueba a esa colección.\nRegistrar colección de datos de prueba.\nModificar el fichero RegisterTestDataCollection.html cambiando la url en la etiqueta form, atributo action a:\nhttp://localhost:8080/tdrs-web-1.1-b/testdata/persistent/\nAbrir esa página y registrar el repositorio de ejemplo. Para esto se copia el contenido de OWLDLImportTestSuiteCollection.xml en el área de texto de la página y se hace el submit.\nNo hay ningún resultado, pero si se da nuevamente aceptar entonces dice que ya existe el repositorio.\nRegistrar datos de prueba\nModificar el fichero AddTestDataVersion.html cambiando la url en la etiqueta form, atributo action a:\nhttp://localhost:8080/tdrs-web-1.1-b/testdata/persistent/\nAbrir la pagina y copiar en el área de texto el contenido de OWLDLImportTestSuite1.0.xml, luego seleccionar el fichero de datos OWLDLImportTestSuite1.0.zip y hacer el submit.\nDefinición de datos de prueba\n\nPara realizar esta definición se siguen las guías proporcionadas en: [\n[1]\n]\nEn esta primera iteración se definen los datos de prueba manualmente. La colección de datos de prueba se definió con el siguiente RDF:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n   <rdf:RDF\n    xmlns:rdfs=\"\nhttp://www.w3.org/2000/01/rdf-schema#\n\"\n    xmlns:rdf=\"\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#\n\"\n    xmlns:seals=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#\n\"\n    xmlns:dcterms=\"\nhttp://purl.org/dc/terms/\n\">\n       <seals:PersistentTestData>\n           <seals:hasName rdf:datatype=\"http:/www.w3.org/XMLSchema#string\">Categorized Theatre Tweets</seals:hasName>        \n           <dcterms:identifier>Theatre+Tweets+Categorized+ADV+EXP+OPI+01</dcterms:identifier>\n           <dcterms:description>This test data suite collection contains tweets manually categorized as advertisement, expectation, opinions and others</dcterms:description>      \n       </seals:PersistentTestData>\n   </rdf:RDF>\nEste rdf se envía al\nrepositorio de datos de prueba\nal hacer una llamada post al servicio\nhttp://localhost:8080/tdrs-web-1.1-b/testdata/persistent/\ndonde el rdf se incluye en el contenido de la variable metadata.\nMUY IMPORTANTE:\nla propiedad\nseals:hasName\nno debería incluir caracteres como \":\" dado que este texto es usado para crear la uri que identifica la colección.\nla primera versión de los datos se definió con el siguiente RDF:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n   <rdf:RDF xmlns:seals=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#\n\"\n    xmlns:rdfs=\"\nhttp://www.w3.org/2000/01/rdf-schema#\n\" \n    xmlns:dcterms=\"\nhttp://purl.org/dc/terms/\n\"\n    xmlns:rdf=\"\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#\n\">\n       <seals:TestDataVersion>\n           <dcterms:identifier>Theatre+Tweets+Categorized+ADV+EXP+OPI+01+V01</dcterms:identifier>\n           <seals:hasName>Categorized Theatre tweets V1.0</seals:hasName>\n           <seals:hasVersionNumber rdf:datatype=\"http:/www.w3.org/XMLSchema#string\">1.0</seals:hasVersionNumber>\n           <seals:hasChangeDescription>First version</seals:hasChangeDescription>\n           <dcterms:description>Version 1.0:theatre tweets manually categorized as advertisement, opinions, expectations and others</dcterms:description>\n       </seals:TestDataVersion>\n   </rdf:RDF>\nLos datos de prueba están almacenados en el fichero data.zip que contiene lo siguiente:\n\\metadata.rdf\n   \\data\n   \\data\\cirque_topics.csv\n   \\data\\cirque_topics_nlp.csv\n   \\data\\matilda_topics.csv\n   \\data\\matilda_topics_nlp.csv\n   \\data\\merrily_topics.csv\n   \\data\\merrily_topics_nlp.csv\n   \\data\\spamalo_topics.csv\n   \\data\\spamalo_topics_nlp.csv\n   \\data\\thelion_topics.csv\n   \\data\\thelion_topics_nlp.csv\nMUY IMPORTANTE:\nseals:hasVersionNumber\neste numero de version va a ser parte de una url que va a permitir acceder a el conjunto de datos de prueba así que no debería contener caracteres no permitidos en urls.\nEste conjunto de datos de prueba consiste de dos casos de prueba: un caso de prueba donde los tweets son modelados solo con tópicos (ficheros terminados en topics.csv) y el otro donde los tweets son modelados adicionalmente con características derivadas de anotaciones lingüísticas (ficheros terminados en nlp.csv). Así el conjunto de datos de prueba se modela como un\nseals:Suite\ny cada caso de prueba como un\nseals:SuiteItem\n. Los ficheros de prueba en si se modelan como\nseals:DataItem\nque se asocian con el correspondiente\nseals:SuiteItem\nque represente el caso de prueba al que pertenecen.\nEsta definición de casos de prueba se realizó teniendo en cuenta que evaluar una nueva técnica, como por ejemplo usar TF-IDF para representar los tweets, no implicará cambios en el resto de los casos de prueba. Sin embargo, adicionar un nuevo musical como fuentes de tweets implicaría modificar todos los casos de prueba existentes.\nLa definición del conjunto de datos de prueba se describe en el fichero metadata.rdf que se presenta a continuación:\n<rdf:RDF\n       xmlns:rdf=\"\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#\n\"\n       xmlns:seals=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#\n\"\n       xmlns:dc=\"\nhttp://purl.org/dc/terms/\n\"\n       xmlns:monnet=\"\nhttp://www.seals-project.eu/ontologies/MonnetSuite.owl#\n\"\n       xmlns:xsd=\"\nhttp://www.w3.org/2001/XMLSchema#\n\" > \n     <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#TheatreTweetsSuit\n\">\n       <seals:hasSuiteItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01\n\"/>\n       <seals:hasSuiteItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02\n\"/>\n       <dc:identifier>TheatreTweetsSuit</dc:identifier>\n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#Suite\n\"/>     \n     </rdf:Description>\n     <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01\n\">\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file01\n\"/>\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file02\n\"/>\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file03\n\"/>\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file04\n\"/>\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file05\n\"/>\n       <dc:identifier>suite item 01</dc:identifier>\n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#SuiteItem\n\"/>\n     </rdf:Description> \n     <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file01\n\">\n       <seals:isLocatedAt>./data/cirque_topics.csv</seals:isLocatedAt>\n       <dc:identifier>cirque_topics_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description>\n     <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file02\n\">\n       <seals:isLocatedAt>./data/matilda_topics.csv</seals:isLocatedAt>\n       <dc:identifier>matilda_topics_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description>\n     <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file03\n\">\n       <seals:isLocatedAt>./data/merrily_topics.csv</seals:isLocatedAt>\n       <dc:identifier>merrily_topics_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description>  \n   <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file04\n\">\n       <seals:isLocatedAt>./data/spamalo_topics.csv</seals:isLocatedAt>\n       <dc:identifier>spamalo_topics_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description>    \n   <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase01file05\n\">\n       <seals:isLocatedAt>./data/thelion_topics.csv</seals:isLocatedAt>\n       <dc:identifier>thelion_topics_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description> \n   <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02\n\">\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file01\n\"/>\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file02\n\"/>\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file03\n\"/>\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file04\n\"/>\n       <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file05\n\"/>\n       <dc:identifier>suite item 02</dc:identifier>\n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#SuiteItem\n\"/>\n     </rdf:Description> \n       <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file01\n\">\n       <seals:isLocatedAt>./data/cirque_topics_nlp.csv</seals:isLocatedAt>\n       <dc:identifier>cirque_topics_nlp_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description>\n     <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file02\n\">\n       <seals:isLocatedAt>./data/matilda_topics_nlp.csv</seals:isLocatedAt>\n       <dc:identifier>matilda_topics_nlp_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description>\n     <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file03\n\">\n       <seals:isLocatedAt>./data/merrily_topics_nlp.csv</seals:isLocatedAt>\n       <dc:identifier>merrily_topics_nlp_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description>  \n   <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file04\n\">\n       <seals:isLocatedAt>./data/spamalo_topics_nlp.csv</seals:isLocatedAt>\n       <dc:identifier>spamalo_topics_nlp_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description>    \n   <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es/TheatreTweets#testcase02file05\n\">\n       <seals:isLocatedAt>./data/thelion_topics_nlp.csv</seals:isLocatedAt>\n       <dc:identifier>thelion_topics_nlp_01</dc:identifier>\n       <seals:hasComponentType>source</seals:hasComponentType>    \n       <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\" />\n     </rdf:Description> \n   </rdf:RDF>\nFinalmente esta versión de los datos de prueba se subió al repositorio ejecutando una llamada http post al siguiente servicio\nhttp://localhost:8080/tdrs-web-1.1-b/testdata/persistent/Categorized+Theatre+Tweets/\n.\nEs en esta llamada donde hace el enlace entre la colección de datos de prueba y la versión de los datos de prueba\n. La url contiene al final el nombre de la colección que se corresponde con la la propiedad\nseals:hasName\nde la colección. Es por esto que esta propiedad (seals:hasName) no debería tener caracteres especiales. El rdf que describe la versión de los datos se envia en la variable metadata y el fichero zip se envia en la variable\ndata\nque es de tipo\nfile\n.\nMUY IMPORTANTE:\nEl valor de\ndc:identifier\nen la descripción de un\nseals:SuiteItem\nva a ser utilizado en una url que permite acceder a los datos de la suite así que no debería contener caracteres no permitidos en una url.\nEl valor de\ndc:identifier\nen la descripción de un\nseals:DataItem\nva a ser utilizado en una url que permite acceder a los ficheros del caso de prueba así que no debería contener caracteres no permitidos en una url.\nPROBLEMAS ENCONTRADOS:\n\nTuve muchos problemas siguiendo algunos de los ejemplos proporcionados debido a que no es claro donde se hace el enlace entre la versión de los datos y la colección.\nTambién tuve problemas porque no sabia que la propiedad hasName iba a ser el identificador de la colección. Pensé que era metadata y que podia contener cualquier cadena de caracteres.\nDe acuerdo a esta frase \"Please note, that, although, the test data represents a test suite, it is not describing using the Suite Ontology but using a ontology defined in WP10.\" no esta claro los datos de prueba se deben especificar con la ontologia del WP10, o si opcionalmente también se pueden describir con la Suite Ontology.\nTampoco sabia como se borran colecciones y versiones del repositorio?\nPara borrar colecciones se debe usar el sesame workbench (\nhttp://localhost:8080/openrdf-workbench/\n), seleccionar el repositorio testdata y borrar el correspondiente contexto con la opción\nclear\n.\nConsultas al repositorio de pruebas:\n\nOjo: depende de la versión del repositorio.\nRecuperar el RDF que describe el conjunto de casos de prueba (i.e., suite)\nhttp://.../tdrs-web/testdata/persistent/\n[collection name]/[version number]/suite/\ndonde [collection name] es el valor de\nseals:hasName\nasociado a la colección, y [version number] es el valor de\nseals:hasVersionNumber\nasociado a la versión de los datos. Así la url resultante es:\nhttp://localhost:8080/tdrs-web-1.1-b/testdata/persistent/Categorized+Theatre+Tweets/1.0/suite/\nRecuperar un data item (fichero de datos de prueba):\nhttp://seals.sti2.at/tdrs-web/testdata/persistent/\n[collection name]/[version number]/suite/[suite item identifier]/item/[item identifier]/\ndonde [collection name] y [version number] se definen de la manera descrita previamente y [suite item identifier] es el valor de\ndc:identifier\nasociado al test case (\nseals:SuiteItem\n) e [item identifier] es el valor de\ndc:identifier\nasociado al fichero de pruebas (\nseals:DataItem\n). Así la url es:\nhttp://localhost:8080/tdrs-web-1.1-b/testdata/persistent/Categorized+Theatre+Tweets/1.0/suite/suite+item+01/item/cirque_topics_01\nMejoras:\n\nSi se quiere hacer un dump del rdf de las pruebas para luego hacer consultas SPARQL las instancias de TestDataVersion y Suite deberian tener el mismo URI. Sin embargo esta relación no existe en la ontología.\nLa relación entre persistentTestData y TestDataVersion no esta explicita en la ontología. Esta relación solo es evidente en la URL de creación y de acceso a los datos de prueba.\nDefinición de ficheros de resultados\n\nPara la definición de los resultados de la evaluación se ha extendido la ontología de Seals de tal manera que permitiera representar el caso de prueba del que provienen los resultados (SuitItem), el clasificador que se uso en la prueba, el tipo de evaluación que se realizo al clasificador (cross-validation, Percentage Split, training y testing), así como los valores asociados a las métricas de evaluación (precision, recall, f-measure).\nLa ontología se describe a continuación en formato turtle:\n@prefix xsd: <\nhttp://www.w3.org/2001/XMLSchema#\n> .\n  @prefix owl: <\nhttp://www.w3.org/2002/07/owl#\n> .\n  @prefix : <\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#\n> .\n  @prefix xml: <\nhttp://www.w3.org/XML/1998/namespace\n> .\n  @prefix rdf: <\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#\n> .\n  @prefix rdfs: <\nhttp://www.w3.org/2000/01/rdf-schema#\n> .\n  @base <\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl\n> .\n  \n  <\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl\n> rdf:type owl:Ontology ;                                                                       \n                                                                      rdfs:label [ ] ;\n  \n  owl:imports <\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl\n> .\n    \n  #################################################################\n  #    Object Properties\n  #################################################################\n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#generatedFromDataItem\n:generatedFromDataItem rdf:type owl:ObjectProperty ;\n                         rdfs:domain :ClassifierResultItem ;\n                         rdfs:range <\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n> .\n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#generatedFromSuitItem\n:generatedFromSuitItem rdf:type owl:ObjectProperty ;\n                         rdfs:domain :ClassifierResult ;\n                         rdfs:range <\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#SuiteItem\n> .\n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#hasClassifierResultItem\n:hasClassifierResultItem rdf:type owl:ObjectProperty ;                            \n                           rdfs:domain :ClassifierResult ;\n                           rdfs:range :ClassifierResultItem .\n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#hasEvaluationType\n:hasEvaluationType rdf:type owl:ObjectProperty ;                      \n                     rdfs:range :ClassifierEvaluationType ;                      \n                     rdfs:domain :ClassifierResult .\n  \n  #################################################################\n  #    Data properties\n  #################################################################  \n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#hasFMeasureValue\n:hasFMeasureValue rdf:type owl:DatatypeProperty ;                     \n                    rdfs:domain :ClassifierResultItem ;                     \n                    rdfs:range xsd:double .\n        \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#hasPrecisionValue\n:hasPrecisionValue rdf:type owl:DatatypeProperty ;\n                     rdfs:domain :ClassifierResultItem ;\n                     rdfs:range xsd:double .\n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#hasRecallValue\n:hasRecallValue rdf:type owl:DatatypeProperty ;\n                  rdfs:domain :ClassifierResultItem ;\n                  rdfs:range xsd:double .\n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#usedClassifier\n:usedClassifier rdf:type owl:DatatypeProperty ;\n                  rdfs:domain :ClassifierResult ;\n                  rdfs:range xsd:string .  \n  \n  #################################################################\n  #    Classes\n  #################################################################   \n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#ClassifierEvaluationType\n:ClassifierEvaluationType rdf:type owl:Class ;                             \n                            owl:equivalentClass [ rdf:type owl:Class ;\n                                                  owl:oneOf ( :PercentageSplit\n                                                              :ProvidedTestAndTrainingData\n                                                              :CrossValidation\n                                                            )\n                                                ] .\n        \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#ClassifierResult\n:ClassifierResult rdf:type owl:Class ;\n                    rdfs:subClassOf <\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#RawResult\n> .\n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#ClassifierResultItem\n:ClassifierResultItem rdf:type owl:Class .\n  \n  #################################################################\n  #    Individuals\n  #################################################################   \n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#CrossValidation\n:CrossValidation rdf:type owl:NamedIndividual .\n  \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#PercentageSplit\n:PercentageSplit rdf:type owl:NamedIndividual .\n     \n  ###\nhttp://robinson.dia.fi.upm.es/ontologies/ClassifierEvaluation.owl#ProvidedTestAndTrainingData\n:ProvidedTestAndTrainingData rdf:type owl:NamedIndividual .\nDefinición de tipo de herramienta en SEALS para el clasificador\n\nClasificador desde la linea de comando\n\nIncluir en el classpath el jar de weka\nset CLASSPATH=%CLASSPATH%;D:\\Program Files\\Weka-3-6\\weka.jar\nPara transformar un csv en un arff (ficheros que entiende weka) se debe ejecutar lo siguiente en la linea de comando.\njava weka.core.converters.CSVLoader cirque_topics.csv >> > cirque_topics.arff\nSe deben ignorar los mensajes que dicen que no se han podido cargar los controladores JDBC ya que no se usan en el proceso.\nEl ultimo atributo del fichero arff se asume que es la clase que se quiere predecir con los clasificadores.\nPara validar que el fichero arff esta bien y obtener estadisticas de uso usar:\njava weka.core.Instances cirque_topics.arff\nEjecución clasificador basico (ZeroR escoge la clase mas frecuente y se puede usar como baseline )con crossvalidation:\njava weka.classifiers.rules.ZeroR -t cirque_topics.arff\nPara ejecutar el clasificador usado en las pruebas:\njava -Xmx512m weka.classifiers.meta.ClassificationViaRegression -t cirque_topics.arff -i -o -x 10 -W weka.classifiers.trees.M5P -- -M 4.0 > classificationViaRegression.out &\n-t speciﬁes the training ﬁle (ARFF format)\n -T speciﬁes the test ﬁle in (ARFF format). If this parameter is missing, a crossvalidation will be performed (default: ten-fold cv)\n -x This parameter determines the number of folds for the crossvalidation. A cv will only be performed if -T is missing.\n -i A more detailed performance description via precision, recall, true- and false positive rate is additionally output with this parameter. \n -o This parameter switches the human-readable output of the model description oﬀ. In case of support vector machines or NaiveBayes, this makes some sense unless you want to parse and visualize a lot of information.        \n -M <minimum number of instances> Build regression tree/rule rather than a model tree/rule Set minimum number of instances per leaf (default 4)\n -p # outputs just the predictions for each test instance, along with a range of onebased attribute ids (0 for none)\n & starts the process in background\nUna vez ejecutado el clasificador se pueden extraer los valores de las metricas de evaluación:\ncygwin /cygdrive/c/Documents and Settings/hagarcia/Documents/NetBeansProjects/TimeOut/weka/classifierInputOutput/in-out\nPor ejemplo para obtener precision, recall y f-measure se deben ejecutar:\ngrep -A 19 \"Stratified\"  classificationViaRegression.out | grep \"^Weighted Avg\" | cut -c39-44\ngrep -A 19 \"Stratified\"  classificationViaRegression.out | grep \"^Weighted Avg\" | cut -c49-54\ngrep -A 19 \"Stratified\"  classificationViaRegression.out | grep \"^Weighted Avg\" | cut -c59-64\nClasificador desde Java\n\nIncluir en el pom.xml weka y jena:\n<dependency>\n                   <groupId>org.apache.jena</groupId>\n                   <artifactId>jena-tdb</artifactId>\n                   <version>0.10.1</version>\n               </dependency>\n               <dependency>\n                   <groupId>nz.ac.waikato.cms.weka</groupId>\n                   <artifactId>weka-stable</artifactId>\n                   <version>3.6.6</version>\n               </dependency>\nEl código para ejecutar el clasificador en java:\n//This method trains and evaluates the classifier using the input file which is defined with the input argument (urlInputFile)\n  public String executeClassifier(String urlInputFile) throws Exception{       \n      try{\n          // get the input file from the URL\n          InputStream input=download(urlInputFile);\n          //load the input file (csv) into a set of weka instances\n          CSVLoader loader = new CSVLoader();\n          loader.setSource(input);\n          Instances data = loader.getDataSet();\n          // setting class attribute if the data format does not provide this information\n          if (data.classIndex() == -1)\n             data.setClassIndex(data.numAttributes() - 1);\n           // create a new meta classifier\n           weka.classifiers.meta.ClassificationViaRegression scheme = new weka.classifiers.meta.ClassificationViaRegression();            \n           // set model trees as the classifier used in the meta classifier\n           scheme.setOptions(weka.core.Utils.splitOptions(\"-W weka.classifiers.trees.M5P -- -M 4.0\"));            \n           scheme.buildClassifier(data);\n           // set the evaluation type\n           Evaluation eTest = new Evaluation(data);\n           eTest.crossValidateModel(scheme,data,10,new Random(1));\n           String strSummary = eTest.toSummaryString();\n           logger.info(strSummary);\n           logger.info(eTest.toClassDetailsString());\n           logger.info(\"weighted precision:\"+eTest.weightedPrecision());\n           logger.info(\"weighted recall:\"+eTest.weightedRecall());\n           logger.info(\"weighted f-measure:\"+eTest.weightedFMeasure());\n           //creates an rdf representation of the evaluation resutls\n           String resultOntologyText= getResultOntology(eTest.weightedPrecision(),eTest.weightedRecall(),eTest.weightedFMeasure());\n           logger.info(resultOntologyText);\n           return resultOntologyText;\n       }\n      catch(Exception ex){\n           StringWriter errors = new StringWriter();\n           ex.printStackTrace(new PrintWriter(errors));\n           throw new ToolException(errors.toString());\n      }\n   }\npublic InputStream download(String url) throws IOException {\n       InputStream input = new URL(url).openStream();\n       return input;\n   }\nWrapper para incluirlo en un SimpleTool de SEALS\n\nSe decidió usar el SimpleTool que provee seals para la ejecución del clasificador en la plataforma. El simpleTool recibe un string como argumento de entrada y devuelve un string como un argumento de salida. Esta interfaz encaja perfectamente con el clasificador, la entrada es la url del fichero de entrada, y la salida es un string que contiene el rdf que describe los resultados de la evaluación.\nMiguel Esteban me envió un proyecto maven donde viene una implementación del SimpleTool. En este proyecto maven está la clase SimpleToolBridgeImpl dentro del paquete eu.sealsproject.platform.res.domain.itest.simple. Esta clase tiene el metodo execute con la siguiente firma:\npublic String execute(String parameter) throws ToolBridgeException, ToolException\nEs en este método donde se debe ejecutar el clasificador usando el fichero de instancias que se encuentra en la URL definida en el argumento de entrada\nparameter\n. El rdf que describe los resultados de la evaluación se devuelve en el string que retorna el método.\nclassifierEvaluator=new Classifier();\n           String evaluationResultOnto;\n           logger.info(String.format(\"invoked %s-%s (%s) %s::execute(%s)... \",this.getId(),this.getVersion(),this.getType(),this.getClass().getCanonicalName(),parameter));\n           //testFilePublisher();\n           if (parameter != null){\n               try{\n                   evaluationResultOnto=classifierEvaluator.executeClassifier(parameter, filePublisher);\n                   logger.info(String.format(\"  returning: %s\", evaluationResultOnto.toString()));\n                   return evaluationResultOnto.toString();\n               }\n               catch (ToolException tex){\n                   throw tex;\n               }\n               catch (Exception ex){\n                   StringWriter errors = new StringWriter();\n                   ex.printStackTrace(new PrintWriter(errors));\n                   throw new ToolBridgeException(errors.toString());\n               }\n           }\n           else {                \n               logger.info(\"  throwing tool bridge exception.\");\n               throw new ToolBridgeException(\"null parameter\");\n           }\nInstalación del wrapper en la plataforma SEALS\n\nNota Importante:\nVerificar la versión del runtime evaluation service (tanto core y worker) que se va a instalar. En mi caso tuve que reinstalar el res debido a que había instalado la versión 1.1 y se requeria la versión 2.0 snapshot. Preguntar a Miguel Esteban.\nInstalación de la plataforma SEALS\n\nPara instalar el wrapper en la plataforma SEALS primero hay que instalar el runtime evaluation service tanto el core como el worker. Esta instalación se realizó siguiendo las guías proporcionadas en el deliverable D9.3\nv2.0\nbeta Iterative Evaluation and Implementation of the runtime evaluation service. En general la instalación fue fácil aunque algunos componentes de software ya estan desactualizados y hay que buscar la versión correcta.\nPara poder ejecutar el test de integración hubo que aprender a usar el SOAP UI. Sin embargo al ejecutar el test de integración tuvimos diferentes problemas que resultaron ser de configuración y que nos llevo alrededor de 1 semana solucionar.\nLos errores empezaron por la versión del repositorio de datos de prueba\nque necesitaba una versión diferente (1.1) a la versión instalada (tdrs-web-1.1-b). El error se produjo al seguir las instrucciones de una presentación desactualizada.\nTambién hubo algunos problemas con los puertos utilizados por el res core y el worker. Para encontrar los problemas se siguieron los puertos 8080 y 1890 usando el tcpmon. Para esto se cambiaron estos puertos al 8081 y al 1891.\nEl seguimiento y solución de estos problemas fueron hechos por Miguel Esteban. Tardamos 3 días en solucionarlos.\nDeploy del wrapper simpleTool en el RES Worker\n\nPara hacer el deploy del wrapper se construye el proyecto maven donde está el codigo del SimpleTool. Esta construcción produce un fichero zip (res-itest-tool-1.2-tool-package.zip) en la carpeta target que debe descomprimirse en la carpeta SEALS/package/simple en el res worker. Hay que asegurarse que el fichero SEALS/package/simple/descriptor.xml contenga la siguiente linea (en caso contrario remplazar la existente con lo siguiente):\n<tpd:bridge>\n           <tpd:class>eu.sealsproject.platform.res.domain.itest.simple.SimpleToolBridgeImpl</tpd:class>\nPara probar que el simpleTool funcionará correctamente Miguel Esteban creó un test en el SOAP UI. Sin embargo este test fallo y por tanto se tuvo que realizar un proceso de debug del código. Para esto se uso el debuger de netbeans en un puerto 5005. Este proceso era nuevo para mi así que tuve que aprender a realizarlo. Este debug permitió identificar el problema en la clase FilePublisher que provee seals para publicar ficheros. Se concluyó que era un problema de configuración y fue solucionado.\nEn este proceso se detectó que el runtime evaluation service (1.1) utilizado no era el que se debia utilizar (2.0 snapshot). Así que fue necesario volver a realizar la instalación del res core y del res worker.\nLa ejecución del proyecto SOAP UI fue satisfactoria lo que permitió concluir que el wrapper funcionaba bien.\nTiempo: 4 días\nBPEL\n\nSe reutilizó el fichero bpel integration-testing-evaluation.bpel que viene en seals-res-2.0-SNAPSHOT\\examples\\ed\\res-itest-ed-ode-su\\src\\main\\resources. Se recomienda hacer una copia del directorio ed y trabajar sobre esa copia. Primero tuve que bajar un designer bpel para visualizar el workflow (eclipse designer). Tuve que leer un poco para entender los elementos tipicos de un bpel y posteriormente ser capaz de modificarlo.\nA modo de resumen el workflow descrito en el bpel consulta el repositorio de resultados e itera sobre los data items asociados al conjunto de resultados y la versión que se han especificado en la llamada al bpel. Esta llamada se realiza utilizando un proyecto SOAPUI. Para cada data item (URL) en el repositorio de resultados se ejecuta el SimpleTool que empaqueta una llamada al classificador. El classificador se entrena y se evalua automaticamente devolviendo en un string la ontología con los resultados de evaluación. Estos resultados de evaluación se almacena en una variable metadatos y se adiciona al paquete de resultados. Cuando finalizan los data items del conjunto de pruebas, se publica el paquete resultados en el repositorio de resultados. El fichero bpel se ilustra en la siguiente imagen y se puede descargar en el siguiente enlace\nFile:Integration-testing-evaluation.zip\nNota importante:\nLa propiedad hasComponentType en el conjunto de resultados se utiliza para discriminar entre data items. Así que cada data item debería tener un hasComponentType diferente por caso de prueba. Hablar con Raul y Miguel Esteban.\nUna vez modificado el bpel para que se adaptase a mis requerimientos seguía el deploy. Para hacer el deploy hay que abrir el proyecto maven que esta en seals-res-2.0-SNAPSHOT\\examples\\ed\\res-itest-ed-ode-su\\. Netbeans no fue capaz de abrirlo así que tuve que instalar eclipse JEE. Con eclipse depure el proyecto y lo construí generando el fichero res-itest-ed-sa-2.0-SNAPSHOT.zip en seals-res-2.0-SNAPSHOT\\examples\\res-itest-ed-sa\\target.  Este fichero tenia que desplegarse en el res core. Para esto en el res core (fuse console) hay que verificar si ya esta instalado el paquete correspondiente al integration test usando el comando osgi:list, una vez identificado el numero del bundle entonces desinstalarlo usando uninstall #bundle. Posteriormente hay que instalar el paquete:\ninstall -s file:///D:/SEALS/environment/seals-res-2.0-SNAPSHOT/examples/ed/res-itest-ed-ode-su/target/res-itest-ed-ode-su-2.0-SNAPSHOT.zip\nPara probar el bpel hay que usar el proyecto integrationTest (Res service 2.0) en el SOAP UI. Se recomienda clonar el proyecto existente y trabajar sobre el nuevo.\nResultados de la ejecución del Bpel\n\nEn el proyecto SOAPUI hay un mock service llamado legacy callback service que contiene propiedades que describen los posibles resultados de la ejecución del bpel: aborted, completed, failed. Si la ejecución ha sido correcta la propiedad completed debería tener como valor lo siguiente:\n<soap:Envelope xmlns:soap=\"\nhttp://schemas.xmlsoap.org/soap/envelope/\n\">\n     <soap:Header>\n        <Header xmlns=\"\nhttp://www.seals-project.eu/resources/res/common/header/xsd/v1\n\">\n           <header:Destination xmlns:header=\"\nhttp://www.seals-project.eu/resources/res/common/header/xsd/v1\n\">                \n           <header:HttpURI>\nhttp://127.0.0.1\n</header:HttpURI></header:Destination>  \n           <header:ExecutionRequestId xmlns:header=\"\nhttp://www.seals-project.eu/resources/res/common/header/xsd/v1\n\">\nurn:ere:f0233942-5886-380f-a5d6-847df31357b8\n</header:ExecutionRequestId>\n        </Header>\n     </soap:Header>\n     <soap:Body>\n        <completed xmlns=\"\nhttp://www.seals-project.eu/resources/res/engine/evaluation/wsdl/v2\n\">\n           <tns:result xmlns:tns=\"\nhttp://www.seals-project.eu/resources/res/engine/evaluation/wsdl/v2\n\">\n              <commons:name xmlns:commons=\"\nhttp://www.seals-project.eu/resources/res/common/types/xsd/v1\n\">rawResult</commons:name>\n              <commons:value xmlns:commons=\"\nhttp://www.seals-project.eu/resources/res/common/types/xsd/v1\n\">9cd63753-10a7-468b-808e-14810df14fd9</commons:value>\n           </tns:result>\n           <tns:output xmlns:tns=\"\nhttp://www.seals-project.eu/resources/res/engine/evaluation/wsdl/v2\n\">\n              <tns:numberToolBridgeFaults>0</tns:numberToolBridgeFaults>\n              <tns:numberToolFaults>0</tns:numberToolFaults>\n              <tns:totalToolExecutionTime>15906</tns:totalToolExecutionTime>\n           </tns:output>\n        </completed>\n     </soap:Body>\n  </soap:Envelope>\nEn particular la siguiente linea contiene el identificador del rawresult que se ha subido al repositorio de resultados:\n<commons:value xmlns:commons=\"\nhttp://www.seals-project.eu/resources/res/common/types/xsd/v1\n\">9cd63753-10a7-468b-808e-14810df14fd9</commons:value>\nEste raw result puede ser obtenido usando los servicios web que provee el repositorio de resultados o accediendo directamente al file system donde esta la carpeta del repositorio (D:\\SEALS\\environment\\repositories\\results\\rawresults) donde hay que renombrar el fichero que contenga el id a .zip. En nuestro caso el fichero zip solo contiene el fichero metadata.rdf ya que no hemos incluido ficheros en el paquete de datos de resultado. El contenido del metada.rdf generado se presenta a continuación. Este rdf no es completamente correcto debido a algunas inconsistencias detectadas.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n  <rdf:RDF\n     xmlns:rdfs=\"\nhttp://www.w3.org/2000/01/rdf-schema#\n\"\n     xmlns:onto=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation.owl#\n\"\n     xmlns:seals=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#\n\"\n     xmlns:xsd=\"\nhttp://www.w3.org/2001/XMLSchema#\n\"\n     xmlns:owl=\"\nhttp://www.w3.org/2002/07/owl#\n\"\n     xmlns:rdf=\"\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#\n\"\n     xmlns:indv=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#\n\">\n  <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#dataItem01\n\">\n     <seals:isLocatedAt>file path</seals:isLocatedAt>\n     <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#DataItem\n\"/>\n  </rdf:Description>\n  <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#suitItemIns01\n\">\n     <seals:hasDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#dataItem01\n\"/>\n     <rdf:type rdf:resource=\"\nhttp://www.seals-project.eu/ontologies/SEALSMetadata.owl#SuiteItem\n\"/>\n  </rdf:Description>\n  <rdf:Description rdf:about=\"\nhttp://localhost:8080/ontologies/ClassifierEvaluation.owl/instances\n\">\n     <owl:imports rdf:resource=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation.owl\n\"/>\n     <rdf:type rdf:resource=\"\nhttp://www.w3.org/2002/07/owl#Ontology\n\"/>\n  </rdf:Description>\n  <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#classifierResultItemsIns01\n\">\n     <onto:generatedFromDataItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#dataItem01\n\"/>\n     <onto:hasFMeasureValue rdf:datatype=\"\nhttp://www.w3.org/2001/XMLSchema#double\n\">0.6084436930590778</onto:hasFMeasureValue>\n     <onto:hasRecallValue rdf:datatype=\"\nhttp://www.w3.org/2001/XMLSchema#double\n\">0.6346153846153846</onto:hasRecallValue>\n     <onto:hasPrecisionValue rdf:datatype=\"\nhttp://www.w3.org/2001/XMLSchema#double\n\">0.6266053129260677</onto:hasPrecisionValue>\n     <rdf:type rdf:resource=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation.owl#ClassifierResultItem\n\"/>\n  </rdf:Description>\n  <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#classifierResult01\n\">\n     <onto:usedClassifier>ModelTree</onto:usedClassifier>\n     <onto:hasClassifierResultItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#classifierResultItemsIns01\n\"/>\n     <onto:hasEvaluationType rdf:resource=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation.owl#CrossValidation\n\"/>\n     <onto:generatedFromSuitItem rdf:resource=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#suitItemIns01\n\"/>\n     <rdf:type rdf:resource=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation.owl#ClassifierResult\n\"/>\n  </rdf:Description>\n  <rdf:Description rdf:about=\"\nhttp://robinson.dia.fi.upm.es:8080/ontologies/ClassifierEvaluation/resource#classifierResultItemsIns01\n\">\n     <onto:hasFMeasureValue rdf:datatype=\"\nhttp://www.w3.org/2001/XMLSchema#double\n\">0.5991154078737227</onto:hasFMeasureValue>\n     <onto:hasRecallValue rdf:datatype=\"\nhttp://www.w3.org/2001/XMLSchema#double\n\">0.6153846153846154</onto:hasRecallValue>\n     <onto:hasPrecisionValue rdf:datatype=\"\nhttp://www.w3.org/2001/XMLSchema#double\n\">0.5943265068265069</onto:hasPrecisionValue>\n  </rdf:Description>\n  </rdf:RDF>\nTiempo\n: 3 días.\nTiempos Reales de Ejecución\n\nTiempo total: 25 días.\nDetalle de actividades y problemas encontrados.\nPreparación del proyecto. 3 días\nLectura deliverables SEALS y presentaciones\nSeals community\nInfraestructura SEALS\nPlan de trabajo\nDefinir test data sets: 5 días.\nCrear repositorio local para datos de prueba\nDefinir estructura de los test data sets y de los metadatos asociados\nCrear test data sets siguiendo la estructura definida\nRegistrar los conjuntos de datos de prueba\nPrincipales problemas:\nConceptualmente, en la ontología, no esta clara la relación entre PersistentTestData y TestDataVersion. La relación se establece por medio del servicio web que sube los datos.\nAlgunas propiedades de la ontología se utilizan como identificadores que posteriormente se usan en urls (e.g. hasName). Si estas propiedades tienen caracteres no validos en urls entonces los servicios web fallan. Este comportamiento es recurrente en los diferentes componentes del test suite.\nLas propiedades de la ontología que se usan en los servicios web dependen de la versión del repositorio de resultados.\nCuando estaba definiendo el bpel me di cuenta que la propiedad hasComponentType se usa para distinguir entre los distintos data ítems de un suite ítem, así que esta propiedad debería tener valores distintos por cada data item.\nMantenimiento del repositorio nada intuitivo. Hay que borrar las tripletas directamente.\nDefinir resultados: 2 días\nCrear repositorio local de resultados\nDefinir estructura de los resultados así como de los metadatos asociados (Crear ontología)\nDefinir interpretación de los resultados\nEmpaquetar el clasificador: 4 días\nDefinir interfaz del clasificador\nImplementar\ntool wrapper\n(Andrés)\nCrear\ntool package\npara el wrapper (Simple Tool)\nImplementar cliente parar verificar la validez del\ntool package\nusando las utilidades del\nRuntime Evaluation Service\nPrincipales problemas:\nNo se puede probar el wrapper hasta que se haga el despliegue en el runtime evaluation service.\nVerificar funcionamiento del clasificador en\nRES Worker\nlocalmente: 5 días\nDesplegar localmente el\nRES Worker\ny la extensión para el uso del clasificador (de manera que se use la instancias locales de los repositorios de datos y resultados) (Andrés, Miguel)\nDesplegar\ntool package\nen el\nRES Worker\nlocal (Andrés, Miguel)\nImplementar pruebas de integración usando\nSoapUI\npara verificar la ejecución del clasificador vía\nRES Worker\n(Andrés, Miguel)\nPrincipales problemas:\nLa versión del repositorio de datos de prueba no era la esperada por el test de integración así que se tuvo que modificar este ultimo. El error se produjo por seguir las guías de una una presentación antigua.\nProceso de depuración sólo puede ser hecho por el experto de la plataforma\nUna vez descartados los problemas de configuración hay que depurar el wrapper usando una herramienta de depuración remota.\nVersión del runtime evaluation service desactualizada.\nCrear evaluación. 4 días\nDiseñar proceso de evaluación\nImplementar proceso como un workflow\nBPEL\nValidar el workflow\nBPEL\nusando\nApache ODE 1.3.5\nCrear\nevaluation description\nPrincipales problemas:\nCurva de aprendizaje BPEL\nInstalación de eclipse bpel designer para visualizar el workflow\nInstalación de eclipse java para poder compilar el proyecto maven que incluye el bpel\nDetalles de configuración conocidos sólo por el experto de la plataforma\n.\nVerificar funcionamiento de la evaluación en\nRES Core\nlocalmente y Ejecución local de la evaluación con el clasificador a través del\nRuntime Evaluation Service\n. 2 días\nDesplegar\nevaluation description\nen el\nRES Core\nlocal\nImplementar pruebas de integración usando\nSoapUI\npara verificar la ejecución de la clasificador vía\nRES Core\n, mockeando el RES Worker\nImplementar proyecto\nSoapUI\npara lanzar ejecuciones de la evaluación con el clasificador",
  "speaker": "SYSTEM",
  "uuid": "5046216c-a2ac-4238-afee-06557b172d82"
}