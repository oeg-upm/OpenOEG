{
  "message": "SYSTEM: Barzilay2004.pdf: Página 7\nSystem\nExtraction accuracy\nContent-based\n88%\nSentence classiﬁer\n76%\n(words + location)\nLeading\n\u0000sentences\n69%\nTable 4: Summarization-task results.\n 0\n 10\n 20\n 30\n 40\n 50\n 60\n 70\n 80\n 90\n 0\n 5\n 10\n 15\n 20\n 25\n 30\nSummarization accuracy\nTraining-set size (number of summary/source pairs)\ncontent-model\nword+loc\nlead\nFigure 3: Summarization performance (extraction accu-\nracy) on Earthquakes as a function of training-set size.\nsentence-level classiﬁer on the full training set. Clearly,\nthis performance gain demonstrates the effectiveness of\ncontent models for the summarization task.\n5.5\nRelation Between Ordering and Summarization\nMethods\nSince we used two somewhat orthogonal tasks, ordering\nand summarization, to evaluate the quality of the content-\nmodel paradigm, it is interesting to ask whether the same\nparameterization of the model does well in both cases.\nSpeciﬁcally, we looked at the results for different model\ntopologies, induced by varying the number of content-\nmodel states. For these tests, we experimented with the\nEarthquakes data (the only domain for which we could\nevaluate summarization performance), and exerted direct\ncontrol over the number of states, rather than utilizing the\ncluster-size threshold; that is, in order to create exactly\n\f\nstates for a speciﬁc value of\n\f\n, we merged the smallest\nclusters until\n\f\nclusters remained.\nTable 5 shows the performance of the different-sized\ncontent models with respect to the summarization task\nand the ordering task (using OSO prediction rate). While\nthe ordering results seem to be more sensitive to the num-\nber of states, both metrics induce similar ranking on the\nmodels. In fact, the same-size model yields top perfor-\nmance on both tasks. While our experiments are limited\nto only one domain, the correlation in results is encourag-\ning: optimizing parameters on one task promises to yield\nModel size\n10\n20\n40\n60\n64\n80\nOrdering\n11% 28% 52% 50% 72%\n57%\nSummarization 54% 70% 79% 79% 88%\n83%\nTable 5: Content-model performance on Earthquakes as\na function of model size. Ordering: OSO prediction rate;\nSummarization: extraction accuracy.\ngood performance on the other. These ﬁndings provide\nsupport for the hypothesis that content models are not\nonly helpful for speciﬁc tasks, but can serve as effective\nrepresentations of text structure in general.\n6\nConclusions\nIn this paper, we present an unsupervised method for the\ninduction of content models, which capture constraints\non topic selection and organization for texts in a par-\nticular domain. Incorporation of these models in order-\ning and summarization applications yields substantial im-\nprovement over previously-proposed methods. These re-\nsults indicate that distributional approaches widely used\nto model various inter-sentential phenomena can be suc-\ncessfully applied to capture text-level relations, empiri-\ncally validating the long-standing hypothesis that word\ndistribution patterns strongly correlate with discourse\npatterns within a text, at least within speciﬁc domains.\nAn important future direction lies in studying the cor-\nrespondence between our domain-speciﬁc model and\ndomain-independent formalisms, such as RST. By au-\ntomatically annotating a large corpus of texts with dis-\ncourse relations via a rhetorical parser (Marcu, 1997;\nSoricut and Marcu, 2003), we may be able to incorpo-\nrate domain-independent relationships into the transition\nstructure of our content models. This study could uncover\ninteresting connections between domain-speciﬁc stylistic\nconstraints and generic principles of text organization.\nIn the literature, discourse is frequently modeled using\na hierarchical structure, which suggests that probabilis-\ntic context-free grammars or hierarchical Hidden Markov\nModels (Fine et al., 1998) may also be applied for model-\ning content structure. In the future, we plan to investigate\nhow to bootstrap the induction of hierarchical models us-\ning labeled data derived from our content models. We\nwould also like to explore how domain-independent dis-\ncourse constraints can be used to guide the construction\nof the hierarchical models.\nAcknowledgments\nWe are grateful to Mirella Lapata\nfor providing us the results of her system on our data, and\nto Dominic Jones and Cindi Thompson for supplying us\nwith their document collection. We also thank Eli Barzi-\nlay, Sasha Blair-Goldensohn, Eric Breck, Claire Cardie,\nYejin Choi, Marcia Davidson, Pablo Duboue, No´emie\n",
  "speaker": "SYSTEM",
  "uuid": "797b754f-3261-4a04-8699-ce72a6b7ca36"
}