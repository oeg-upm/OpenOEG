{
  "message": "SYSTEM: Iswc10_gracia.pdf: Página 7\nis not lost and can be proposed for future groundings jointly with the other back-\nground ontology terms. The anchor terms may be related afterwards to terms in\nother ontologies (by other domain experts).\nDifferent algorithms can be applied for ranking the list of candidate senses, taking\ninto account the context where the model term appears (surrounding terms in the model)\nto determine the probability of being the right sense [19]. In our approach, the system\npromotes the reuse of already utilized groundings, which are shown ﬁrst. A list of syn-\nonyms is maintained in the system (fed by the information accessible in the background\nontologies, e.g., rdfs:label). This is used for expanding the list of candidate senses\n(when searching for a term we can also search for their synonyms).\nThe system proposes by default the use of DBpedia [2] as the main knowledge\nsource to support the grounding process, though it can be complemented by the use\nof other particular domain vocabularies. The choice of DBpedia as preferred source\nof knowledge in our system is supported by the results of experimenting with several\nsources of knowledge (see Section 6).\nWhen the user conﬁrms the grounding, we use the owl:sameAs construct for\nlinking the model term with the background ontology term. The generated statement is\nstored jointly with the model. Finally, the grounded models (as well as the generated\nontology of anchor terms) are stored in a semantic repository7, where they remain ac-\ncessible to the modelling tool for its later reuse (and to any other system interested in\nreusing the knowledge contained in the stored models)8.\n4.2\nBeneﬁts of Grounding in QR\nBy grounding a model, we are able to bridge the gap between the loosely and imprecise\nterminology used by a modeller and the well-deﬁned semantics of an ontology. This\nfacilitates interoperability among models or model fragments. Beneﬁts following from\nthis include:\n1. In an educational context, a teacher might restrict the vocabulary used by the learner\nto the knowledge contained in a certain domain ontology, thus speeding up the\ntraining period required to learn that vocabulary.\n2. New knowledge can be inferred using standard semantic reasoning techniques.\nFor example, let us suppose that entities whale and mammal in a QR model are\ngrounded to equivalent terms of the same background ontology. If this ontology as-\nserts that whale is a subclass of mammal, then the same relationship can be inferred\nfor the entities in the model. Other relations not explicitly declared in the model\ncan be also inferred (such as whale is an animal).\n3. Inconsistencies and contradictions between models can be more easily detected.\nBesides semantic inconsistencies (which can be discovered by applying a reasoner),\nother modelling issues can be detected. For example, suppose that a model asserts\nthat the increasing size of a population increases the demand of natural resources\n7 Based on Jena semantic framework (http://jena.sourceforge.net/) in our current prototype.\n8 A set of web services has been developed to support the communication between repository\nand modelling tool.\n",
  "speaker": "SYSTEM",
  "uuid": "56e1acb2-0536-44e6-aace-662168519718"
}