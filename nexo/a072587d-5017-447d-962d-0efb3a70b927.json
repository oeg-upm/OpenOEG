{
  "message": "SYSTEM: Wiki: https://delicias.dia.fi.upm.es/wiki/index.php/Preguntas_de_investigaci%C3%B3n \n\nFill your research question according to this structure:\nName:\nYour name\nResearch questions:\nWhat research questions are you addressing?\nRelevance:\nWhy are these questions relevant?\nResearch hypotheses:\nWhat are the hypotheses that are related to the research questions?\nContents\n[\nhide\n]\n1\nFilip Radulovic\n1.1\nResearch questions\n1.2\nRelevance\n1.3\nResearch hypotheses\n2\nIdafen Santana\n2.1\nResearch questions\n2.2\nRelevance\n2.3\nResearch hypotheses\n3\nOlga Ximena Giraldo Pasmín\n3.1\nResearch questions\n3.2\nRelevance\n3.3\nResearch hypotheses\n4\nDaniel Garijo Verdejo\n4.1\nResearch questions\n4.2\nRelevance\n4.3\nResearch hypotheses\n5\nFreddy Priyatna\n5.1\nResearch questions\n5.2\nRelevance\n5.3\nResearch hypotheses\n6\nVíctor Rodríguez-Doncel\n6.1\nResearch questions\n6.2\nRelevance\n6.3\nResearch hypotheses\n7\nNandana Mihindukulasooriya\n7.1\nResearch questions\n7.2\nRelevance\n7.3\nResearch hypotheses\n8\nMaría Poveda\n8.1\nResearch questions\n8.2\nRelevance\n8.3\nResearch hypotheses\n8.4\nAssumptions\n8.5\nRestrictions\n9\nMariano Rico\n9.1\nResearch questions\n9.2\nRelevance\n9.3\nResearch hypotheses\n9.4\nAssumptions\n10\nAlejandro Llaves\n10.1\nResearch questions\n10.2\nRelevance\n10.3\nResearch hypotheses\n11\nJavier D. Fernández\n11.1\nResearch hypotheses\n11.2\nResearch questions\n11.3\nRelevance\n12\nJorge Gracia\n12.1\nResearch questions\n12.2\nRelevance\n12.3\nResearch hypotheses\n13\nAlmudena Ruiz-Iniesta\n13.1\nResearch questions\n13.2\nRelevance\n13.3\nResearch hypotheses\n14\nAntonio Sánchez-Padial\n14.1\nResearch questions\n14.2\nRelevance\n14.3\nResearch hypotheses\n14.4\nResearch hypotheses\n15\nMaría Navas-Loro\n15.1\nResearch questions\n15.2\nRelevance\n15.3\nResearch hypotheses\nFilip Radulovic\n\nResearch questions\n\nIs it possible to automate the comparison of alternatives in a process of recommendation by exploiting the results of their evaluation\nIs it possible to adapt existing multiple criteria decision making method to automatically address user quality requirements in a process of recommendation\nRelevance\n\nWhen using a multiple criteria decision making method in a process of recommendation, alternatives to be recommended have to be compared against various criteria and this is usually done by users or experts, which can be expensive and time-consuming. In the cases when alternatives have been previously evaluated, their automatic comparison based on evaluation results can solve this problem.\nFurthermore, since different users have different requirements for the alternatives to be recommended, adapting multiple criteria decision making method to automatically address user quality requirements in a process of recommendation can lead to better recommendations tailored to users' needs.\nResearch hypotheses\n\nH1 - Recommendation framework to be developed in my thesis is not able to rank better those alternatives that satisfy more of user quality requirements\nH2 - Recommendations produced by the recommendation framework to be developed in my thesis are not in line with recommendations made by experts\nIdafen Santana\n\nResearch questions\n\nIs it possible to conserve the knowledge of the execution environment of a scientific workflow?\nIs it possible to use this knowledge to recreate a new execution environment that is able to re-execute the former workflow?\nWhich are the relevant and necessary properties that must be documented in order to achieve the reproduction?\nRelevance\n\nScientific reproducibility is a cornerstone of the scientific method, either in traditional science or in computational science. Nowadays most of the current approaches on computational experiment conservation/preservation and reproducibility focus on how to deal with the data and scientific procedure decay. Many studies show the need of addressing the third pillar of an experiment, that is, the equipment. An approach to achieve it has not been thoughtfully considered yet. In this work we claim that exposing the information about the infrastructure and developing methods for reproducing it in the future based on this information would achieve both the conservation and reproduction of the execution environment.\nResearch hypotheses\n\nThe execution environment of a computational scientific workflow can be conserved for its future reproduction by describing its relevant properties in a standardized way.\nOlga Ximena Giraldo Pasmín\n\nResearch questions\n\nHow to semantically formalize experimental protocols so that sharing and discovering can be supported?\nRelevance\n\nWhy?\nBecause, a protocol is a depiction of a sequence of operations; experimental protocols are usually written in natural language. Generally, they are presented in a “recipe” style providing step-by-step descriptions for processes. Such sequence of tasks and operations in experimental research are fundamental units of knowledge. Investigators follow and generate protocols in their daily activities; as experimental protocols reflect the know-how of a laboratory they are shared and adapted for various purposes. Most importantly, experimental protocols are essential for patenting; they are also central in reproducibility efforts. Several efforts have focused on accurate description of data for interoperability purposes; however, fewer efforts have emphasized on the actual how data was produced.\nResearch hypotheses\n\nThe standardization of laboratory protocols improves the reproducibility of an experiment.\nDaniel Garijo Verdejo\n\nResearch questions\n\nHow to create abstractions in scientific experiments?\nHow do we represent scientific experiment information?\nHow do we link abstract workflow representations to their implementations and executions?\nHow can we detect typical operations in workflows automatically?\nWhat is the relationship among different workflows?\nRelevance\n\nReusing scientific workflows is often difficult. Existent workflows might be too specific for one's purposes, although in many cases parts of these workflows are valuable for reuse (preprocessing steps, visualization steps, etc.). By knowing how different workflows relate to each other (even if it is at an abstract level), a user gains more understanding on the available work by their colleagues, and a designer can be suggested useful fragments that are related to their work.\nIn summary: important for discovery, understanding, exploration, design of scientific workflows.\nResearch hypotheses\n\nIt is possible to identify/extract automatically patterns/abstractions in workflow repositories/catalogs/libraries that are useful for workflow designers and workflow users.\nFreddy Priyatna\n\nResearch questions\n\nIs it possible to formalize SPARQL to SQL query translation for RDB2RDF systems?\nIs it possible to improve the performance SPARQL to SQL query translation for RDB2RDF systems?\nRelevance\n\nMost of the data currently stored in relational database and making them available as RDF datasets, whether materialized or virtual, plays an important role in the emergence of Web of Data. Having the data available as virtual RDF datasets is preferable in many cases, in which many legacy systems still mandate the use of relational databases and the data changes frequently. In these cases, dumping the data into materialized RDF datasets is not a good approach because it is difficult to maintain the consistency of materialized RDF datasets with the data in relational database systems. SPARQL queries used to access the virtual RDF datasets have to be translated into efficients SQL queries so that they can be evaluated over the underlying database, with reasonable peformance. This shows the need and relevance of formalization and optimizations of query translation.\nResearch hypotheses\n\nQuery translation algorithm originally designed for RDB-backed triple stores can be adapted to work with R2RML mappings.\nFurthermore, on some commonly used query patterns, various optimizations can be done to enhance the performance of the algorithm.\nVíctor Rodríguez-Doncel\n\nResearch questions",
  "speaker": "SYSTEM",
  "uuid": "a072587d-5017-447d-962d-0efb3a70b927"
}