{
  "message": "SYSTEM: Wiki: https://delicias.dia.fi.upm.es/wiki/index.php/Proyectos_Fin_de_Carrera \n\nLinguistic Linked Data\n\nOld projects\n\nBelow are the projects defined on or before 2020\n2.\nCorrector de texto para Twitter\nUno de los principales problemas a la hora de analizar textos procedentes de las redes sociales son los errores gramaticales que suelen contener, así como la presencia de elementos propios de este tipo de foros que requieren de un procesamiento especial (i.e. hashtags, formas de mencionar a otros usuarios o emoticonos y expresiones habituales en las redes). Además, la limitación en el número de caracteres existente en Twitter la convierte en un caso singular dentro de las redes sociales, ya que los usuarios tienden a adaptar su forma de escribir a dicha limitación, omitiendo palabras y creando acortaciones que dificultan el uso de herramientas genéricas de procesamiento del lenguaje, especialmente a la hora de realizar tareas como el Análisis de Sentimientos. El objetivo de este practicum será la creación de un corrector que \"normalice\" tweets en español.\nEl objetivo del trabajo es la creación de un módulo software que:\nCorrija tweets (deletreo, faltas de ortografía...)\nProcese emoticonos y deduzca su significado en el contexto del Análisis de Sentimientos.\nExpanda hashtags.\nCorrija gramaticalmente los tweets (palabras omitidas, acortadas...).\nAdicionalmente, podrían procesarse las conversaciones a las que pertenecen los tweets, así como las URLs o las imágenes que contienen, para enriquecer el texto y dotarlo de un contexto.\nFunciones a desarrollar:\nAnálisis de otros correctores existentes.\nDiseño e implementación del corrector (en base a una versión básica ya implementada o partiendo de cero).\nPruebas.\nDocumentación.\nAdicionalmente, se podría crear un servicio web que corrija tweets en línea usando el módulo implementado.\nRequisitos:\nJava, especialmente parseado de cadenas de texto.\nConocimiento previo de NLP y de Twitter y su API es bienvenido pero no imprescindible.\n3.\nMapeador de elementos urbanos\nEl objetivo de este practicum es mapear automáticamente los elementos urbanos de una ciudad dada una ruta. Para ello, se propone el uso de las siguientes herramientas:\nGoogle Directions para obtener el recorrido de la ruta\nGoogle Street View para obtener las imágenes de la ruta\nGoogle Vision para identificar el tipo de elemento urbano.\nEl alumno podrá hacer uso de otras herramientas si lo considera necesario\nEl resultado de este prácticum será un mapa con las posiciones (latitud, longitud) de los elementos identificados a lo largo de la ruta\nComo caso de uso nos centraremos en las farolas.\nFunciones a desarrollar:\nMódulo para el cálculo de ruta de ruta\nMódulo con imágenes de la ruta\nClasificador de imágenes para reconocimiento de elementos urbanos\nRequisitos:\nDiseño Web\nHTML/CSS\nUso de API\nUso de librerías de Machine Learning (opcional)\n[Esteban González Guardia]\n4.\nClasificador de Farolas\nEl objetivo de este practicum es el desarrollo de una aplicación basada en el juego NightKnights (\nhttp://www.nightknights.eu\n) con el objetivo de reconocer los distintos tipos de farolas. Para ello se hará uso de una plantilla para generar este tipo de juegos disponible en [\n[1]\n]\nFunciones a desarrollar:\nIdentificación de los distintos tipos de farolas\nConstrucción de un banco de imágenes de farolas\nAdaptar la plantilla existente al juego que se quiere desarrollar.\nRequisitos:\nHTML+CSS+Javascript\nPHP\n[Esteban González Guardia]\n5.\nMapas de contaminación lumínica\nEl objetivo es desarrollar una aplicación web para visualizar mapas de contaminación lumínica basados en datos procedentes de sensores, farolas, mediciones tomadas por ciudadanos con aplicaciones como Loss of the Night [\n[2]\n], etc ...\nFunciones a desarrollar:\nIdentificar fuentes de datos relacionadas con Contaminación lumínica\nDesarrollo de un módulo para acceder a los datos de dichas fuentes, siempre que sean de acceso público.\nDesarrollo de un mapa con cada una de las fuentes de datos y la combinación de ellas (incluyendo gráficas si es aplicable)\nRequisitos:\nHTML + CSS\nLeaflet (opcional)\n[Esteban González Guardia]\n6.\nIdentificación de núcleos urbanos mediante el uso de mapas de cielo\nNixnox es un proyecto de STARS4ALL (\nhttp://nixnox.stars4all.eu\n) para la generación de mapas de brillo de cielo. Estos mapas se basan en las mediciones de la bóveda celeste tomadas por un aparato llamado SQM (Sky Quality Meter) [\n[3]\n]. Los objetivos de este proyecto son:\nEl desarrollo de una pequeña aplicación móvil o web en la que se introduzcan los datos del sensor mediante un formulario.\nA partir del mapa generado, identificar las distintas fuentes de luz,  principalmente núcleos urbanos, que están produciendo el brillo en el cielo. Además se adjuntará información relevante del núcleo urbano como número de habitantes, renta per cápita, etc … Para ello, el alumno podrá hacer uso de herramientas como Open Street Map, DBpedia, Wikidata, etc\nUn ejemplo de mapa de cielo generado por nixnox puede verse aquí: [\n[4]\n]\nFunciones a desarrollar:\nDesarrollar un módulo para la extracción de datos de DBPedia / Wikidata / OSM\nDesarrollar un script que genere mapas de cielo. Una versión de este script ya ha sido generada. El alumno deberá modificarla para incluir los datos procedentes de DBPedia o Wikidata.\nMódulo para almacenar los mapas y los datos generados en el Portal de datos de STARS4ALL [\n[5]\n] y/o Zenodo.\nRequisitos:\nPython\nSPARQL (en caso de usar DBPedia o Wikidata)\n[Esteban González Guardia]\n7.\nTesting y visualización de resultados de la aplicación Dark Sky Meter\nDark Sky Meter es una aplicación para Android cuya finalidad es medir el brillo de cielo nocturno con la cámara de un iPhone.\nFunciones a desarrollar:\nPublicar los datos de la aplicación en un CKAN\nVisualizar los datos en forma de mapa de contaminación lumínica\nTestear la aplicación siguiendo la misma técnica que se emplea en NixNox (Practicum 6) que consiste en explorar toda la bóveda celeste. Los datos obtenidos se compararán tanto con un Sky Quality Meter (SQM - fotómetro)[\n[6]\n] como con un TESS (fotómetro desarrollado por STARS4ALL) [\n[7]\n]\nRequisitos:\nPython\n8.\nNamed entity recognition and disambiguation in the legal domain\nWork description: Legal documents (EU directives, national laws, judgements) contain references to companies and individuals, to public entities and to other legal documents. These textual references are not made explicit, hampering the navigation of the documents, preventing the development of advanced search engines and decreasing the performance of information analysis algorithms.\nThe person taking this assignment would design and develop algorithms and methods to identify and disambiguate the key named entities in legal documents and would create a graph with the cross references.\nDesired skills: The person taking this assignment would ideally have interest in NLP technologies and a fair knowledge of either Java or Python. Specific skills on NLP toolkits are not required but would be a plus.\n[Víctor Rodríguez Doncel]\n9.\nHarvesting of terminological resources in the legal domain and its conversion to RDF\nWork description: Domain dependent vocabularies or terminologies are collections of terms used in specific domains. In the case of the legal domain, those terms are the ones used by experts (lawmakers, lawyers, judges…) in their daily communication and also the ones that appear in directives, laws, norms, standards, etc. Such terminologies are normally scattered, monolingual or multilingual, and in many different formats. This makes it difficult to reuse and integrate them in NLP systems.\nThe person taking this assignment would harvest legal terminologies, analyse them, and transform them, if feasible, into RDF.\nDesired skills: The person taking this assignment would ideally have interest in NLP technologies and a fair knowledge of RDF. Specific skills on NLP toolkits are not required but they would be a plus.\n[Elena Montiel Ponsoda]\nOntologies",
  "speaker": "SYSTEM",
  "uuid": "8ae77600-4d75-47fb-8fd2-be1366f6cc2f"
}