{
  "message": "SYSTEM: Neon_2008_d2.2.2.pdf: Página 21\nD2.2.2 Methods and Tools Supporting Re-engineering\nPage 21 of 124\nsenses and words and seventeen for each relationship. This method tackles the internal data model\nof the lexicon, and devises how the lexicon data is represented and accessed for the transformation.\nThe method also provides resource provenance information, so the resultant ontology keeps the\nreference to WordNet.\nThe process for designing the conversion consists in (1) analyzing existing conversions, which helps\nto understand the different ways in which WordNet is used on the Semantic Web; (2) formulating the\nrequirements; (3) analyzing the source ﬁles and documentation; (4) designing the RDF/OWL schema;\n(5) designing a program for converting Prolog data to RDF/OWL; (6) drafting a Working Group Note\nexplaining the requirements and design choices; and (7) reviewing the draft note and schema/data\nﬁelds.\nThe authors have been established the following requirements: (a) the method should be a full con-\nversion; (b) it should be convenient to work with; (c) it should reﬂect as mush as possible the original\nstructure of WordNet; and (d) it should provide OWL semantics while still being interpretable by pure\nRDF(S) tools.\nThe method follows the approach to transforming resource schema into an ontology schema and\nresource content into instances of the ontology; for the transformation an ad-hoc wrapper has\nbeen employed. The method takes into account syntactic transformation aspects, how symbols\nare structured in WordNet and ontology formats. But, this method does not consider fully seman-\ntic transformation aspects, since one of the requirements stipulates that interpretation should be\navoided (requirement c). The transformation is performed automatically with the Swi-Prolog12 tool.\nThe method consists in\n– Creating a set of classes for each of the main components of WordNet including classes for word,\nsynset and sense.\n– Modelling words, synsets and senses belonging to WordNet as instances of the previously cre-\nated classes.\n– Coding part of the semantics related to each instance by means of the URIs used to identify each\ninstance.\nThe method produces one single ontology. The ontology components generated are classes, at-\ntributes, relations, and instances. The resultant ontology is expressed in RDF(S)/OWL Full.\n• Gangemi et al. [GNV03, GGMO03] present a method that explains how WordNet information can be\nbootstrapped, mapped, reﬁned and modularized. This method employs with WordNet 1.6, which is\nstored in relational databases. This is a hybrid method because it employs top-down techniques\nand tools from formal ontology and bottom-up techniques from computational linguistics and machine\nlearning. This hybrid method can automatically extract association relations from WordNet, and in-\nterpret those associations in terms of a set of conceptual relations, formally deﬁned in the DOLCE13\nontology. It follows the approach to transforming the resource content into an ontology schema.\nThe method uses a formal speciﬁcation of the conversions between WordNet components and the\nontology ones. It takes into account syntactic transformation aspects, as well as how symbols\nare structured in the lexicon and ontology formats. It also takes into account semantic transforma-\ntion aspects, and the semantic interpretation of the resource elements when deﬁning transformations\nto ontology elements. The method tackles the internal data model of the resource, and describes\nhow the resource data is represented and accessed for the transformation. This method does not pro-\nvide the resource provenance information, so the resultant ontology does not keep the reference to\nWordNet. The method consists of the following two steps:\n12http://www.swi-prolog.org/packages/semweb.html\n13http://www.loa-cnr.it/DOLCE.html\n2006–2008 c⃝Copyright lies with the respective authors and their institutions.\n",
  "speaker": "SYSTEM",
  "uuid": "5b2a5f1a-6b9a-4686-bde3-d45cf49ae756"
}