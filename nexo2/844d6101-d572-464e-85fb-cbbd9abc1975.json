{
  "message": "SYSTEM: 1.-\n#The Open Provenance Model\n2.-\n#A semantic Web Approach to the Provenance Challenge\n3.-\n#Using trust and Provenance for content filtering on the semantic Web\n4.-\n#Annotation and Provenance Trackin in Semantic Web Photo Libraries\n5.-\n#A distributed Algorithm for Determining the Provenance Data\n6.-\n#Towards Content Trust of Web Resources\n7.-\n#Conceptos reutilizables del estado del arte de los proyectos mIO! y España Virtual\n8.-\n#Problem-Solving Methods for understanding Process Executions\n9.-\n#Validation of E-Science Experiments using a Provenance-based Approach (presentación)\n10.-\n#Provenance and Interoperability (presentación)\n11.-\n#Semantic e-Science\n12.-\n#Assessing Information Quality Using Web Data Provenance\n13.-\n#PrOM: A Semantic Web Framework for Provenance Mangement in Science\nContents\n[\nhide\n]\n1\nThe Open Provenance Model\n2\nA semantic Web Approach to the Provenance Challenge\n3\nUsing trust and Provenance for content filtering on the semantic Web\n4\nAnnotation and Provenance Tracking in Semantic Web Photo Libraries\n5\nA distributed Algorithm for Determining the Provenance Data\n6\nTowards Content Trust of Web Resources\n7\nConceptos reutilizables del estado del arte de los proyectos mIO! y España Virtual\n8\nProblem-Solving Methods for understanding Process Executions\n9\nValidation of E-Science Experiments using a Provenance-based Approach (presentación)\n10\nProvenance and Interoperability (presentación)\n11\nSemantic e-Science\n12\nAssessing Information Quality Using Web Data Provenance\n13\nPrOM: A Semantic Web Framework for Provenance Mangement in Science\nThe Open Provenance Model\n\nAutores\n: Luc Moreau(Editor), Beth Pale, Simon Miles, Carole Goble, Paolo Missier, Roger Barga, Yogesh Simmhan, Joer Futrelle, Robert E. McGrath, Jim Myers, Patrick Paulson, Shawn Bowers, Bertram Ludaescher, Natalia Kwasnikowska, Jan Van den Bussche, Tommy Ellkvist, Juliana Freire y Paul Groth.\nFecha\n: 17 de julio, 2008\nPaper donde se introduce un modelo de provenance que intenta cubrir los siguientes requisitos:\nPermitir que la información del provenance pueda ser compartida entre sistemas basándose en un modelo de provenance compartido\nPermitir a los desarrolladores construir y compartir herramientas para operar con dicho modelo.\nDefinir el modelo\nDefinir un conjunto de reglas que identifiquen las inferencias válidas en grafos provenance\nSin embargo, no se especifican las representaciones internas que debe hacer cada sistema para manipular el provenance internamente, no se define una sintaxis \"parseable\" para el modelo, y no se especifican protocolos para almacenar la información del provenance en los repositorios.\nEl modelo que se propone está basado en 3 entidades primarias: artefactos, procesos y agentes.\nLos artefactos son piezas inmutables de estado, que bien pueden representar un objeto físico o bien uno digital en un sistema. Los procesos son las acción o series de acciones causadas por los artefactos, que desembocan en la creación de nuevos artefactos.\nLos agentes, por último, son los \"catalizadores\" del proceso, facilitando o controlando su desarrollo.\nLas dependencias que existen entre estas entidades varían:\nExiste una dependencia de uso cuando un proceso P usa un artefacto A en su ejecución\nExiste una dependencia de \"serGeneradoPor\" cuando un artefacto A es resultante del proceso P.\nExiste una dependencia de \"serControladoPor\" cuando el agente Ag controla el proceso P\nExiste una dependencia de \"serActivadoPor\" cuando un proceso P2 activa un proceso P1\nExiste una dependencia de \"serDerivadoDe\" cuado un artefacto A2 se obtiene a partir del artefacto A1.\nEn el caso de las 3 primeras, hay que destacar que como un proceso puede usar varios artefactos,(o un artefacto ser generado por varios procesos, o un proceso ser controlado por varios agentes), es importante identificar el rol bajo el cual se usó cada uno de ellos.\nCada proceso, agente o artefacto tiene un identificador propio que los distingue de los demás. Sólo son iguales si coinciden sus ids. Las aristas del grafo se distinguen por su fuente, destino y su rol.\nSe proponen 2 modelos de grafo : uno si tener en cuenta el tiempo en el que ocurren los sucesos y otro teniéndolo en cuenta, dado que se argumenta que el tiempo no influye en la causalidad de las entidades: que un proceso se produzca antes que otro no quiere decir que el segundo dependa de alguna manera del primero.\nEn cuanto al conocimiento que puede ser inferido, se introduce la relación \"puedeHaberSidoDerivadoDe\", si un artefacto fue generado por un proceso que a su vez usó otro artefacto. Además se define el cierre transitivo de las relaciones de uso, serGeneradoPor,serDerivadoDe y serActivadoPor,( de manera que, por ejemplo, si un proceso fue activado por otro y ese otro usaba un artefacto, entonces podríamos decir que el nuevo proceso también lo ha usado).\nPara terminar, se explica un ejemplo con detalle y se subraya que este modelo sirve para ejecuciones pasadas. Además se invita a los grupos que hayan definido su propio modelo a convertir sus representaciones al que se presenta y viceversa.\nA semantic Web Approach to the Provenance Challenge\n\nAutores :\nJennifer Goldbeck y James Hendler.\nFecha :\n15 de Noviembre de 2006. MaryLand\nEl provenance es crítico para los sistemas científicos, dado que permite  verificar datos, repetir experimentos y descubrir dependencias. En este artículo se presenta una aproximación semántica del \"Desafío Provenance\", usando Web services, ontologías y razondadores OWL entre otros.\nActualmente la búsqueda por palabras clave está bastante desarrollada, pero no así las imágenes, audio o video.\nLos lenguajes de la web semántica son 3 principalmente: Resource Description Framework,(RDF), RDF Schema(RDFS) y Web Ontology Lenguage (OWL). Se usan para escribir ontologías y describir modelos para codificar los datos.\nFuncionamiento\n:\nCada uno de los archivos tiene asignada una URI, que permite referenciar los archivos en documentos semánticos y transmitir las referencias mientras ejecutamos el flujo de trabajo. Cada proceso es encapsulado en un webservice, que recupera los archivos y ejecuta el proceso, creando los archivos de salida. A su vez cada uno de los archivos de salida es almacenado y tendrá su correspondiente URI, por lo que será accesible desde cualquier lado. Con cada ejecución también se guarda un archivo OWL en el servidor, que también posee la URI identificativa.\nUna vez termine el proceso, se devolverá como resultado todos los String de los ficheros de salida.\nTodo el flujo de trabajo lo lleva acabo un web service (Workflow Execution Service, WES). Se encargará de invocar los servicios representantes de los procesos en el flujo de trabajo, pasar las URIs de los archivos de entrada, y de obtener las URIs de los ficheros de salida.\nRepresentación de la información\n:\nSe ha generado la ontología de manera que no es totalmente genérica, sino con la idea de que sea modificada o extendida por los programadores que la usen.\nLa clase raíz es \"Recurso\", bajo las cuales se organizan las clases \"Archivos\". Las clases están conectadas mediante propiedades, que recogen los datos que hemos grabado para cada clase de objetos.\nEjecución de servicio: clase que describe una ejecución de un servicio específico. Se usa para almacenar la fecha, hora, inputs y putputs the la invocación.\nArchivo: representa la parte de provenance para todos los archivos producidos por el flujo de trabajo. Se usa para almacenar los propios datos así como para conectar otros archivos a las clases \"Ececución de servicio\" correspondientes.\nFlujo de trabajo: sirve para representar el flujo completo de la ejecución. Almacenará tanto las fechas de comienzo y fin como todas las ejecuciones de servicio que hayamos generado.\nComparación con otras propuestas\n:\nEl beneficio de la alternativa que se propone en este artículo es que está basada completamente en la web, siendo un sistema sistema distribuido e independiente. Además básicamente todos los formatos pueden ser convertidos a una representación RDF, por lo que el frontend usado se puede usar para interactuar con la información.\nEn conclusión, el artículo resume que ha conseguido alcanzar los objetivos que se ha propuesto, pero que actualmente están invirtiendo sus esfuerzos en métodos para filtrar los resultados basándose en la confianza y cómo utilizarla cuando hay múltiples fuentes para un un archivo. Admite que los filtros sociales son comunes cuando hablamos de datos científicos, y que un sistema automático para usarla en un sistema con provenance podría resultar interesante y útil.\nUsing trust and Provenance for content filtering on the semantic Web\n\nAutores :\nJennifer Goldbeck y Aaron Mannes, ambos de la universidad de Marylannd\nFecha :\nMayo 2006, para la WWW2006, Edinburgo, UK\nArtículo en el que se enfatiza la importancia de la confianza, provenance y anotaciones en la web semántica. Propone un algoritmo para inferir relaciones de confianza usando el provenance, y por último 2 aplicaciones en las que se usa como ejemplo.\nLas anotaciones acerca de la confianza son particularmente interesantes, puesto que pueden ser aplicadas de dos maneras: En primer lugar, se pueden dar recomendaciones acerca de cuánto un usuario debería confiar en otro basándose en los caminos que los comunican en una red social.\nEn segundo lugar, si además disponemos de información de provenance en el sistema, podemos filtrar la información que le llega al usuario basándonos en la confianza que tenga de la fuente que hizo la anotación.\nCuando dos individuos están directamente conectados en una red, pueden tener puntuaciones de confianza del otro. Si no están conectados directamente, no tienen información de confianza desde un principio. Sin embargo, los caminos que les conectan a través de la red pueden contener información acerca de cuánto es probable que confíen el uno en el otro.\nEvidentemente las inferencias de confianza no van a ser tan precisas como una puntuación directa. Surgen dos cuestiones: cuánto afectan las personas intermedias a la confianza inferida, y la longitud total del camino.\nAlgoritmo\n:\nLa idea es que el nodo fuente comienza una búsqueda por el nodo destino. Pregunta a cada uno de sus vecinos para que le de su opinión sobre el destino, y éstos repetirán el proceso llevando la cuenta de la lejanía respecto a la fuente. \nLa fuerza del camino a cada vecino es la mínima puntuación  de la fuente al nodo y la puntuación del nodo al vecino. Cada vecino graba el camino con más fuerza hacia el destino, y se establece la profundidad a la máxima profundidad disponible.\nUna vez completado, se fija el umbral escogiendo el máximo de los caminos que se dirigen al destino. Cualquier nodo puntuado por encima de este umbral será el accedido por sus vecinos para que les de la información de confianza.\nPara ilustrar el algoritmo, el artículo hace pruebas con dos aplicaciones diferentes: un  recomendador de películas y una red de confianza entre agencias de inteligencia para determinar la validez de los informes acerca de objetivos o de evaluación.\nEn el primer caso, no parece funcionar muy bien debido a que se habían votado masivamente las cincuenta mejores películas, e interferían demasiado con el algoritmo como para dar alternativas mejores. Sin embargo, para la gente que discrepaba con la media, se ofrecían mejores propuestas. Se concluye diciendo que el mejor método sería una mezcla entre la solución propuesta y los métodos de filtrado colaborativo con los que se compararon los resultados.\nEn el segundo caso, resulta una herramienta útil para la comunidad de inteligencia. Basándose también en el provenance, obtenemos un análisis básico para comprender cómo funciona la propia comunidad y cómo analiza la información.\nAnnotation and Provenance Tracking in Semantic Web Photo Libraries\n\nAutores :\nChristian Halascheck-Wiener, Jennifer Goldbeck, Andrew Schain, Michael Grove, Bijan Parsia y Jim Hendler\nFecha :\n(No se indica fecha en el artículo, pero por las referencias es posteiror a 2005). Universidad de Meryland\nEn este artículo se propone un framework de dominio independiente para gestionar y anotar imágenes en la Web Semántica, y, además, se introduce una herramienta que facilita crear y publicar en ella anotaciones OWL de contenido de imagen.\nSe hace hincapié en la cantidad de imágenes que inundan actualmente la red, y la necesidad de gestionarlas y organizarlas adecuadamente para recuperarlas cuando sea necesario. Para ello, se propone una solución genérica y flexible para publicar anotaciones de contenidos de imágenes digitales, y un mecanismo para gestionarlas y hacer el seguimiento de su provenance a través de un portal web semántico basado en ontologías.\nRequisitos\n:\n-Es necesario un mecanismo que catalogue todos los tipos de contenido de imagen en diferentes dominios. Se requiere información de la propia imagen, (fecha de creación , fuente, etc), así como del contenido que representa.\n-Los metadatos asociados deben de ser mantenibles y se deben de poder extender para que las relaciones entre imágenes y datos evolucionen y se ramifiquen en otras disciplinas.\n-Se debe poder anotar imágenes o zonas de imágenes usando conceptos de ontologías(OWL o RDFS).\nDetalles de implementación\n:\nSe presenta PhotoStuff, plataforma independiente de software libre y que sirve para anotar imágenes o regiones de las mismas respecto a conceptos de cualquier número de ontologías especificadas en RDFS u OWL. Los usuarios pueden cargar ontologías, marcar imágenes y exportar las anotaciones resultantes.\nLa aplicación saca ventaja de los metadatos implícitos en la imagen, codificándolos en RDF/XML para hacerlos accesibles desde la Web Semántica. Además, se comunicará con un portal web semántico, enviando las instancias generadas al portal, actualizando sus RDF/XML y subiendo nuevas imágenes para que sean referenciadas por un URI.\nGestión del provenance\n:\nCuando un usuario sube algún tipo de anotación al portal, se le pide su nombre y un comentario. Ambos datos se almacenan, junto con el timestamp. El portal ofrece una interfaz en donde se podrán ver todos los datos subidos para asistir a los administradores del sistema. Éstos podrán editar o eliminar los contenidos en caso de considerarlo necesario.\nTrabajo futuro\n:\nLos autores reconocen que aunque han alcanzado sus objetivos, aún queda trabajo por hacer para facilitar al usuario la tarea de la anotación: si se aplicaran técnicas de segmentación de regiones en las fotos, se podría sugerir al usuario regiones de interés. También ayudarían técnicas de procesamiento de imagen para detectar automáticamente regiones parecidas en distintas imágenes.\nA distributed Algorithm for Determining the Provenance Data\n\nAutores :\nPaul T. Groth\nFecha :\n(No se indica fecha, pero por las referencias ha de ser posterior a Junio del 2008). Universidad de California del Sur\nPaper donde se describe un algoritmo, D-PQuery, para determinar el provenance de datos a partir de provenances distribuidos de manera paralela.\nCuando efectuamos un experimento, se producen muchos datos-provenance: los datos de entrada, los ficheros o archivos temporales que se producen durante la ejecución y los datos resultantes. Si también consideramos los datos compartidos por las aplicaciones, entonces podemos inferir el grafo de dependencias que relaciona todo y saber cuál fue el estado de un experimento en un momento dado.\nSe considera que cada nodo del grafo describe una entidad en cuestión en un momento en concreto, por lo que no representa el estado actual ni el futuro de la entidad, sino el pasado. Se tratará de grafos dirigidos y aciclicos,(DAG en inglés). Las aristas del grafo denotan la dependencia entre nodos.\nUna vez establecido el sistema de representación de la información, se aborda el problema de consultar el provenance, y se divide en 2 fases:\nConstrucción del DAG de a partir de la información provenance, que puede ser representado a su vez por multitud de grafos.\nEncontrar un subgrafo en el DAG que describa el item en cuestión.\nPara llevarlas a cabo, en primer lugar hemos de consolidar toda la información del provenance, (que puede estar distribuida en varios repositorios), en un solo repositorio. A continuación se construirá el DAG y se realizará un recorrido a través del grafo de dependencias para llevar a cabo la segunda fase.\nEl algoritmo D-PQuery se divide en 6 procedimientos principales: traducir, filtrar, atravesar, consolidar, reducir y mezclar.\nTraducir:\nEl algoritmo recibe como entrada información provenance y  como salida da un grafo dirigido describiendo las relaciones de dependencia.\nFiltrar:\nSe reduce el tamaño del grafo filtrando los vértices que no deberían formar parte del grafo de provenance resultante. Se introducen las \"funciones de parada\", que determinan si los hijos de un nodo particular deberían ser incluidos en el grafo final.\nAtravesar:\nSe recorre el grafo manteniendo todos los hijos que se visitan para recorrer futuros grafos. También se marcan las entradas que contienen vértices que estén en el provenance objetivo, es decir, en las consultas que queramos recuperar.\nConsolidar:\nEs una simple unión de los hijos producidos por cada una de los recorridos de la anterior fase.\nReducir y mezclar:\nSe eliminan todas las entradas que están de más, recorriendo los grafos dirigidos resultantes y eliminando las entradas cuya propiedad de \"keep\" (mantener) es false. Por último se mezclan todos los grafos dirigidos, añadiendo al grafo general los hijos de cada grafo si no están ya en él.\nEl artículo continúa definiendo las tecnologías que se han usado para implementar el modelo,(Condor DAGMan, KickStart,...), y los resultados obtenidos tras varias simulaciones, pudiendo ver las gráficas resultantes.\nPara terminar, hace una revisión del trabajo que se ha hecho respecto al tema, enumerando los pros y los contras respecto al algoritmo que se presenta en el artículo.\nTowards Content Trust of Web Resources\n\nAutores :\nYolanda Gil y Donovan Artz.\nFecha :\nDiciembre 2007, Universidad de California del Sur.\nArtículo que quizá no está muy relacionado con el provenance, puesto que se centra en cómo clasificar de manera óptima la información disponible cuando un usuario reliza una busqueda en la Web. No se centra sólo en el contenido de la información, (como hacen la mayoría de los modelos\nexistentes), sino que se tiene en cuenta las circunstancias que rodean a la fuente.\nPara ello, se distingue entre la \"Confianza de entidad\",(juicio de confianza de una entidad basándose en su identidad y comportamiento), y \"Confianza de contenido\"(juicio de confianza de una información concreta en un contexto dado), resaltando la dificultad de gestionar ambos debido al carácter subjetivo que tienen y su dependencia del contexto.\nPero ¿cuáles son los factores que influyen determinantemente en la confianza sobre el contenido? En el artículo se exponen hasta 19, desde el tópico del que se está tratando, su popularidad, la autoridad de la fuente (no es lo mismo si un gobierno da la información que si es un señor anónimo), recomendación, provenance (si la fuente es fiable, el contenido adquiere fiabilidad), hasta lo reciente que es el contenido o la falta de otras fuentes con las que comparar la información.\nSin embargo, muchos de estos factores son parecidos, y se agrupan en 4 grupos principales: Autoridad, Fuentes asociadas (las relaciones de una fuente con otras influye en su confianza), Provenance y Bias (capacidad de una fuente de omitir información para parecer más fiable).\nModelo propuesto :\nSe toma un recurso r como la unidad básica de contenido, cualquier cosa que pueda ser referenciado por una URI. Cada recurso es representado por un subset de todas las asociaciones A. Cada miembro de A es representado mediante una tupla, <ar,ae>, que contiene la relación de la asociación \"ar\" y la entidad asociada \"ae\".\nSe definen varias funciones, cada una de las cuales devuelve un valor representativo de la confianza. El rango de todas ellas es t, que puede ser discreto o continuo, (por ejemplo, puede ser un set con los valores, confianza, desconfianza y neutralidad).\nUAT: user association trust,(la confianza de un usuario en una asociación para una consulta especícica): Q,A,U->t, donde Q es el grupo de queries, A, las asociaciones y U los usuarios.\nURT: user resource trust,(la decisión sobre la confianza de un usuario se calcula partir de las decisiones de las asociaciones de la fuente para una consulta dada): QRU->t\nAT: association trust,(confianza global de una asociación): Q,A->t\nRT: resource trust, (confianza global en un recurso): Q,R->t. Se deriva de URT.\nERT: estimated resource trust, (confianza estimada del recurso): mapedada por la función Q,R->t.\nEAT: estimated association trust, (confianza estimada en la asociación): Q,A->t\nCada recurso o fuente tiene una puntuación de relevancia, s^q:R->O, donde O es el set de valores que pueden ser usados para efectuar el ránking de recursos.\nEn último lugar, se presentan varios casos de uso donde aplicar el modelo, demostrando mediante los resultados el funcionamiento del mismo. Sin embargo, se hace hincapié en que se necesita más investigación en el área, puesto que los casos de uso propuestos puede que no sean los suficientemente genéricos como para dar por concluido el problema. Además hay que tener en cuenta que la web semántica no será sólo usada por personas, sino por razonadores y agentes que también seleccionan las fuentes en función de su confianza.\nConceptos reutilizables del estado del arte de los proyectos mIO! y España Virtual\n\nEn el estado del arte de España Virtual no he encontrado nada que creo que sea aplicable al data provenance.\nEn el estado del arte de mIO! me parece que el punto 1.1, \"Computación sensible al contexto\", aunque no trata directamente del data provenance, puede ser interesante nombrarlo. Plantea que el contexto en el que se ejecutan las acciones cambia, y como el provenance al final es un sistema mediante el cual podemos recuperar las acciones pasadas, es importante almacenar también el contexto en el que se ejecutan.\nDe no ser así, si recuperamos con éxito las acciones que un determinado usuario efectuó en un momento dado, pero no sabemos en qué contexto se ejecutaron, los resultados que se producirían si las volviéramos a reproducir podrían ser totalmente opuestos.\nProblem-Solving Methods for understanding Process Executions\n\nAutores :\nJose Manuel Gómez-Pérez y Oscar Corcho\nFecha :\n2008, iSOCO, Universidad Politécnica de Madrid y Universidad de Machester\nPaper donde se realiza una descripción del problema existente con el provenance dada la cantidad de datos que se han de manejar, y cómo el usuario que los va a usar no tiene porqué saber nada acerca de todo el sistema que gestiona dichos datos.\nSe usan los métodos de resolución de problemas (en inglés PSMs), para dotar al provenance de varios niveles de abstracción. La idea es que se interpreten los eventos pasados en vez de modelarlos. Los PSMs definen cuatro tipos de recursos de conocimiento:\nTareas: Describen lo que un proceso va a conseguir\nPSMs: Describen cómo un proceso consigue llevar a cabo una tarea, es decir, su estrategia, cómo se debe descomponer en subtareas, etc\nModelos de dominios: Describen el dominio particular al que aplicar las tareas y PSMs.\nOntologías: Dotan al resto de la semántica necesaria.\nTambién podemos representar los PSMs en 3 vistas: la vista de interacción, (que viene a ser una perspectiva de caja negra), la vista de flujo de conocimiento, (que indica cómo se intercambia la información entre subtareas), y la vista de descomposición, (donde se puede ver cómo el PSM se divide en subtareas).\nSe presenta KOPE, (\"Knowledge-Oriented Provenance Environment\"), como un sistema que el usuario puede instalar para analizar los logs del provenance. Su arquitectura se divide en 3 bloques principales: una infraestructura provenance para documentar y consultar la información acerca de los procesos, un editor PSM para que los usuarios gestionen las librerías PSM y ontologías, y el motor KOPE, que usa los métodos en las librerías PSM y las ontologías para analizar las distintas ejecuciones de los procesos.\nEn último lugar, se narra la participación de KOPE en el \"Provenance Challenge\", con el doble objetivo de evaluar su interoperabilidad con otros sistemas provenance, (como PASOA, en el cual está basado), y para probar su capacidad de análisis, (analizando la ejecución del workflow del atlas del cerebro (brain atlas workflow's execution)). Los resultados fueron positivos, ya que KOPE describió el proceso de creación del atlas del cerebro con un nivel 3 de refinamiento sobre 4.\nValidation of E-Science Experiments using a Provenance-based Approach (presentación)\n\nAutores :\nSylvia Wong, Simon Miles, Weijian Fang, Paul Groth y Luc Moreau\nFecha :\n???, Universidad de Southampton, Reino Unido.\nPresentación en la que se describe un sistema para validar experimentos con ayuda del provenance y ontologías. Muy útil cuando queremos verificar si un experimento se ha ejecutado correctamente con un criterio dado, (que no tiene porqué saberse cuando el propio experimento se diseñó o ejecutó).\nCuando se diseña un experimento, tenemos que distinguir todos los servicios que se usan y, para cada servicio, realizar una descripción del mismo que contenga lo que hace el servicio, sus entradas de datos y sus salidas de datos. Cada descripción se guardará en un registro.\nUna vez se ponga en marcha el experimento, se guardarán sus detalles en el provenance, y cada servicio documentará su propia ejecución.\nSi ahora quisiéramos reconstruir el experimento para saber, por ejemplo, si las salidas de un determinado proceso son compatibles con las entradas de otro, en primer lugar extraeríamos del provenance el par de procesos implicados, y miraríamos en el registro sus descripciones.\nEl problema es que normalmente las entradas de un proceso suelen ser la generalización de las salidas de otro, por lo que aquí es donde entra en juego la ontología: si describimos la relación de los tipos de las salidas, podremos razonar posteriormente si ambos son compatibles.\nProvenance and Interoperability (presentación)\n\nAutores :\nSimon Miles\nFecha :\n???, King's College, London\nPresentación donde se describe brevemente el porqué del provenance, los estándares que se intentan seguir a la hora de construir uno, y algunas de las herramientas que podemos utilizar para manejarlo en la actualidad.\nComienza enumerando las preguntas a las que debe ser capaz de responder el provenance, (¿Qué entradas se han usado para obtener la salida de este proceso?, ¿Cómo he llegado a este resultado?, etc.), y distinguiéndo qué entendemos exactamente por provenance,(todo aquello que ha causado que una entidad esté en el estado que está actualmente).También resalta la importancia de que muchas veces no estamos buscando todo un grafo, sino tan sólo una parte relevante del mismo.\nEn segundo lugar, se efectúa una breve descripción del OPM, del que ya he hablado en el primer artículo; y termina describiendo algunas de las herramientas en las que se usa, como Tupelo o Taverna.\nSemantic e-Science\n\nAutores :\nJun Zhao, Oscar Corcho, Paolo Missier, Khalid Belhajime, David Newmann, David de Roure y Carole A Goble\nFecha :\n???, universiades de Oxford, Politécnica de Madrid, Manchester y Southampton.\nCapítulo donde se describen una serie de proyectos e-science semánticos y se resumen algunas de las áreas que se están investigando y se han de investigar en el futuro.\nLos autores comienzan explicando que hay mucha información producida por la interacción en los workflows científicos, y que no se puede almacenar toda en un solo lugar. Sin embargo, si se distribuye surgen otros problemas, como que el formato en el que está la información.\nSe hace hincapié en la importancia del provenance: grabar los experimentos nos permite no sólo reporducirlos posteriormente, (con el ahorro que eso conlleva), sino analizar si son correctos con todos los metadatos que tenemos y la capacidad de ver si partes de los mismos son compatibles con otras de otros lugares. (Viendo por ejemplo si las entradas y las salidas coinciden).\nSin embargo, aunque el provenance tenga los datos y metadatos distribuidos en varias fuentes, los usuarios que accedan a él han de verlo como un único almacén. Para ellos la gestión de la información que ocurre por debajo ha de ser transparente, tan solo les interesa la respuesta a su consulta.\nA continuación se describen las necesidades de la e-Science, que son las siguientes:\nGestión de los datos: cada vez tenemos más datos, que van creciendo sin parar.\nNecesidad de soportar la naturalidad colaborativa multidisciplinaria de la ciencia: varios experimentos de varios equipos que han de trabajar juntos, por ejemplo.\nLa necesidad de reusar y reinterpretar información, y de entender su calidad.\nDescubrir información y herramientas que mejor le vengan a los científicos.\nIntegrar, operar agregar y comparar nueva información e información heredada.\nAcabar con la división entre datos, experimentos y publicaciones científicas.\nOrganizar e indexar la información obtenida con la investigación\nApoyar una investigación colaborativa multidisciplinaria\nSoportar, reusar y reinterpretar los recursos de los experimentos, y analizar su calidad.\nBuscar los recursos para los datos y herramientas de los científicos\nEl capítulo continúa enumerando varios proyectos relacionados y qué es lo que hace cada uno. También explica los problemas que trata y las herramientas semánticas que usa.\nGestión datos de investigación: el Observatorio Solar-Terrestre Virtual: Proyecto en el que se muestra cómo las tecnologías semánticas pueden ser aplicadas para proveer a los científicos acceso a conjuntos de datos observacionales.\nSoporte a investigación colaborativa multidisciplinaria: el entorno social virtual de investigación myExperiment: Aunque en un principio surgió como una simple red social para científicos, con el tiempo se ha convertido en un entorno social virtual de investigación basado en web. Sus 3 principales características son gestión del contenido, anotación de objetos e intarcción como si de una red social se tratase. Todo el modelo de datos está expresado en RDF, para ser reusable por otros proyectos, y los usuarios pueden subir nuevos contenidos para actualizar los workflows de sus experimentos. De esta manera podemos hacer un seguimiento de sus progresos.\nReusabilidad, reinterpretación y calidad de los experimentos : Qurator: Proyecto en el que se usa el modelado semántico para formalizar nociones de calidad de información en el contexto de e-Science, y para llevar a cabo la especificación de procesos formales que codifican la computación de métricas de calidad definidas por el usuario.\nDescubrimiento de datos y herramientas: el (BioCatalogue Web Service Registry) y el servicio web de anotación semántica QuAsar: el proyecto Biocatalogue tiene el objetivo de construir un servicio web de registro dedicado a la vida de la comunidad científica, ofreciendo una descripción semántica de los servicios web. Por otra parte, el proyecto QuAsar desarrolló un método para el aprendizaje de la anotación semántica en servicios web que una diferentes fuentes de información.\nCross-linking of Data Sources: Linked Open Data:La integración de datos científicos es un problema conocido. La información está esparcida por la red, en diferentes bases de datos y en diferentes formatos, haciendo muchas veces que obtengamos información incompatible. Sin embargo, para rellenar estos huecos de acceso se han ido desarrollando una seria de servicios web que sirvan de puente entre un tipo de datos y otro.\nEl proyecto Linking Open Drug Data intenta adoptar este modelo, favoreciendo la interoperabilidad.\nAcabando con la división entre datos, experimentos y publicaciones científicas: el proyecto Prospect: La división con la que se plantea acabar este proyecto es la que impide reusar y reciclar las investigaciones pasadas para que sean completamente explotadas. Se centra en el área de la Química, y mediante el uso de RDFS y Ontologías permite a los científicos buscar fácilmente artículos relacionados con el tema que están tratando, e incluso de acuerdo a la estructura jerárquica de clasificación de los términos usados en la búsqueda.\nEn último lugar, se habla de los recursos relacionados, que aportan otros puntos de vista interesantes para la visión de la e-Science semántica, y culmina haciendo un resúmen de los asuntos que aún quedan pendientes por resolver:\nUsabilidad de las tecnologías: lo útlimo que esperan los usuarios es tener que aprender complejas herramientas a la hora de realizar el proceso de revisión.\nIdentidades heterogéneas implican que los enlaces cruzados se compliquen: actualmente existen varios intentos de hacer homogéneas las identidades, pero esto no se puede conseguir a menos que se llegue a un consenso general.\nMejor soporte para buscar en la Web: la meta que se ha de proponer la web semántica es ser comparable a los motores de búsquedas actuales. La gente no va a cambiar a menos que esté convencida de las mejoras.\nConfianza y calidad: las aplicaciones construidas en la web semántica no servirán de mucho si la calidad y confianza de la información que encontramos es subjetiva. Para ello sirven todos los metadatos asociados a la información, que se han de recoger y gestionar de manera automática en la medida de lo posible.\nTransferencias de conocimiento para involucrar a los científicos: son los propios científicos los que necesitan aprender a organizar e indexar la información y el conocimiento que generan sus experimentos, así como compartirlos con el resto de la comunidad. Si no se implican en los métodos y prácticas de investigación propuestos, toda la maquinaria descrita anteriormente no serviría para mucho.\nTransferencia de conocimiento y educación: no solo hay que difundir las novedades obtenidas a otros científicos, sino también a nuevos estudiantes que empiecen a interesarse por las mismas.\nAssessing Information Quality Using Web Data Provenance\n\nAutores :\nOlaf Hartig y Jun Zhao\nFecha :\nWWW 2010,(26-30 de Abril), Universidad de Berlin y universidad de Oxford.\nArtículo en donde se presenta un modelo de provenance para los datos en la Web, parecido al OPM pero con diferencias significativas. Basándose en dicho modelo, se propone además un método para evaluar la calidad de la información que podemos encontrar en la Web.\nEn primer lugar, tras una breve introducción donde se narran las intenciones del artículo, se hace una revisión del trabajo ya realizado por otros investigadores, en concreto en el área del análisis de la calidad de la información. El proceso no es nada simple, porque requiere identificar los Indicadores de Calidad (Quality Indicators) para obtener un criterio IQ con el que obtener la puntuación IQ.\nUn indicador de calidad puede ser la información misma, metadatos sobre la información y las circunstancias de su creación o acceso, o puntuaciones dadas por los propios usuarios.\nLa evaluación de la calidad basada en el contenido usa la propia información como indicador de calidad. Sin embargo, en casos de datos no estructurados necesitaremos una técnica precisa de procesado de la información, junto a un análisis de texto autómatico que no siempre es preciso.\nPor otro lado, el análisis de metadatos procedentes del provenance ha sido utilizado para evaluar otro tipo criterios-IQ, como la credibilidad y confianza.\nEl OPM propone un modelo común para el provenance, y contiene muchos conceptos parecidos a los que se presentan en el paper, como los artefactos. Sin embargo, este modelo fue diseñado para un mundo cerrado , como un workflow o base de datos, mientras que el sistema del artículo se ha pensado para un mundo abierto como la Web.\nModelo de provenance\nLos tipos de elementos que contiene son 3: actores, ejecuciones y artefactos. Los actores son los que realizan la ejecución de un proceso, que  la mayoría de las veces, desemboca en la creación de un artefacto como un objeto de datos único. Un ejecución puede haber incluido el uso de artefactos, que a su vez pueden haber sido resultado de otra ejecución.\nEn cuanto a la creación de datos, el elemento central es la ejecución de creación de datos, ejecutada por un creador de datos. Para la creación, datos fuente y guías de creación podrían haber sido utilizados.\nEl grafo resultante de todas las interacciones entre los datos es lo que se denomina el grafo provenance. Los nodos son elementos provenance. Las aristas corresponden a las relaciones entre elementos, y su nombre es su etiqueta.\nPublicando información Provenance:\nUn estudio reciente destaca la falta de metadatos relacionados con el provenance en Internet. En el artículo se propone el Provenance Vocabulary para solucionar esto. Este vocabulario permite a los proveedores redactar información acerca  la información que están aportando.\nBásicamente consiste en 3 bloques principales: términos generales, términos para la creación de datos y términos para el acceso de datos. Está implementado como una ontología OWL.\nEvaluación basada en provenane\nValores de Impacto:\nEl propósito de un método de evaluación que siga el método propuesto en el paper es evaluar el criterio IQ de un item. Muchos de los elementos que están asociados al item están influenciados por el criterio IQ. Algunas de estas influencias las podemos verificar fácilmente basándonos en nuestro conocimiento sobre ellas, pero hay otras donde esto no es evidente. (Por ejemplo, si un proveedor manipula la información que publica).\nDebemos ignorar estas influencias potenciales, y para ello se proponen los valores de impacto.\nSe trata de valores asociados a cada elemento provenance, y representan la probabilidad de que el proveedor haya manipulado la información asociada.\nProcedimiento general para la evaluación IQ:\n1.-Generar el grafo provenance para el elemento en cuestión:\n2.- Anotar el grafo con valores de impacto\n3.- Calcular la puntuación IQ de un grafo anotado.\n-Diseñando métodos de evaluación:\nEn cada paso debemos responder una serie de preguntas para seguir adelante:\nPaso 1: ¿Qué tipos de elementos provenance son necesarios para determinar un criterio IQ? ¿Qué nivel de detalle es necesario para describir el provenance en el escenario de la aplicación? ¿Cómo conseguimos construir el grafo a partir de la información provenance que disponemos?\nExisten dos opciones posibles: algunas partes se pueden grabar desde el propio sistema. Otras a partir de metadatos de terceras personas/entidades.\nPaso 2: ¿Cómo influencia el criterio IQ cada elemento del provenance? ¿Cómo representamos las influencias con los valores de impacto?¿Cómo determinamos los valores de impacto?\nLos valores de impacto los podemos determinar a partir de  la información provenance, (por ejemplo, creación de la información); mediante análisis del contenido, mediante análisis del contexto o con los datos que nos da el usuario.\nPaso 3: ¿Cómo podemos representar el criterio IQ con un valor? ¿Qué función usamos para calcular dicho valor a partir del grafo provenance?\nSe recomienda diseñar la función junto con la especificación de los valores de impacto. La función de evaluación debe ser capaz de tratar con un grafo incompleto y en ocasiones incierto.\nA continuación, los autores realizan una evaluación del procedimiento, dando un criterio IQ, evaluando su influencia y decidiendo los valores de impacto, (como por ejemplo, el de creación del elemento). Se evitan los valores de impacto que faltan buscando información de contexto en la página del que publicó la información.\nPor último, se concluye diciendo que con el provenance no se consigue obtener toda la información necesaria en muchos casos, y que necesitaremos probablemente el contenido de la información u otros metadatos para la evaluación. Además se intentará alinear el modelo propuesto con el Open Provenance Project.\nPrOM: A Semantic Web Framework for Provenance Mangement in Science\n\nAutores :\nSatya S. Sahoo, Roger Barga, Amit Sheth, Krishnaprasad Thirunarayan, Pascal Hitzler\nFecha :\nWWW 2010,(24-30 de Abril), Universidad Wright State, Dayton y Microsoft Research, Radmond.\nUn sistema provenance es completamente inútil sin un sistema de queries bien definido. No sirve de nada tener toda la información referente al origen de un objeto si luego no sabemos cómo recuperarla.\nSe presenta el sistema prOM, que modela y resuelve los problemas de queries en la gestión del provenance.\nSucio:\nNecesidad de una representación común en la terminología del provenance. Las ontologías son consideradas como soluciones adecuadas para los requerimientos que tenemos, y además soportan el razonamiento para descubrir conocimiento implícito en amplias colecciones de datos.\nSin embargo, la información provenance no se limita a un solo dominio, por lo que el desarrollo de una ontología común es impracticable. En el paper se propone un enfoque multi-ontológico modular, fundado en una ontología para provenance llamada Provenir. Esta ontología se puede expandir para crear provenance sobre dominios específicos, como bien se muestra en el artículo con la ontología llamada Tridente.\nHasta la fecha no ha habido ningún estudio significativo sobre las características de las queries que deben poder hacerse a un sistema provenance. Se propone un esquema de clasificación para las queries, para categorizarlas y definir operadores en términos de la ontología Provenir.\nModelo\nPrimer problema: encontrar el equilibrio entre las ontologías abstractas de alto nivel y las de dominio específico. Provenir representa un set de términos provenance que son comunes a los dominios y que pueden ser fácilmente extensibles a dominios específicos por los desarrolladores de acuerdo a sus requisitos particulares.\nProceso, dato y agente son las tres clases clave en la ontología Provenir. Para relacionarlos entre sí se define la “Relation ontology”, que propone un set de 10 propiedades con dominio y rango bien definidos. Además, también se clasifican los parámetros de espacio, tiempo y tema, (por ejemplo, la localización geográfica de un sensor es un parámetro de espacio).\nProvenance query y análisis:\nLas queries se pueden dividir en 3 categorías: las que recuperan información provenance de una entidad, las que recuperan entidades que satisfagan una serie de restricciones y las que efectúan operaciones con la información provenance, (como modificación o comparación).\nPara llevar a cabo cada una de las queries, se proponen los operadores.  El primero sirve para satisfacer las queries de la categoría 1: provenance. Tiene 2 fases: inicialización y recursiva. En la fase de inicialización, se añaden todos los individuos de la clase proceso que tienen que ver con la entrada a través de la propiedad “has_participant”. En la fase recursiva, se utilizan los procesos individuales para rescatar todas las entidades que están relacionadas con process mediante la relación “preceeded_by”.\nPara el segundo operador, provenance_context, usamos directamente en el primer operador. Como entrada admite los valores de provenance a modo de restricciones, y como salida da las entidades que satisfacen dichas restricciones.\nEn último lugar, los operadores restantes sirven para comparar y mezclar provenance. Se usa la definición RDF equivalencia de grafos con la funcionalidad añadida de “colorear” los nodos y etiquetar aristas usando la ontología Provenir, de manera que se puedan comparar dos grafos provenance. Para realizar la mezcla, se eligen como entrada 2 grafos provenance y como salida obtenemos un grafo mezclado y sin duplicados.\nImplementación y evaluación:\nPara la implementación se usa un compositor de queries, que hace un mapping de los operadores a SPARQL; una función para procesar el cierre transitivo en RDF eficientemente, y un optimizador de queries usando vistas materializadas de provenance, que permite al motor de peticiones escalar grandes sets de datos RDF.\nEn cuanto a la evaluación, se realiza la separación entre la complejidad de la expresión de la query y la complejidad de los datos. En ambos casos, los resultados obtenidos son que la implementación directa del provenance no es escalable si los datos se van incrementando. Por ello se introducen las vistas materializadas de provenance, que materializa sub-grafos provenance para las clases de las entradas seleccionadas. Con ellas los resultados mejoran enormemente.\nPara terminar el artículo se hace una pequeña revisión del estado del arte, en donde se muestran las diferencias con el OPM, y las carencias y contradicciones que muestra a la hora de hacer una implementación.",
  "speaker": "SYSTEM",
  "uuid": "844d6101-d572-464e-85fb-cbbd9abc1975"
}