{
  "message": "SYSTEM: Neon_2008_d2.2.2.pdf: Página 101\nD2.2.2 Methods and Tools Supporting Re-engineering\nPage 101 of 124\nEnrichment Result\n# of Tags\nPercentage\nCORRECT\n281\n24.5%\nINCORRECT\n20\n1.7%\nUNDETERMINED\n4\n0.3%\nNON ENRICHED\n841\n73.4%\nTotal\n1146\n100%\nTable 6.1: Evaluation of semantic enrichment for individual tags.\nwith any of the rest of the tags, the WordNet sense assigned to it was the most popular one, Geometrical\nshape. This lead to the assignment of non-relevant SWE’s namely, Square SubClassOf Rectangle and\nSquare SubClassOf RegularPolygonShaped. Despite this error, the rest of the tags in this tagset were\ncorrectly enriched.\nFLOR failed to enrich 841 tags, i.e., 73.4% of the tags (see Table 6.1). Because this is a signiﬁcant amount\nof tags, we wished to understand whether the enrichment failed because of FLOR’s recall or because most\nof the tags have no equivalent coverage in online ontologies. To that end we selected a random 10% of the\n841 tags (85 tags) and manually identiﬁed appropriate SWE(s) using WATSON and taking into account the\ncontext(s) of the tags in the tagset(s) they appear. Out of the 85 tags we manually enriched 29. We therefore\nestimate that the number of tags that could have been enriched by FLOR (i.e., those for which an appropriate\nSWE exists) is approximately 287. Thus, taking into account that the overall number of tags that should be\ncorrectly enriched was 568 (281+287) but only 281 were enriched by FLOR this leads to an approximate\nrecall rate of 49%. While this is quite a low recall, these results are highly superior to the ones we have\nobtained in previous experiments where phase 2 was not part of FLOR, i.e., we directly searched for SWEs\nfor the tags without relying on WordNet as an intermediary step. Indeed, the WordNet sense deﬁnition and\nexpansion of the tags with synonyms and hypernyms (FLOR phase 2) increased the tag discovery in the\nSemantic Web thus having a positive effect on recall.\nFLOR failed to enrich the above 29 tags due to the following reasons. The majority of the failures (55%) was\ndue to different deﬁnition in terms of superclasses in WordNet and in online ontologies For example, the\ndeﬁnition of love in WordNet and the relevant entity found in the Semantic Web are:\nWordNet: Love→Emotion→Feeling→Psychological feature\n(a strong positive emotion of regard and affection)\nSemantic Web: Love SubClassOf Affection\nAlthough both these deﬁnitions refer to the same sense, and additionally the superclass Affection belongs to\nthe gloss of Love in WordNet, they were not matched because Affection does not appear as a hypernym of\nLove. Current work investigates alternative ways of Semantic Expansion.\nA further 24% of the tags not connected to any SWE were assigned to the wrong sense during phase 2.\nFor example, bulb referring to light bulb in its tagset is assigned the incorrect sense Bulb →Stalk →\nStem →Plant organ. The rest of the unenriched tags are due to failures in anchoring them into appropriate\nSWE’s. For example, the sense of butterfly was correctly identiﬁed, but non of its lexical forms matched\nthe label of the appropriate SWE (Butterﬂy_Insect):\nWordNet: Butterﬂy→Lepidopterous insect →Lepidopteron →Lepidopteran →Insect\nSemantic Web: Identiﬁed entity with localname Butterﬂy_Insect\nIn the case of 4 tags the evaluator could not determine whether the enrichment was correct or incorrect\n(Table 6.1). This is because the meaning of the tag was unclear even when considering its context and the\nactual photo.\n2006–2008 c⃝Copyright lies with the respective authors and their institutions.\n",
  "speaker": "SYSTEM",
  "uuid": "57aea6bf-f438-48ea-89b4-213389c2ad45"
}