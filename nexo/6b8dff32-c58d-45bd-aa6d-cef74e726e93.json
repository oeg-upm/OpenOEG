{
  "message": "SYSTEM: Science-2015-HirschbergManning-NLP.pdf: Página 2\n(6). Rather than translating word by word, the\nkey advance is to notice that small word groups\noften have distinctive translations. The Japa-\nnese\n“mizu iro” is literally the sequence\nof two words (“water color”), but this is not the\ncorrect meaning (nor does it mean a type of\npainting); rather, it indicates a light, sky-blue color.\nSuch phrase-based MT was used by Franz Och in\nthe development of Google Translate.\nThis technology enabled the services we have\ntoday, which allow free and instant translation\nbetween many language pairs, but it still pro-\nduces translations that are only just serviceable\nfor determining the gist of a passage. However,\nvery promising work continues to push MT for-\nward. Much subsequent research has aimed to\nbetter exploit the structure of human language\nsentences (i.e., their syntax) in translation sys-\ntems (7, 8), and researchers are actively building\ndeeper meaning representations of language (9)\nto enable a new level of semantic MT.\nFinally, just in the past year, we have seen the\ndevelopment of an extremely promising approach\nto MT through the use of deep-learning–based\nsequence models. The central idea of deep learn-\ning is that if we can train a model with several\nrepresentational levels to optimize a final objec-\ntive, such as translation quality, then the model\ncan itself learn intermediate representations\nthat are useful for the task at hand. This idea\nhas been explored particularly for neural net-\nwork models in which information is stored in\nreal-valued vectors, with the mapping between\nvectors consisting of a matrix multiplication fol-\nlowed by a nonlinearity, such as a sigmoid func-\ntion that maps the output values of the matrix\nmultiplication onto [−1, 1]. Building large models\nof this form is much more practical with the\nmassive parallel computation that is now econo-\nmically available via graphics processing units. For\ntranslation, research has focused on a particular\nversionofrecurrentneuralnetworks, withenhanced\n“long short-term memory” computational units\nthat can better maintain contextual information\nfrom early until late in a sentence (10, 11) (Fig. 2).\nThe distributed representationsofneuralnetworks\nare often very effective for capturing subtle seman-\ntic similarities, and neural MT systems have al-\nready produced some state-of-the-art results (12, 13).\nA still-underexplored area in MT is getting ma-\nchines to have more of a sense of discourse, so\nthat a sequence of sentences translates naturally—\nalthough work in the area has begun (14). Finally,\nMT is not necessarily a task for machines to do\nalone. Rather it can be reconceptualized as an op-\nportunity for computer-supported cooperative\nwork that also exploits human skills (15). In such\na system, machine intelligence is aimed at human-\ncomputer interface capabilities of giving effective\nsuggestions and reacting productively to human\ninput, rather than wholly replacing the skills and\nknowledge of a human translator.\nSpoken dialogue systems and\nconversational agents\nDialogue has been a popular topic in NLP re-\nsearch since the 1980s. However, early work on\ntext-based dialogue has now expanded to include\nspoken dialogue on mobile devices (e.g., Apple’s\nSiri, Amtrak’s Julie, Google Now, and Microsoft’s\nCortana) for information access and task-based\napps. Spoken dialogue systems (SDSs) also allow\nrobots to help people with simple manual tasks\n[e.g., Manuela Veloso’s CoBots (16)] or provide\ntherapy for less-abled persons [e.g., Maja Mataric’s\nsocially assistive robots (17)]. They also enable ava-\ntars to tutor people in interview or negotiation stra-\ntegies or to help with health care decisions (18, 19).\nThe creation of SDSs, whether between hu-\nmans or between humans and artificial agents,\nrequires tools for automatic speech recognition\n(ASR), to identify what a human says; dialogue\nmanagement (DM), to determine what that hu-\nman wants; actions to obtain the information or\nperform the activity requested; and text-to-speech\n(TTS) synthesis, to convey that information back\nto the human in spoken form. (Fig. 3). In addition,\nSDSs need to be ready to interact with users when\nan error in speech recognition occurs; to decide\nwhat words might be incorrectly recognized; and\nto determine what the user actually said, either\nautomatically or via dialogue with the user. In\nspeech-to-speech translation systems, MT com-\nponents are also needed to facilitate dialogue\nbetween speakers of different languages and the\nsystem, to identify potential mistranslations before\nthey occur, and to clarify these with the speaker.\nPractical SDSs have been enabled by break-\nthroughs in speech recognition accuracy, mainly\ncoming from replacing traditional acoustic feature–\nmodeling pipelines with deep-learning models that\nmapsoundsignalstosequencesof human language\nsounds and words (20). Although SDSs now work\nfairly well in limited domains, where the topics of\nthe interaction are known in advance and where\nthe words people are likely to use can be predeter-\nmined, they are not yet very successful in open-\ndomain interaction, where users may talk about\nanything at all. Chatbots following in the tradition\nof ELIZA (21) handle open-domain interaction by\ncleverly repeating variations of the human input;\n262\n17 JULY 2015 • VOL 349 ISSUE 6245\nsciencemag.org SCIENCE\ncase\naux\nnsubj\nM\nMrs. Clinton previously worked for Mr. Obama, but she is \nnow distancing herself from him  .\nPart of speech:\nNNP\nNNP\nPRP\nPRP\nPRP\nNNP\nVBD\nVBZ\nVBG\nNNP\nRB\nRB\nCC\nIN\nIN\n,\nMrs.                Clinton previously     worked   for   Mr.                 Obama, but she is \nnow          distancing  herself from          him  .\nBasic dependencies:\nNNP\nNNP\nPRP\nPRP\nPRP\nNNP\nVBD\nVBZ\nNNP\nRB\nRB\nCC\nIN\nIN\n,\n.\nMrs. Clinton previously worked for Mr. Obama, but she is now distancing herself from him.\nNamed entity recognition:\nPerson\nDate\nDate\nPerson\nMrs. Clinton previously worked for Mr. Obama, but she is now distancing herself from him.\nCo-reference:\nMention\nM\nMent\nCoref\ncompound\ncompound\ncase\ndobj\nadvmod\nnmod\nnmod\ncc\nconj\nadvmod\nnsubj\nCoref\nCoref\nMention\nVBG\n.\nFig. 1. Many language technology tools start by doing linguistic structure analysis. Here we show output from Stanford CoreNLP. As shown from top to\nbottom, this tool determines the parts of speech of each word, tags various words or phrases as semantic named entities of various sorts, determines which entity\nmentions co-refer to the same person or organization, and then works out the syntactic structure of each sentence, using a dependency grammar analysis.\nARTIFICIAL INTELLIGENCE\n \n",
  "speaker": "SYSTEM",
  "uuid": "6b8dff32-c58d-45bd-aa6d-cef74e726e93"
}