{
  "message": "SYSTEM: ISWC2010_Andres_SemGroCrosLingFol.pdf: Página 13\nSemantic Grounding of Cross-Lingual Folksonomies\n13\nTable 3. Evaluation results achieved by the diﬀerent approaches for Spanish entities.\nWilcoxon’s statistical test was conducted for MAP, P@1, R@1, F-measure, MRR and\nNDCG metrics. Values in underline bold (p=0.01), bold (p=0.05), and italic bold\n(p=0.1) indicate a statistical signiﬁcance diﬀerence with values achieved by the baseline\napproach. Values marked with ‡(p=0.01), †(p=0.05), and ∗(p=0.1) indicate a statistical\nsigniﬁcance diﬀerence with values achieved by Sem4Tags approach.\nMAP P@1 P@2 P@3 P@4 P@5 R@1 R@2 R@3 R@4 R@5\nF\nMRR NDCG\nAll entities\nBaseline\n0.71\n0.88\n-\n-\n-\n-\n0.71\n-\n-\n-\n-\n0.27\n0.88\n0.74\nSem4Tags\n0.93\n0.93 0.58 0.42 0.33 0.27 0.79\n0.90 0.95 0.97 0.98 0.41 0.96\n0.95\nSem4TagsAC\n0.93\n0.94 0.57 0.42 0.33 0.27 0.80∗0.89 0.93 0.96 0.96 0.40 0.96\n0.95\nSem4TagsAbs\n0.88‡ 0.90∗0.53 0.39 0.32 0.26 0.76 ∗0.85 0.90 0.93 0.94 0.39 0.93∗0.91‡\nSem4TagsAbsAC 0.89‡ 0.91∗0.54 0.40 0.32 0.26\n0.77\n0.85 0.90 0.93 0.94 0.39 0.94∗0.91‡\nNamed entities\nBaseline\n0.67\n0.90\n-\n-\n-\n-\n0.67\n-\n-\n-\n-\n0.27\n0.90\n0.72\nSem4Tags\n0.94\n0.96 0.64 0.48 0.38 0.31 0.74\n0.87 0.93 0.96 0.97 0.45 0.98\n0.96\nSem4TagsAC\n0.93\n0.96\n0.63 0.47 0.38 0.31 0.74\n0.87 0.92 0.96 0.96 0.44 0.98\n0.95\nSem4TagsAbs\n0.88‡ 0.92∗0.58 0.44 0.36 0.30 0.71 ∗0.82 0.88 0.92 0.93 0.42 0.95∗0.91‡\nSem4TagsAbsAC 0.88‡ 0.92∗0.58 0.44 0.36 0.30\n0.72\n0.82 0.88 0.93 0.93 0.42 0.96∗0.91‡\nUnnamed entities\nBaseline\n0.78\n0.84\n-\n-\n-\n-\n0.78\n-\n-\n-\n-\n0.27\n0.84\n0.79\nSem4Tags\n0.93\n0.91\n0.53 0.38 0.29 0.24\n0.83\n0.92 0.96 0.98 0.98 0.37 0.95\n0.95\nSem4TagsAC\n0.92\n0.93\n0.52 0.37 0.28 0.23 0.85∗0.91 0.95 0.96 0.96 0.36 0.95\n0.94\nSem4TagsAbs\n0.89\n0.89 0.50 0.36 0.28 0.23\n0.81\n0.88 0.92 0.94 0.94 0.36 0.92 ∗\n0.91\nSem4TagsAbsAC\n0.90\n0.90 0.51 0.36 0.28 0.23\n0.82\n0.89 0.92 0.94 0.94 0.36 0.93\n0.92\nFinally, note that the baseline retrieves a single semantic association for\neach tag. For this reason, metrics P@N and R@N with N = 2, 3, 4, 5 are not\nreported for that approach. Indeed, the coverage (recall) of the baseline is low in\ncomparison to the proposed approaches, as shown in the tables. Analyzing the\nobtained results, the following conclusions can be drawn from our study.\n– In general, the baseline obtained high performance results with tags in En-\nglish and in Spanish. This fact suggests that a high percentage of the ana-\nlyzed tags were used in the sense directly found by the Baseline. However, as\nwe will discuss in Section 5.2, the baseline was able to ﬁnd semantic resources\nfor just a fraction of the analyzed data set.\n– Sem4Tags and its variants perform better when dealing with Spanish tags.\nThe amount of information in the Spanish Wikipedia compared with the\nEnglish version is considerably lower25. Nevertheless, the Spanish version\nseems to contain more precise information that leads to better results.\n– All approaches obtained better precision with named entities than with un-\nnamed entities. The same observation is applicable to ranking based metrics\nMRR and NDCG. The ﬁrst positions of the approach rankings tend to\nhave more relevant results for named entities. This can be explained by the\nfact Wikipedia is more an encyclopedia than a dictionary, and thus named\nentities are a central part of the Wikipedia compared with other words.\n25 As of June 2010, the English and Spanish Wikipedia have 3,332,294 and 614263\narticles respectively\n",
  "speaker": "SYSTEM",
  "uuid": "6ba5e505-e0b6-484c-bccd-02a3f4a9cf2d"
}