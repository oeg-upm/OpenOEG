{
  "message": "SYSTEM: 2216-LT2013_Report_20130408.pdf: Página 46\n44\nwww.lt‐innovate.eu ‐ contact@lt‐innovate.eu\nspeech synthesizers since the early 1980s.\nVendors active in text‐to‐speech include Cereproc, BuddyBird, NeoSpeech, TextSpeak, Acapela, and Nuance.\nApplications\nVirtual assistants for business\nVoice‐enabled virtual assistants for the enterprise inspired by Apple’s Siri application, such as Nuance\nCommunications’ Nina, Angel’s Lexee, and Taptera’s Sophia became available during 2012. Unlike Siri, these\nvirtual assistants are designed for business purposes.\nEmotive voices\nSeveral European vendors are developing emotion‐rich voices including Cereproc and Acapela. MARY Open‐\nSource Emotional Text‐to‐Speech Synthesis is a multilingual (German, U.S. and U.K. English, Turkish, and\nTibetan), multiplatform (Windows, Linux, Mac OS X, and Solaris) speech synthesis. With EmoSpeak tool,\nMARY can synthesize emotionally expressive speech using diaphone voices. Users can also select expressive\nunit voices, such as a German soccer announcer and control the intonation \nLoquendo TTS voices have been enriched with expressive cues that allow for highly emotional pronunciation.\nThese cues, which can be typed directly into the text with the appropriate punctuation or selected from a\ndrop‐down menu, contain conventional figures of speech, such as greetings and exclamations (hello, oh no,\nthank you), interjections (oh, well, hmm), and paralinguistic events (breathing, laughing, coughing), to con‐\nvey additional layers of expressive intent, such as gratitude, doubt, or confirmation. A Pronunciation Lexicon\nensures that specialized vocabulary, abbreviations, acronyms, and even regional pronunciation differences\nsound as the developer intended them. Loquendo supports 30 languages with a total of 72 voices.\n4.4 Speech ID/Verification, Voice Biometrics\nAlso known as speaker recognition, speech ID / verification comprise methods designed to distinguish\nbetween real human users and computer programs that are interacting with the system, verifying that a\nhuman is interacted with the automated speech based system or application.\nSpeaker recognition has a history dating back some four decades and uses the acoustic features of speech\nthat have been found to differ between individuals. These acoustic patterns reflect both anatomy (e.g., size\nand shape of the throat and mouth) and learned behavioural patterns (e.g., voice pitch, speaking style).\nSpeaker verification has earned speaker recognition its classification as a «behavioural biometric».\nFrom a security perspective, identification is different from verification. For example, presenting your pass‐\nport at border control is a verification process ‐ the agent compares your face to the picture in the document.\nConversely, a police officer comparing a sketch of an assailant against a database of previously documented\ncriminals to find the closest match (es) is an identification process.\nSpeaker verification is usually employed as a «gatekeeper» in order to provide access to a secure system.\nThese systems operate with the user’s knowledge and typically require their cooperation. Speaker identifi‐\ncation systems can also be implemented covertly without the user’s knowledge to identify talkers in a dis‐\ncussion, alert automated systems of speaker changes, check if a user is already enrolled in a system, etc.\nIn forensic applications, it is common to first perform a speaker identification process to create a list of «best\nmatches» and then perform a series of verification processes to determine a conclusive match. Also, there\n",
  "speaker": "SYSTEM",
  "uuid": "efeb0612-d28a-4d0f-a148-d8d8be8af077"
}