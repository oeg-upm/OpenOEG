{
  "message": "SYSTEM: Neon_2008_d2.2.2.pdf: Página 115\nD2.2.2 Methods and Tools Supporting Re-engineering\nPage 115 of 124\nmore general classes but better accuracy (does not overgenerate so much). For example, in the following\nsentence:\nThe individuals communicate using a variety of clicks, whistles and other vocalizations.\nvariety of click is recognised as a subclass of vocalization. While this is technically correct, a better interpre-\ntation would be simply the subclass click.\nSimilarly in the sentence:\nA minor class of sheep are the dairy breeds.\nminor class of sheep is recognised as a superclass, with subclass dairy breeds. Better would be to recognise\nthe superclass simply as sheep, since the subclass relation indicates the minor class relationship.\nOn the other hand, if we reduce the span of the noun phrase, we risk losing some important information. For\nexample, in the sentence:\nMygalomorph and Mesothelae spiders have two pairs of book lungs ﬁlled with haemolymph\nif we do not identify the full noun phrase two pairs of book lungs, we can end up with the rather uninformative\nproperty two pairs of the class Mesothelae spider. A closer analysis of the spans is needed, which may help\nidentify which patterns require longer spans than others, for example. Currently, the NP chunker decides the\nspan for all noun phrases, but it may be more appropriate to alter the functionality of the chunker depending\non the pattern, or to restrict the NPs to terms using TermRaider for some cases.\nSecond, lexical patterns tend to be quite ambiguous as to which relations they indicate. For example, NP\nhave NP could indicate an object property or a datatype property relationship. Also, English word order can\nlead to inverse relations. For example, in the sentence “A traditional Cornish pilchard dish is the stargazy\npie”, stargazy pie is a kind of Cornish pilchard dish, but the sentence can equally be written “The stargazy pie\nis a traditional Cornish pilchard dish”. Here, the use of the deﬁnite and indeﬁnite determiner helps to identify\nthe correct relationship, but this is not always the case. Often, further context is also crucial. For example, in\nthe sentence “Both African males and females have external tusks”, it is not very useful to extract the concept\nfemales with the property have external tusks unless you know that females actually refers to female African\nelephants. To extract this information would require also coreference matching.\nCare also needs to be taken to avoid actual erroneous (rather than simply spurious) results. For example,\nif negatives are not taken into acount, the consequences can be disastrous. From the phrase “DAT is a\nlegitimate therapy”, we could easily deduce that DAT could be classiﬁed as an instance of therapy. How-\never, further inspection of the wider context reveals that the opposite is true, as the sentence actually reads\n“Reviews of this and other published dolphin-assisted therapy (DAT) studies have found important method-\nological ﬂaws and have concluded that there is no compelling scientiﬁc evidence that DAT is a legitimate\ntherapy.” Of course, this is a common problem with shallow NLP systems.\nTo summarise, we are currently investigating a number of options to improve the recognition.\nFirst, we\nare looking at the incorporation of deeper semantic relations using semantic classes from VerbNet[Sch05]\nand WordNet[Fel98] in order to look for verbal patterns connecting terms in a sentence. We make use of\nthe ANNIC plugin in GATE [ATBC05] to search for frequently occurring annotation patterns. We are also\ninvestigating the use of TermRaider for restricting the number of candidates for extraction. Also, we plan to\nincorporate combinations of Hearst patterns and statistically derived collocational information, because its\ncombination with lexico-syntactic patterns has proven to improve precision and recall [CW03].\nIntegration of a full parser has also been investigated, but discarded on the grounds of speed (full parsing is\nextremely computationally expensive in this situation). In particular, we found that the sentences in Wikipedia\narticles, which we have used for training and testing, are quite hard to parse well, because they frequently\nexhibit a long and complex sentence structure which is highly ambiguous to a parser. This causes not only\nspeed but also accuracy problems.\n2006–2008 c⃝Copyright lies with the respective authors and their institutions.\n",
  "speaker": "SYSTEM",
  "uuid": "356dcba6-4f31-4621-a554-9086d3453bbb"
}