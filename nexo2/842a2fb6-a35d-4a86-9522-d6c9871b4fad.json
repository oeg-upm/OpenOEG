{
  "message": "SYSTEM: Science-2015-HirschbergManning-NLP.pdf: Página 4\nML. A structured prediction classifier proposes\ninstances of such relations based on extracted\nfeatures from the sequence of words and gram-\nmatical structure of a sentence (28, 29). Such sys-\ntems are the mainstay of literature fact-extraction\ntools in fields such as biomedicine (30, 31).\nIn many scientific fields, there have been ma-\njor efforts to build databases of structured infor-\nmation based on the textual scientific record,\nsuch as the Gene Ontology database (32) in bio-\nmedicine or the PaleoBiology Database for fossil\nrecords (33). This has generally been done man-\nually, via concerted work by trained profes-\nsionals. Using artificial intelligence software to\nextract these databases, as well as to perform\nsubsequent reasoning and hypothesis genera-\ntion, has become a major research goal. One\nsubfield where these questions have been ac-\ntively pursued is pharmacogenomics (34). For\nexample, Percha et al. (35) trained a model of\ndrug-drug interactions based on drug-gene in-\nteractions extracted from the literature and were\nabletouseittopredictnoveldrug-druginteractions.\nIf a partial knowledge base—for instance, Freebase\n(36), dbpedia (37), Wikidata (38) (related to Wikipe-\ndia),ortheGeneOntologydatabase(32)—hasalready\nbeen extracted from biomedical research articles,\nthen there is an opportunity to automatically align\nknown facts from the knowledge base with puta-\ntive expressionsof thosefactsintext.Thetype labels\nfrom this mapping can then be used as if they were\nsupervised data for ML information-extraction sys-\ntems (Fig. 4). This is referred to as distantly super-\nvised relation extraction. Early systems aligned\nentity mentions and then made the naïve assump-\ntion that sentences containing a pair of entities\nexpressed every known relation between the two\nentities in the database (39). More recent systems\nhave used increasingly sophisticated probabilistic\ninference to discern which textual clauses map to\nwhich facts in the knowledge base, or to something\nelse entirely (40, 41). A dramatic recent applica-\ntion of this approach has been the DeepDive sys-\ntem (42), which aims to automate the construction\nof such systems by providing efficient large-scale\nlearning and inference so a user can simply focus\non good features for their domain. PaleoDeepDive,\nits application to the fossil record, has recently been\nshown to do a better job at fact extraction from\njournal articles than the scientist volunteers who\nmaintain the PaleoBiology Database (43).\nThe relation-extraction task is made general,\nif less semantically precise, by aiming to ex-\ntract all relations from any piece of text, a task\nnormally referred to as open information ex-\ntraction (Open IE) (44). Early work emphasized\nthe development of simple but highly scalable\nfact-extraction techniques that do not require\nany kind of hand-labeled data (45). With ever-\ngrowing computational power, a second genera-\ntion of work increasingly emphasized careful use\nof linguistic structure, which can reliably be ex-\ntracted with the use of detailed NLP (46).\nCurrently, a number of avenues are being\nexplored to further extend the ability of compu-\nters to build and use knowledge bases starting\nfrom textual information. An exciting unification\nis the proposal for universal schemas (47), which\nallow simultaneous inference and knowledge-\nbase completion over both the open set of textual\nrelations (such as “born in”) found in Open IE\nand the more exact schema of databases (such\nas per:city_of_birth). Even with all of our text-\nextraction techniques, any knowledge base will\nonly be partial and incomplete; some recent\nwork explores how it can be probabilistically com-\npleted to deliver a form of common-sense rea-\nsoning (48). Finally, we hope to move beyond\nsimply extracting relations, events, and facts to\nbe able to understand the relations between\nevents (such as causation) and complex multistep\nprocedures and processes. In (49), Berant et al.\nexplore how this can be done for understanding\nthe steps in biological processes, showing that\nextracting explicit process structures can improve\nthe accuracy of question answering. The flip side of\nmachine reading is to provide question-answering\nsystems, by which humans can get answers from\nconstructed knowledge bases. There has recently\nbeen dramatic progress in building such systems\nby learning semantic parsers (50).\nMining social media\nThe development of social media has revolution-\nized the amount and types of information avail-\nable today to NLP researchers. Data available\nfrom sources such as Twitter, Facebook, YouTube,\nblogs, and discussion forums make it possible\nto examine relations between demographic in-\nformation, language use, and social interaction\n(51). Researchers use Web-scraping techniques,\noften via application program interfaces pro-\nvided by websites, to download previously unim-\naginable amounts and categories of data. Using\nstatistical and ML techniques, they learn to iden-\ntify demographic information (such as age and\ngender) from language, track trending topics and\npopular sentiment, identify opinions and beliefs\nabout products and politicians, predict disease\nspreading (for instance, with Google Flu Trends:\nwww.google.org/flutrends/) from symptoms men-\ntioned in tweets or food-related illnesses (52),\nrecognize deception in fake reviews (53), and\nidentify social networks of people who interact\ntogether online.\nIn this era of big data, the availability of social\nmedia has revolutionized the ways advertisers,\njournalists, businesses, politicians, and medical\nexperts acquire their data and the ways in which\nthose data can be put to practical use. Product\nreviews can be mined to predict pricing trends\nand assess advertising campaigns. Political forums\ncan be searched to predict candidate appeal and\nperformance in elections. Social networks can be\nexamined to find indicators of power and influ-\nence among different groups. Medical forums can\nbe studied to discover common questions and\nmisconceptions about sufferers from particular\nmedical conditions so that website information\ncan be improved.\nSocial media also provide very large and rich\nsources of conversational data in Web forums\nthat can provide “found” data for the study of lan-\nguage phenomena such as code-switching (mixed\n264\n17 JULY 2015 • VOL 349 ISSUE 6245\nsciencemag.org SCIENCE\nJohn Curtin\nThe Right Honourable\n14th Prime Minister of Australia\nElections: 1937, 1940, 1943\nPersonal details\nBorn\nJohn Joseph Curtin\n8 January 1885\nCreswick, Colony of Victoria\nBritish Empire\nDied\n5 July 1945 (aged 60)\nCanberra, Australia\nJohn Curtin (1885-1945),\nprime minister and journalist,\nwas born on 8 January 1885\nat Creswick, Victoria, \neldest of four children of \nIrish-born parents John \nCurtin and his wife \nCatherine (Kate) Agnes,\nnée Bourke.  . . .\nper: city_of_birth\nper: date_of_birth\nLearn how to extract\nslots from free text:\nwas born on <DATE>\nborn . . . at <LOCATION>\nper: city_of_birth\nper: date_of_birth\nFig. 4. Distantly supervised learning. In this ap-\nproach, facts in a structured knowledge repre-\nsentation are projected onto pieces of text that\nmention the people, places, dates, etc., that appear\nin knowledge-base entries.This projection is noisy,\nbut when done over large quantities of text, it pro-\nvides enough signal to successfully learn good clas-\nsifiers for extracting relations from text. [Photo\nsource: National Library of Australia, http://nla.gov.\nau/nla.pic-an12267621]\nARTIFICIAL INTELLIGENCE\n \n",
  "speaker": "SYSTEM",
  "uuid": "842a2fb6-a35d-4a86-9522-d6c9871b4fad"
}